---
layout: post
title: Automatic Speech Recognition (ASR Part 0)
date: '2018-12-04T13:35:39.001162'
author: Sujay S Kumar
tags: 
---

Automatic Speech Recognition (ASR) systems are used for transcribing spoken text into words/sentences. ASR systems are complex systems consisting of multiple components, 
working in tandem to transcribe. In this blog series, I will be exploring the different components of a generic ASR system (although I will be using Kaldi for some
references).

Any ASR system consists of the following basic components:

- [Audio and Speech Signal Processing (ASR Part 1)]({% post_url 2018-12-04-asr-part1 %})
- [Acoustic Modeling (ASR Part 2)]({% post_url 2018-12-05-asr-part2 %})
- Language Modeling (ASR Part 3)
- Decoding (ASR Part 4)

### ASR Resources

- [Lecture Videos](<https://www.superlectures.com/icassp2011/category.php?lang=en&id=131>)
- [Slides](<http://www.danielpovey.com/kaldi-lectures.html>)
- [edX Course](<https://www.edx.org/course/speech-recognition-systems-1>)
- [Nice Tutorial](<https://www.eleanorchodroff.com/tutorial/kaldi/introduction.html>)
- [Josh Meyer's Website](<http://jrmeyer.github.io/>)
- [Josh Meyer's Notes](<http://jrmeyer.github.io/asr/2016/02/01/Kaldi-notes.html>)


### Abbreviations

- LVCSR - Large Vocabulary Continuous Speech Recognition
- HMM - Hidden Markov Models
- AM - Acoustic Model
- LM - Language Model


### Data Requirements

The following are the data requirements for any ASR system

- **Labeled Corpus**: Collection of speech audio files and their transcriptions
- **Lexicon**: Mapping from the word to the series of phones to describe how the word is pronounced.
Not necessary for phonetically written languages like Kannada.
- **Data for training Language Model**: Large text corpus (to train a statistical language model) in case we are looking to train an ASR system to handle generic/natural language inputs.
If we are looking at constrained ASR systems that are only capable of transcribing a certain set of grammar rules (like PAN numbers, telephone numbers etc),
we can directly write the grammar rules without training a statistical LM and hence this requirement is flexible.

### Bayes Rule in ASR

Any ASR follows the following principle.

$$P(S|audio) = \frac{P(audio|S)P(S)}{P(audio)}$$

Here, $$P(S)$$ is the LM and $$S$$ is the sentence.

$$P(audio)$$ is irrelevant since we are taking argmax.
$$P(audio|S)$$ is the Acoustic Model. This describes distribution over the acoustic observations $$audio$$ given the word sequence $$S$$.

This equation is called as the **Fundamental Equation of Speech Recognition**

