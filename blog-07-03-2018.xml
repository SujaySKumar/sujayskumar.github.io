<?xml version='1.0' encoding='UTF-8'?><?xml-stylesheet href="https://www.blogger.com/styles/atom.css" type="text/css"?><feed xmlns='http://www.w3.org/2005/Atom' xmlns:openSearch='http://a9.com/-/spec/opensearchrss/1.0/' xmlns:gd='http://schemas.google.com/g/2005' xmlns:thr='http://purl.org/syndication/thread/1.0' xmlns:georss='http://www.georss.org/georss'><id>tag:blogger.com,1999:blog-925060870564624560.archive</id><updated>2018-06-30T00:52:21.694-07:00</updated><title type='text'>Machine Learning and Data Science</title><link rel='http://schemas.google.com/g/2005#feed' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/archive'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/archive'/><link rel='http://schemas.google.com/g/2005#post' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/archive'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><generator version='7.00' uri='https://www.blogger.com'>Blogger</generator><entry><id>tag:blogger.com,1999:blog-925060870564624560.layout</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#template'/><title type='text'>Template: Machine Learning and Data Science</title><content type='text'>&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
&lt;!DOCTYPE html&gt;
&lt;html b:version='2' class='v2' expr:dir='data:blog.languageDirection' expr:lang='data:blog.locale' xmlns='http://www.w3.org/1999/xhtml' xmlns:b='http://www.google.com/2005/gml/b' xmlns:data='http://www.google.com/2005/gml/data' xmlns:expr='http://www.google.com/2005/gml/expr'&gt;
  &lt;head&gt;
    &lt;meta expr:content='data:blog.isMobile         ? &amp;quot;width=device-width,initial-scale=1.0,minimum-scale=1.0,maximum-scale=1.0&amp;quot;         : &amp;quot;width=1100&amp;quot;' name='viewport'/&gt;
    &lt;b:include data='blog' name='all-head-content'/&gt;
    &lt;title&gt;&lt;data:blog.pageTitle/&gt;&lt;/title&gt;

    &lt;b:skin&gt;&lt;![CDATA[/*
-----------------------------------------------
Blogger Template Style
Name:     Simple
Designer: Blogger
URL:      www.blogger.com
----------------------------------------------- */

/* Variable definitions
   ====================
   &lt;Variable name="keycolor" description="Main Color" type="color" default="#66bbdd" value="#66bbdd"/&gt;

   &lt;Group description="Page Text" selector="body"&gt;
     &lt;Variable name="body.font" description="Font" type="font"
         default="normal normal 12px Arial, Tahoma, Helvetica, FreeSans, sans-serif" value="normal normal 16px PT Sans"/&gt;
     &lt;Variable name="body.text.color" description="Text Color" type="color" default="#222222" value="#666666"/&gt;
   &lt;/Group&gt;

   &lt;Group description="Backgrounds" selector=".body-fauxcolumns-outer"&gt;
     &lt;Variable name="body.background.color" description="Outer Background" type="color" default="#66bbdd" value="#f5f5f5"/&gt;
     &lt;Variable name="content.background.color" description="Main Background" type="color" default="#ffffff" value="#ffffff"/&gt;
     &lt;Variable name="header.background.color" description="Header Background" type="color" default="transparent" value="transparent"/&gt;
   &lt;/Group&gt;

   &lt;Group description="Links" selector=".main-outer"&gt;
     &lt;Variable name="link.color" description="Link Color" type="color" default="#2288bb" value="#2288bb"/&gt;
     &lt;Variable name="link.visited.color" description="Visited Color" type="color" default="#888888" value="#2288bb"/&gt;
     &lt;Variable name="link.hover.color" description="Hover Color" type="color" default="#33aaff" value="#33aaff"/&gt;
   &lt;/Group&gt;

   &lt;Group description="Blog Title" selector=".header h1"&gt;
     &lt;Variable name="header.font" description="Font" type="font"
         default="normal normal 60px Arial, Tahoma, Helvetica, FreeSans, sans-serif" value="normal normal 50px Roboto"/&gt;
     &lt;Variable name="header.text.color" description="Title Color" type="color" default="#3399bb"  value="#2288bb"/&gt;
   &lt;/Group&gt;

   &lt;Group description="Blog Description" selector=".header .description"&gt;
     &lt;Variable name="description.text.color" description="Description Color" type="color"
         default="#777777"  value="#777777"/&gt;
   &lt;/Group&gt;

   &lt;Group description="Tabs Text" selector=".tabs-inner .widget li a"&gt;
     &lt;Variable name="tabs.font" description="Font" type="font"
         default="normal normal 14px Arial, Tahoma, Helvetica, FreeSans, sans-serif" value="normal normal 14px Roboto"/&gt;
     &lt;Variable name="tabs.text.color" description="Text Color" type="color" default="#999999" value="#999999"/&gt;
     &lt;Variable name="tabs.selected.text.color" description="Selected Color" type="color" default="#000000" value="#000000"/&gt;
   &lt;/Group&gt;

   &lt;Group description="Tabs Background" selector=".tabs-outer .PageList"&gt;
     &lt;Variable name="tabs.background.color" description="Background Color" type="color" default="#f5f5f5" value="#f5f5f5"/&gt;
     &lt;Variable name="tabs.selected.background.color" description="Selected Color" type="color" default="#eeeeee" value="#eeeeee"/&gt;
   &lt;/Group&gt;

   &lt;Group description="Post Title" selector="h3.post-title, .comments h4"&gt;
     &lt;Variable name="post.title.font" description="Font" type="font"
         default="normal normal 22px Arial, Tahoma, Helvetica, FreeSans, sans-serif" value="normal normal 22px Arial, Tahoma, Helvetica, FreeSans, sans-serif"/&gt;
   &lt;/Group&gt;

   &lt;Group description="Date Header" selector=".date-header"&gt;
     &lt;Variable name="date.header.color" description="Text Color" type="color"
         default="$(body.text.color)" value="#666666"/&gt;
     &lt;Variable name="date.header.background.color" description="Background Color" type="color"
         default="transparent" value="transparent"/&gt;
     &lt;Variable name="date.header.font" description="Text Font" type="font"
         default="normal bold 11px Arial, Tahoma, Helvetica, FreeSans, sans-serif" value="normal bold 11px Arial, Tahoma, Helvetica, FreeSans, sans-serif"/&gt;
     &lt;Variable name="date.header.padding" description="Date Header Padding" type="string" default="inherit" value="inherit"/&gt;
     &lt;Variable name="date.header.letterspacing" description="Date Header Letter Spacing" type="string" default="inherit" value="inherit"/&gt;
     &lt;Variable name="date.header.margin" description="Date Header Margin" type="string" default="inherit" value="inherit"/&gt;
   &lt;/Group&gt;

   &lt;Group description="Post Footer" selector=".post-footer"&gt;
     &lt;Variable name="post.footer.text.color" description="Text Color" type="color" default="#666666" value="#666666"/&gt;
     &lt;Variable name="post.footer.background.color" description="Background Color" type="color"
         default="#f9f9f9" value="#f9f9f9"/&gt;
     &lt;Variable name="post.footer.border.color" description="Shadow Color" type="color" default="#eeeeee" value="#eeeeee"/&gt;
   &lt;/Group&gt;

   &lt;Group description="Gadgets" selector="h2"&gt;
     &lt;Variable name="widget.title.font" description="Title Font" type="font"
         default="normal bold 11px Arial, Tahoma, Helvetica, FreeSans, sans-serif" value="normal bold 11px Arial, Tahoma, Helvetica, FreeSans, sans-serif"/&gt;
     &lt;Variable name="widget.title.text.color" description="Title Color" type="color" default="#000000" value="#000000"/&gt;
     &lt;Variable name="widget.alternate.text.color" description="Alternate Color" type="color" default="#999999" value="#999999"/&gt;
   &lt;/Group&gt;

   &lt;Group description="Images" selector=".main-inner"&gt;
     &lt;Variable name="image.background.color" description="Background Color" type="color" default="#ffffff" value="#ffffff"/&gt;
     &lt;Variable name="image.border.color" description="Border Color" type="color" default="#eeeeee" value="#eeeeee"/&gt;
     &lt;Variable name="image.text.color" description="Caption Text Color" type="color" default="$(body.text.color)" value="#666666"/&gt;
   &lt;/Group&gt;

   &lt;Group description="Accents" selector=".content-inner"&gt;
     &lt;Variable name="body.rule.color" description="Separator Line Color" type="color" default="#eeeeee" value="#eeeeee"/&gt;
     &lt;Variable name="tabs.border.color" description="Tabs Border Color" type="color" default="$(body.rule.color)" value="#eeeeee"/&gt;
   &lt;/Group&gt;

   &lt;Variable name="body.background" description="Body Background" type="background"
       color="$(body.background.color)" default="$(color) none repeat scroll top left" value="$(color) none repeat scroll top left"/&gt;
   &lt;Variable name="body.background.override" description="Body Background Override" type="string" default="" value=""/&gt;

   &lt;Variable name="body.background.gradient.cap" description="Body Gradient Cap" type="url"
       default="url(https://resources.blogblog.com/blogblog/data/1kt/simple/gradients_light.png)" value="url(https://resources.blogblog.com/blogblog/data/1kt/simple/gradients_light.png)"/&gt;
   &lt;Variable name="body.background.gradient.tile" description="Body Gradient Tile" type="url"
       default="url(https://resources.blogblog.com/blogblog/data/1kt/simple/body_gradient_tile_light.png)" value="url(https://resources.blogblog.com/blogblog/data/1kt/simple/body_gradient_tile_light.png)"/&gt;

   &lt;Variable name="content.background.color.selector" description="Content Background Color Selector" type="string" default=".content-inner" value=".content-inner"/&gt;
   &lt;Variable name="content.padding" description="Content Padding" type="length" default="10px" min="0" max="100px" value="10px"/&gt;
   &lt;Variable name="content.padding.horizontal" description="Content Horizontal Padding" type="length" default="$(content.padding)" min="0" max="100px" value="10px"/&gt;
   &lt;Variable name="content.shadow.spread" description="Content Shadow Spread" type="length" default="40px" min="0" max="100px" value="40px"/&gt;
   &lt;Variable name="content.shadow.spread.webkit" description="Content Shadow Spread (WebKit)" type="length" default="5px" min="0" max="100px" value="5px"/&gt;
   &lt;Variable name="content.shadow.spread.ie" description="Content Shadow Spread (IE)" type="length" default="10px" min="0" max="100px" value="10px"/&gt;

   &lt;Variable name="main.border.width" description="Main Border Width" type="length" default="0" min="0" max="10px" value="0"/&gt;

   &lt;Variable name="header.background.gradient" description="Header Gradient" type="url" default="none" value="none"/&gt;
   &lt;Variable name="header.shadow.offset.left" description="Header Shadow Offset Left" type="length" default="-1px" min="-50px" max="50px" value="-1px"/&gt;
   &lt;Variable name="header.shadow.offset.top" description="Header Shadow Offset Top" type="length" default="-1px" min="-50px" max="50px" value="-1px"/&gt;
   &lt;Variable name="header.shadow.spread" description="Header Shadow Spread" type="length" default="1px" min="0" max="100px" value="1px"/&gt;
   &lt;Variable name="header.padding" description="Header Padding" type="length" default="30px" min="0" max="100px" value="30px"/&gt;

   &lt;Variable name="header.border.size" description="Header Border Size" type="length" default="1px" min="0" max="10px" value="1px"/&gt;
   &lt;Variable name="header.bottom.border.size" description="Header Bottom Border Size" type="length" default="$(header.border.size)" min="0" max="10px" value="1px"/&gt;
   &lt;Variable name="header.border.horizontalsize" description="Header Horizontal Border Size" type="length" default="0" min="0" max="10px" value="0"/&gt;

   &lt;Variable name="description.text.size" description="Description Text Size" type="string" default="140%" value="140%"/&gt;

   &lt;Variable name="tabs.margin.top" description="Tabs Margin Top" type="length" default="0" min="0" max="100px" value="0"/&gt;
   &lt;Variable name="tabs.margin.side" description="Tabs Side Margin" type="length" default="30px" min="0" max="100px" value="30px"/&gt;
   &lt;Variable name="tabs.background.gradient" description="Tabs Background Gradient" type="url"
       default="url(https://resources.blogblog.com/blogblog/data/1kt/simple/gradients_light.png)" value="url(https://resources.blogblog.com/blogblog/data/1kt/simple/gradients_light.png)"/&gt;
   &lt;Variable name="tabs.border.width" description="Tabs Border Width" type="length" default="1px" min="0" max="10px" value="1px"/&gt;
   &lt;Variable name="tabs.bevel.border.width" description="Tabs Bevel Border Width" type="length" default="1px" min="0" max="10px" value="1px"/&gt;

   &lt;Variable name="post.margin.bottom" description="Post Bottom Margin" type="length" default="25px" min="0" max="100px" value="25px"/&gt;

   &lt;Variable name="image.border.small.size" description="Image Border Small Size" type="length" default="2px" min="0" max="10px" value="2px"/&gt;
   &lt;Variable name="image.border.large.size" description="Image Border Large Size" type="length" default="5px" min="0" max="10px" value="5px"/&gt;

   &lt;Variable name="page.width.selector" description="Page Width Selector" type="string" default=".region-inner" value=".region-inner"/&gt;
   &lt;Variable name="page.width" description="Page Width" type="string" default="auto" value="auto"/&gt;

   &lt;Variable name="main.section.margin" description="Main Section Margin" type="length" default="15px" min="0" max="100px" value="15px"/&gt;
   &lt;Variable name="main.padding" description="Main Padding" type="length" default="15px" min="0" max="100px" value="15px"/&gt;
   &lt;Variable name="main.padding.top" description="Main Padding Top" type="length" default="30px" min="0" max="100px" value="30px"/&gt;
   &lt;Variable name="main.padding.bottom" description="Main Padding Bottom" type="length" default="30px" min="0" max="100px" value="30px"/&gt;

   &lt;Variable name="paging.background"
       color="$(content.background.color)"
       description="Background of blog paging area" type="background"
       default="transparent none no-repeat scroll top center" value="transparent none no-repeat scroll top center"/&gt;

   &lt;Variable name="footer.bevel" description="Bevel border length of footer" type="length" default="0" min="0" max="10px" value="0"/&gt;

   &lt;Variable name="mobile.background.overlay" description="Mobile Background Overlay" type="string"
       default="transparent none repeat scroll top left" value="transparent none repeat scroll top left"/&gt;
   &lt;Variable name="mobile.background.size" description="Mobile Background Size" type="string" default="auto" value="auto"/&gt;
   &lt;Variable name="mobile.button.color" description="Mobile Button Color" type="color" default="#ffffff"  value="#ffffff"/&gt;

   &lt;Variable name="startSide" description="Side where text starts in blog language" type="automatic" default="left"/&gt;
   &lt;Variable name="endSide" description="Side where text ends in blog language" type="automatic" default="right"/&gt;
*/

/* Content
----------------------------------------------- */
body {
  font: $(body.font);
  color: $(body.text.color);
  background: $(body.background);
  padding: 0 $(content.shadow.spread) $(content.shadow.spread) $(content.shadow.spread);
  $(body.background.override)
}

html body $(page.width.selector) {
  min-width: 0;
  max-width: 100%;
  width: $(page.width);
}

h2 {
  font-size: 22px;
}

a:link {
  text-decoration:none;
  color: $(link.color);
}

a:visited {
  text-decoration:none;
  color: $(link.visited.color);
}

a:hover {
  text-decoration:underline;
  color: $(link.hover.color);
}

.body-fauxcolumn-outer .fauxcolumn-inner {
  background: transparent $(body.background.gradient.tile) repeat scroll top left;
  _background-image: none;
}

.body-fauxcolumn-outer .cap-top {
  position: absolute;
  z-index: 1;
  height: 400px;
  width: 100%;
}

.body-fauxcolumn-outer .cap-top .cap-left {
  width: 100%;
  background: transparent $(body.background.gradient.cap) repeat-x scroll top left;
  _background-image: none;
}

.content-outer {
  -moz-box-shadow: 0 0 $(content.shadow.spread) rgba(0, 0, 0, .15);
  -webkit-box-shadow: 0 0 $(content.shadow.spread.webkit) rgba(0, 0, 0, .15);
  -goog-ms-box-shadow: 0 0 $(content.shadow.spread.ie) #333333;
  box-shadow: 0 0 $(content.shadow.spread) rgba(0, 0, 0, .15);

  margin-bottom: 1px;
}

.content-inner {
  padding: $(content.padding) $(content.padding.horizontal);
}

$(content.background.color.selector) {
  background-color: $(content.background.color);
}

/* Header
----------------------------------------------- */
.header-outer {
  background: $(header.background.color) $(header.background.gradient) repeat-x scroll 0 -400px;
  _background-image: none;
}

.Header h1 {
  font: $(header.font);
  color: $(header.text.color);
  text-shadow: $(header.shadow.offset.left) $(header.shadow.offset.top) $(header.shadow.spread) rgba(0, 0, 0, .2);
}

.Header h1 a {
  color: $(header.text.color);
}

.Header .description {
  font-size: $(description.text.size);
  color: $(description.text.color);
}

.header-inner .Header .titlewrapper {
  padding: 22px $(header.padding);
}

.header-inner .Header .descriptionwrapper {
  padding: 0 $(header.padding);
}

/* Tabs
----------------------------------------------- */
.tabs-inner .section:first-child {
  border-top: $(header.bottom.border.size) solid $(tabs.border.color);
}

.tabs-inner .section:first-child ul {
  margin-top: -$(header.border.size);
  border-top: $(header.border.size) solid $(tabs.border.color);
  border-left: $(header.border.horizontalsize) solid $(tabs.border.color);
  border-right: $(header.border.horizontalsize) solid $(tabs.border.color);
}

.tabs-inner .widget ul {
  background: $(tabs.background.color) $(tabs.background.gradient) repeat-x scroll 0 -800px;
  _background-image: none;
  border-bottom: $(tabs.border.width) solid $(tabs.border.color);

  margin-top: $(tabs.margin.top);
  margin-left: -$(tabs.margin.side);
  margin-right: -$(tabs.margin.side);
}

.tabs-inner .widget li a {
  display: inline-block;

  padding: .6em 1em;

  font: $(tabs.font);
  color: $(tabs.text.color);

  border-$startSide: $(tabs.border.width) solid $(content.background.color);
  border-$endSide: $(tabs.bevel.border.width) solid $(tabs.border.color);
}

.tabs-inner .widget li:first-child a {
  border-$startSide: none;
}

.tabs-inner .widget li.selected a, .tabs-inner .widget li a:hover {
  color: $(tabs.selected.text.color);
  background-color: $(tabs.selected.background.color);
  text-decoration: none;
}

/* Columns
----------------------------------------------- */
.main-outer {
  border-top: $(main.border.width) solid $(body.rule.color);
}

.fauxcolumn-left-outer .fauxcolumn-inner {
  border-right: 1px solid $(body.rule.color);
}

.fauxcolumn-right-outer .fauxcolumn-inner {
  border-left: 1px solid $(body.rule.color);
}

/* Headings
----------------------------------------------- */
div.widget &gt; h2,
div.widget h2.title {
  margin: 0 0 1em 0;

  font: $(widget.title.font);
  color: $(widget.title.text.color);
}

/* Widgets
----------------------------------------------- */
.widget .zippy {
  color: $(widget.alternate.text.color);
  text-shadow: 2px 2px 1px rgba(0, 0, 0, .1);
}

.widget .popular-posts ul {
  list-style: none;
}

/* Posts
----------------------------------------------- */
h2.date-header {
  font: $(date.header.font);
}

.date-header span {
  background-color: $(date.header.background.color);
  color: $(date.header.color);
  padding: $(date.header.padding);
  letter-spacing: $(date.header.letterspacing);
  margin: $(date.header.margin);
}

.main-inner {
  padding-top: $(main.padding.top);
  padding-bottom: $(main.padding.bottom);
}

.main-inner .column-center-inner {
  padding: 0 $(main.padding);
}

.main-inner .column-center-inner .section {
  margin: 0 $(main.section.margin);
}

.post {
  margin: 0 0 $(post.margin.bottom) 0;
}

h3.post-title, .comments h4 {
  font: $(post.title.font);
  margin: .75em 0 0;
}

.post-body {
  font-size: 110%;
  line-height: 1.4;
  position: relative;
}

.post-body img, .post-body .tr-caption-container, .Profile img, .Image img,
.BlogList .item-thumbnail img {
  padding: $(image.border.small.size);

  background: $(image.background.color);
  border: 1px solid $(image.border.color);

  -moz-box-shadow: 1px 1px 5px rgba(0, 0, 0, .1);
  -webkit-box-shadow: 1px 1px 5px rgba(0, 0, 0, .1);
  box-shadow: 1px 1px 5px rgba(0, 0, 0, .1);
}

.post-body img, .post-body .tr-caption-container {
  padding: $(image.border.large.size);
}

.post-body .tr-caption-container {
  color: $(image.text.color);
}

.post-body .tr-caption-container img {
  padding: 0;

  background: transparent;
  border: none;

  -moz-box-shadow: 0 0 0 rgba(0, 0, 0, .1);
  -webkit-box-shadow: 0 0 0 rgba(0, 0, 0, .1);
  box-shadow: 0 0 0 rgba(0, 0, 0, .1);
}

.post-header {
  margin: 0 0 1.5em;

  line-height: 1.6;
  font-size: 90%;
}

.post-footer {
  margin: 20px -2px 0;
  padding: 5px 10px;

  color: $(post.footer.text.color);
  background-color: $(post.footer.background.color);
  border-bottom: 1px solid $(post.footer.border.color);

  line-height: 1.6;
  font-size: 90%;
}

#comments .comment-author {
  padding-top: 1.5em;

  border-top: 1px solid $(body.rule.color);
  background-position: 0 1.5em;
}

#comments .comment-author:first-child {
  padding-top: 0;
  border-top: none;
}

.avatar-image-container {
  margin: .2em 0 0;
}

#comments .avatar-image-container img {
  border: 1px solid $(image.border.color);
}

/* Comments
----------------------------------------------- */
.comments .comments-content .icon.blog-author {
  background-repeat: no-repeat;
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAASCAYAAABWzo5XAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEgAACxIB0t1+/AAAAAd0SU1FB9sLFwMeCjjhcOMAAAD+SURBVDjLtZSvTgNBEIe/WRRnm3U8RC1neQdsm1zSBIU9VVF1FkUguQQsD9ITmD7ECZIJSE4OZo9stoVjC/zc7ky+zH9hXwVwDpTAWWLrgS3QAe8AZgaAJI5zYAmc8r0G4AHYHQKVwII8PZrZFsBFkeRCABYiMh9BRUhnSkPTNCtVXYXURi1FpBDgArj8QU1eVXUzfnjv7yP7kwu1mYrkWlU33vs1QNu2qU8pwN0UpKoqokjWwCztrMuBhEhmh8bD5UDqur75asbcX0BGUB9/HAMB+r32hznJgXy2v0sGLBcyAJ1EK3LFcbo1s91JeLwAbwGYu7TP/3ZGfnXYPgAVNngtqatUNgAAAABJRU5ErkJggg==);
}

.comments .comments-content .loadmore a {
  border-top: 1px solid $(widget.alternate.text.color);
  border-bottom: 1px solid $(widget.alternate.text.color);
}

.comments .comment-thread.inline-thread {
  background-color: $(post.footer.background.color);
}

.comments .continue {
  border-top: 2px solid $(widget.alternate.text.color);
}

/* Accents
---------------------------------------------- */
.section-columns td.columns-cell {
  border-$startSide: 1px solid $(body.rule.color);
}

.blog-pager {
  background: $(paging.background);
}

.blog-pager-older-link, .home-link,
.blog-pager-newer-link {
  background-color: $(content.background.color);
  padding: 5px;
}

.footer-outer {
  border-top: $(footer.bevel) dashed #bbbbbb;
}

/* Mobile
----------------------------------------------- */
body.mobile  {
  background-size: $(mobile.background.size);
}

.mobile .body-fauxcolumn-outer {
  background: $(mobile.background.overlay);
}

.mobile .body-fauxcolumn-outer .cap-top {
  background-size: 100% auto;
}

.mobile .content-outer {
  -webkit-box-shadow: 0 0 3px rgba(0, 0, 0, .15);
  box-shadow: 0 0 3px rgba(0, 0, 0, .15);
}

.mobile .tabs-inner .widget ul {
  margin-left: 0;
  margin-right: 0;
}

.mobile .post {
  margin: 0;
}

.mobile .main-inner .column-center-inner .section {
  margin: 0;
}

.mobile .date-header span {
  padding: 0.1em 10px;
  margin: 0 -10px;
}

.mobile h3.post-title {
  margin: 0;
}

.mobile .blog-pager {
  background: transparent none no-repeat scroll top center;
}

.mobile .footer-outer {
  border-top: none;
}

.mobile .main-inner, .mobile .footer-inner {
  background-color: $(content.background.color);
}

.mobile-index-contents {
  color: $(body.text.color);
}

.mobile-link-button {
  background-color: $(link.color);
}

.mobile-link-button a:link, .mobile-link-button a:visited {
  color: $(mobile.button.color);
}

.mobile .tabs-inner .section:first-child {
  border-top: none;
}

.mobile .tabs-inner .PageList .widget-content {
  background-color: $(tabs.selected.background.color);
  color: $(tabs.selected.text.color);
  border-top: $(tabs.border.width) solid $(tabs.border.color);
  border-bottom: $(tabs.border.width) solid $(tabs.border.color);
}

.mobile .tabs-inner .PageList .widget-content .pagelist-arrow {
  border-$startSide: 1px solid $(tabs.border.color);
}
]]&gt;&lt;/b:skin&gt;

    &lt;b:template-skin&gt;
      &lt;b:variable default='960px' name='content.width' type='length' value='1200px'/&gt;
      &lt;b:variable default='0' name='main.column.left.width' type='length' value='0px'/&gt;
      &lt;b:variable default='310px' name='main.column.right.width' type='length' value='320px'/&gt;

      &lt;![CDATA[
      body {
        min-width: $(content.width);
      }

      .content-outer, .content-fauxcolumn-outer, .region-inner {
        min-width: $(content.width);
        max-width: $(content.width);
        _width: $(content.width);
      }

      .main-inner .columns {
        padding-left: $(main.column.left.width);
        padding-right: $(main.column.right.width);
      }

      .main-inner .fauxcolumn-center-outer {
        left: $(main.column.left.width);
        right: $(main.column.right.width);
        /* IE6 does not respect left and right together */
        _width: expression(this.parentNode.offsetWidth -
            parseInt("$(main.column.left.width)") -
            parseInt("$(main.column.right.width)") + 'px');
      }

      .main-inner .fauxcolumn-left-outer {
        width: $(main.column.left.width);
      }

      .main-inner .fauxcolumn-right-outer {
        width: $(main.column.right.width);
      }

      .main-inner .column-left-outer {
        width: $(main.column.left.width);
        right: 100%;
        margin-left: -$(main.column.left.width);
      }

      .main-inner .column-right-outer {
        width: $(main.column.right.width);
        margin-right: -$(main.column.right.width);
      }

      #layout {
        min-width: 0;
      }

      #layout .content-outer {
        min-width: 0;
        width: 800px;
      }

      #layout .region-inner {
        min-width: 0;
        width: auto;
      }

      body#layout div.add_widget {
        padding: 8px;
      }

      body#layout div.add_widget a {
        margin-left: 32px;
      }
      ]]&gt;
    &lt;/b:template-skin&gt;

    &lt;b:if cond='data:skin.vars.body_background.image.isResizable'&gt;
      &lt;b:include cond='not data:view.isPreview' data='{                          image: data:skin.vars.body_background.image,                          selector: &amp;quot;body&amp;quot;                        }' name='responsiveImageStyle'/&gt;
    &lt;/b:if&gt;

    &lt;b:include data='blog' name='google-analytics'/&gt;
  &lt;/head&gt;

  &lt;body expr:class='&amp;quot;loading&amp;quot; + data:blog.mobileClass'&gt;
  &lt;b:section class='navbar' id='navbar' maxwidgets='1' name='Navbar' showaddelement='no'&gt;
    &lt;b:widget id='Navbar1' locked='true' title='Navbar' type='Navbar'&gt;
      &lt;b:includable id='main'&gt;&amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
    function setAttributeOnload(object, attribute, val) {
      if(window.addEventListener) {
        window.addEventListener(&amp;#39;load&amp;#39;,
          function(){ object[attribute] = val; }, false);
      } else {
        window.attachEvent(&amp;#39;onload&amp;#39;, function(){ object[attribute] = val; });
      }
    }
  &amp;lt;/script&amp;gt;
&amp;lt;div id=&amp;quot;navbar-iframe-container&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script type=&amp;quot;text/javascript&amp;quot; src=&amp;quot;https://apis.google.com/js/plusone.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
      gapi.load(&amp;quot;gapi.iframes:gapi.iframes.style.bubble&amp;quot;, function() {
        if (gapi.iframes &amp;amp;&amp;amp; gapi.iframes.getContext) {
          gapi.iframes.getContext().openChild({
              url: &amp;#39;https://www.blogger.com/navbar.g?targetBlogID\x3d925060870564624560\x26blogName\x3dMachine+Learning+and+Data+Science\x26publishMode\x3dPUBLISH_MODE_BLOGSPOT\x26navbarType\x3dLIGHT\x26layoutType\x3dLAYOUTS\x26searchRoot\x3dhttps://sujayskumar.blogspot.com/search\x26blogLocale\x3den\x26v\x3d2\x26homepageUrl\x3dhttps://sujayskumar.blogspot.com/\x26vt\x3d2039586015777461497&amp;#39;,
              where: document.getElementById(&amp;quot;navbar-iframe-container&amp;quot;),
              id: &amp;quot;navbar-iframe&amp;quot;
          });
        }
      });
    &amp;lt;/script&amp;gt;&amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
(function() {
var script = document.createElement(&amp;#39;script&amp;#39;);
script.type = &amp;#39;text/javascript&amp;#39;;
script.src = &amp;#39;//pagead2.googlesyndication.com/pagead/js/google_top_exp.js&amp;#39;;
var head = document.getElementsByTagName(&amp;#39;head&amp;#39;)[0];
if (head) {
head.appendChild(script);
}})();
&amp;lt;/script&amp;gt;
&lt;/b:includable&gt;
    &lt;/b:widget&gt;
  &lt;/b:section&gt;

  &lt;b:if cond='data:blog.pageType == &amp;quot;index&amp;quot;'&gt;
    &lt;div itemscope='itemscope' itemtype='http://schema.org/Blog' style='display: none;'&gt;
      &lt;meta expr:content='data:blog.title' itemprop='name'/&gt;
      &lt;b:if cond='data:blog.metaDescription'&gt;
        &lt;meta expr:content='data:blog.metaDescription' itemprop='description'/&gt;
      &lt;/b:if&gt;
    &lt;/div&gt;
  &lt;/b:if&gt;

  &lt;div class='body-fauxcolumns'&gt;
    &lt;div class='fauxcolumn-outer body-fauxcolumn-outer'&gt;
    &lt;div class='cap-top'&gt;
      &lt;div class='cap-left'/&gt;
      &lt;div class='cap-right'/&gt;
    &lt;/div&gt;
    &lt;div class='fauxborder-left'&gt;
    &lt;div class='fauxborder-right'/&gt;
    &lt;div class='fauxcolumn-inner'&gt;
    &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class='cap-bottom'&gt;
      &lt;div class='cap-left'/&gt;
      &lt;div class='cap-right'/&gt;
    &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;

  &lt;div class='content'&gt;
  &lt;div class='content-fauxcolumns'&gt;
    &lt;div class='fauxcolumn-outer content-fauxcolumn-outer'&gt;
    &lt;div class='cap-top'&gt;
      &lt;div class='cap-left'/&gt;
      &lt;div class='cap-right'/&gt;
    &lt;/div&gt;
    &lt;div class='fauxborder-left'&gt;
    &lt;div class='fauxborder-right'/&gt;
    &lt;div class='fauxcolumn-inner'&gt;
    &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class='cap-bottom'&gt;
      &lt;div class='cap-left'/&gt;
      &lt;div class='cap-right'/&gt;
    &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;

  &lt;div class='content-outer'&gt;
  &lt;div class='content-cap-top cap-top'&gt;
    &lt;div class='cap-left'/&gt;
    &lt;div class='cap-right'/&gt;
  &lt;/div&gt;
  &lt;div class='fauxborder-left content-fauxborder-left'&gt;
  &lt;div class='fauxborder-right content-fauxborder-right'/&gt;
  &lt;div class='content-inner'&gt;

    &lt;header&gt;
    &lt;div class='header-outer'&gt;
    &lt;div class='header-cap-top cap-top'&gt;
      &lt;div class='cap-left'/&gt;
      &lt;div class='cap-right'/&gt;
    &lt;/div&gt;
    &lt;div class='fauxborder-left header-fauxborder-left'&gt;
    &lt;div class='fauxborder-right header-fauxborder-right'/&gt;
    &lt;div class='region-inner header-inner'&gt;
      &lt;b:section class='header' id='header' maxwidgets='1' name='Header' showaddelement='no'&gt;
        &lt;b:widget id='Header1' locked='true' title='Machine Learning and Data Science (Header)' type='Header'&gt;
          &lt;b:widget-settings&gt;
            &lt;b:widget-setting name='displayUrl'/&gt;
            &lt;b:widget-setting name='displayHeight'&gt;0&lt;/b:widget-setting&gt;
            &lt;b:widget-setting name='sectionWidth'&gt;-1&lt;/b:widget-setting&gt;
            &lt;b:widget-setting name='useImage'&gt;false&lt;/b:widget-setting&gt;
            &lt;b:widget-setting name='shrinkToFit'&gt;false&lt;/b:widget-setting&gt;
            &lt;b:widget-setting name='imagePlacement'&gt;BEHIND&lt;/b:widget-setting&gt;
            &lt;b:widget-setting name='displayWidth'&gt;0&lt;/b:widget-setting&gt;
          &lt;/b:widget-settings&gt;
          &lt;b:includable id='main'&gt;

  &lt;b:if cond='data:useImage'&gt;
    &lt;b:if cond='data:imagePlacement == &amp;quot;BEHIND&amp;quot;'&gt;
      &lt;!--
      Show image as background to text. You can't really calculate the width
      reliably in JS because margins are not taken into account by any of
      clientWidth, offsetWidth or scrollWidth, so we don't force a minimum
      width if the user is using shrink to fit.
      This results in a margin-width's worth of pixels being cropped. If the
      user is not using shrink to fit then we expand the header.
      --&gt;
      &lt;b:if cond='data:mobile'&gt;
        &lt;div id='header-inner'&gt;
          &lt;div class='titlewrapper' style='background: transparent'&gt;
            &lt;h1 class='title' style='background: transparent; border-width: 0px'&gt;
              &lt;b:include name='title'/&gt;
            &lt;/h1&gt;
          &lt;/div&gt;
          &lt;b:include name='description'/&gt;
        &lt;/div&gt;
      &lt;b:else/&gt;
        &lt;div expr:style='&amp;quot;background-image: url(\&amp;quot;&amp;quot; + data:sourceUrl + &amp;quot;\&amp;quot;); &amp;quot;                      + &amp;quot;background-position: &amp;quot;                      + data:backgroundPositionStyleStr + &amp;quot;; &amp;quot;                      + data:widthStyleStr                      + &amp;quot;min-height: &amp;quot; + data:height                      + &amp;quot;_height: &amp;quot; + data:height                      + &amp;quot;background-repeat: no-repeat; &amp;quot;' id='header-inner'&gt;
          &lt;div class='titlewrapper' style='background: transparent'&gt;
            &lt;h1 class='title' style='background: transparent; border-width: 0px'&gt;
              &lt;b:include name='title'/&gt;
            &lt;/h1&gt;
          &lt;/div&gt;
          &lt;b:include name='description'/&gt;
        &lt;/div&gt;
      &lt;/b:if&gt;
    &lt;b:else/&gt;
      &lt;!--Show the image only--&gt;
      &lt;div id='header-inner'&gt;
        &lt;a expr:href='data:blog.homepageUrl' style='display: block'&gt;
          &lt;img expr:alt='data:title' expr:height='data:height' expr:id='data:widget.instanceId + &amp;quot;_headerimg&amp;quot;' expr:src='data:sourceUrl' expr:width='data:width' style='display: block'/&gt;
        &lt;/a&gt;
        &lt;!--Show the description--&gt;
        &lt;b:if cond='data:imagePlacement == &amp;quot;BEFORE_DESCRIPTION&amp;quot;'&gt;
          &lt;b:include name='description'/&gt;
        &lt;/b:if&gt;
      &lt;/div&gt;
    &lt;/b:if&gt;
  &lt;b:else/&gt;
    &lt;!--No header image --&gt;
    &lt;div id='header-inner'&gt;
      &lt;div class='titlewrapper'&gt;
        &lt;h1 class='title'&gt;
          &lt;b:include name='title'/&gt;
        &lt;/h1&gt;
      &lt;/div&gt;
      &lt;b:include name='description'/&gt;
    &lt;/div&gt;
  &lt;/b:if&gt;
&lt;/b:includable&gt;
          &lt;b:includable id='description'&gt;
  &lt;div class='descriptionwrapper'&gt;
    &lt;p class='description'&gt;&lt;span&gt;&lt;data:description/&gt;&lt;/span&gt;&lt;/p&gt;
  &lt;/div&gt;
&lt;/b:includable&gt;
          &lt;b:includable id='title'&gt;
  &lt;b:tag cond='data:blog.url != data:blog.homepageUrl' expr:href='data:blog.homepageUrl' name='a'&gt;
    &lt;data:title/&gt;
  &lt;/b:tag&gt;
&lt;/b:includable&gt;
        &lt;/b:widget&gt;
      &lt;/b:section&gt;
    &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class='header-cap-bottom cap-bottom'&gt;
      &lt;div class='cap-left'/&gt;
      &lt;div class='cap-right'/&gt;
    &lt;/div&gt;
    &lt;/div&gt;
    &lt;/header&gt;

    &lt;div class='tabs-outer'&gt;
    &lt;div class='tabs-cap-top cap-top'&gt;
      &lt;div class='cap-left'/&gt;
      &lt;div class='cap-right'/&gt;
    &lt;/div&gt;
    &lt;div class='fauxborder-left tabs-fauxborder-left'&gt;
    &lt;div class='fauxborder-right tabs-fauxborder-right'/&gt;
    &lt;div class='region-inner tabs-inner'&gt;
      &lt;b:section class='tabs' id='crosscol' maxwidgets='1' name='Cross-Column' showaddelement='yes'/&gt;
      &lt;b:section class='tabs' id='crosscol-overflow' name='Cross-Column 2' showaddelement='no'/&gt;
    &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class='tabs-cap-bottom cap-bottom'&gt;
      &lt;div class='cap-left'/&gt;
      &lt;div class='cap-right'/&gt;
    &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class='main-outer'&gt;
    &lt;div class='main-cap-top cap-top'&gt;
      &lt;div class='cap-left'/&gt;
      &lt;div class='cap-right'/&gt;
    &lt;/div&gt;

    &lt;div class='fauxborder-left main-fauxborder-left'&gt;
    &lt;div class='fauxborder-right main-fauxborder-right'/&gt;
    &lt;div class='region-inner main-inner'&gt;

      &lt;div class='columns fauxcolumns'&gt;

        &lt;div class='fauxcolumn-outer fauxcolumn-center-outer'&gt;
        &lt;div class='cap-top'&gt;
          &lt;div class='cap-left'/&gt;
          &lt;div class='cap-right'/&gt;
        &lt;/div&gt;
        &lt;div class='fauxborder-left'&gt;
        &lt;div class='fauxborder-right'/&gt;
        &lt;div class='fauxcolumn-inner'&gt;
        &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class='cap-bottom'&gt;
          &lt;div class='cap-left'/&gt;
          &lt;div class='cap-right'/&gt;
        &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class='fauxcolumn-outer fauxcolumn-left-outer'&gt;
        &lt;div class='cap-top'&gt;
          &lt;div class='cap-left'/&gt;
          &lt;div class='cap-right'/&gt;
        &lt;/div&gt;
        &lt;div class='fauxborder-left'&gt;
        &lt;div class='fauxborder-right'/&gt;
        &lt;div class='fauxcolumn-inner'&gt;
        &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class='cap-bottom'&gt;
          &lt;div class='cap-left'/&gt;
          &lt;div class='cap-right'/&gt;
        &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class='fauxcolumn-outer fauxcolumn-right-outer'&gt;
        &lt;div class='cap-top'&gt;
          &lt;div class='cap-left'/&gt;
          &lt;div class='cap-right'/&gt;
        &lt;/div&gt;
        &lt;div class='fauxborder-left'&gt;
        &lt;div class='fauxborder-right'/&gt;
        &lt;div class='fauxcolumn-inner'&gt;
        &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class='cap-bottom'&gt;
          &lt;div class='cap-left'/&gt;
          &lt;div class='cap-right'/&gt;
        &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- corrects IE6 width calculation --&gt;
        &lt;div class='columns-inner'&gt;

        &lt;div class='column-center-outer'&gt;
        &lt;div class='column-center-inner'&gt;
          &lt;b:section class='main' id='main' name='Main' showaddelement='no'&gt;
            &lt;b:widget id='Blog1' locked='true' title='Blog Posts' type='Blog'&gt;
              &lt;b:widget-settings&gt;
                &lt;b:widget-setting name='showDateHeader'&gt;true&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='style.textcolor'&gt;#666666&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='showShareButtons'&gt;true&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='showCommentLink'&gt;true&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='style.urlcolor'&gt;#666666&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='showAuthor'&gt;true&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='style.linkcolor'&gt;#2288bb&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='style.unittype'&gt;TextAndImage&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='style.bgcolor'&gt;#ffffff&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='showAuthorProfile'&gt;false&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='style.layout'&gt;1x1&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='showLabels'&gt;true&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='showLocation'&gt;true&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='showTimestamp'&gt;true&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='postsPerAd'&gt;1&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='showBacklinks'&gt;false&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='style.bordercolor'&gt;#ffffff&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='showInlineAds'&gt;false&lt;/b:widget-setting&gt;
                &lt;b:widget-setting name='showReactions'&gt;false&lt;/b:widget-setting&gt;
              &lt;/b:widget-settings&gt;
              &lt;b:includable id='main' var='top'&gt;
  &lt;b:if cond='!data:mobile'&gt;
    &lt;!-- posts --&gt;
    &lt;div class='blog-posts hfeed'&gt;

      &lt;b:include data='top' name='status-message'/&gt;

      &lt;b:loop values='data:posts' var='post'&gt;
        &lt;b:if cond='data:post.isDateStart and not data:post.isFirstPost'&gt;
          &amp;lt;/div&amp;gt;&amp;lt;/div&amp;gt;
        &lt;/b:if&gt;
        &lt;b:if cond='data:post.isDateStart'&gt;
          &amp;lt;div class=&amp;quot;date-outer&amp;quot;&amp;gt;
        &lt;/b:if&gt;
        &lt;b:if cond='data:post.dateHeader'&gt;
          &lt;h2 class='date-header'&gt;&lt;span&gt;&lt;data:post.dateHeader/&gt;&lt;/span&gt;&lt;/h2&gt;
        &lt;/b:if&gt;
        &lt;b:if cond='data:post.isDateStart'&gt;
          &amp;lt;div class=&amp;quot;date-posts&amp;quot;&amp;gt;
        &lt;/b:if&gt;
        &lt;div class='post-outer'&gt;
          &lt;b:include data='post' name='post'/&gt;
          &lt;b:include cond='data:blog.pageType in {&amp;quot;static_page&amp;quot;,&amp;quot;item&amp;quot;}' data='post' name='comment_picker'/&gt;
        &lt;/div&gt;

        &lt;!-- Ad --&gt;
        &lt;b:if cond='data:post.includeAd'&gt;
          &lt;div class='inline-ad'&gt;
            &lt;data:adCode/&gt;
          &lt;/div&gt;
        &lt;/b:if&gt;
      &lt;/b:loop&gt;
      &lt;b:if cond='data:numPosts != 0'&gt;
        &amp;lt;/div&amp;gt;&amp;lt;/div&amp;gt;
      &lt;/b:if&gt;
    &lt;/div&gt;

    &lt;!-- navigation --&gt;
    &lt;b:include name='nextprev'/&gt;

    &lt;!-- feed links --&gt;
    &lt;b:include name='feedLinks'/&gt;

  &lt;b:else/&gt;
    &lt;b:include name='mobile-main'/&gt;
  &lt;/b:if&gt;

  &lt;b:include cond='data:top.showPlusOne' name='googlePlusBootstrap'/&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='backlinkDeleteIcon' var='backlink'&gt;
  &lt;span expr:class='&amp;quot;item-control &amp;quot; + data:backlink.adminClass'&gt;
    &lt;a expr:href='data:backlink.deleteUrl' expr:title='data:top.deleteBacklinkMsg'&gt;
      &lt;img src='https://resources.blogblog.com/img/icon_delete13.gif'/&gt;
    &lt;/a&gt;
  &lt;/span&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='backlinks' var='post'&gt;
  &lt;a name='links'/&gt;&lt;h4&gt;&lt;data:post.backlinksLabel/&gt;&lt;/h4&gt;
  &lt;b:if cond='data:post.numBacklinks != 0'&gt;
    &lt;dl class='comments-block' id='comments-block'&gt;
      &lt;b:loop values='data:post.backlinks' var='backlink'&gt;
        &lt;div class='collapsed-backlink backlink-control'&gt;
          &lt;dt class='comment-title'&gt;
            &lt;span class='backlink-toggle-zippy'&gt;&amp;#160;&lt;/span&gt;
            &lt;a expr:href='data:backlink.url' rel='nofollow'&gt;&lt;data:backlink.title/&gt;&lt;/a&gt;
            &lt;b:include data='backlink' name='backlinkDeleteIcon'/&gt;
          &lt;/dt&gt;
          &lt;dd class='comment-body collapseable'&gt;
            &lt;data:backlink.snippet/&gt;
          &lt;/dd&gt;
          &lt;dd class='comment-footer collapseable'&gt;
            &lt;span class='comment-author'&gt;&lt;data:post.authorLabel/&gt; &lt;data:backlink.author/&gt;&lt;/span&gt;
            &lt;span class='comment-timestamp'&gt;&lt;data:post.timestampLabel/&gt; &lt;data:backlink.timestamp/&gt;&lt;/span&gt;
          &lt;/dd&gt;
        &lt;/div&gt;
      &lt;/b:loop&gt;
    &lt;/dl&gt;
  &lt;/b:if&gt;
  &lt;p class='comment-footer'&gt;
    &lt;a class='comment-link' expr:href='data:post.createLinkUrl' expr:id='data:widget.instanceId + &amp;quot;_backlinks-create-link&amp;quot;' target='_blank'&gt;&lt;data:post.createLinkLabel/&gt;&lt;/a&gt;
  &lt;/p&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='comment-form' var='post'&gt;
  &lt;div class='comment-form'&gt;
    &lt;a name='comment-form'/&gt;
    &lt;b:if cond='data:mobile'&gt;
      &lt;h4 id='comment-post-message'&gt;
        &lt;a expr:id='data:widget.instanceId + &amp;quot;_comment-editor-toggle-link&amp;quot;' href='javascript:void(0)'&gt;&lt;data:postCommentMsg/&gt;&lt;/a&gt;&lt;/h4&gt;
      &lt;p&gt;&lt;data:blogCommentMessage/&gt;&lt;/p&gt;
      &lt;data:blogTeamBlogMessage/&gt;
      &lt;a expr:href='data:post.commentFormIframeSrc' id='comment-editor-src'/&gt;
      &lt;iframe allowtransparency='true' class='blogger-iframe-colorize blogger-comment-from-post' expr:height='data:cmtIframeInitialHeight' frameborder='0' id='comment-editor' name='comment-editor' src='' style='display: none' width='100%'/&gt;
    &lt;b:else/&gt;
      &lt;h4 id='comment-post-message'&gt;&lt;data:postCommentMsg/&gt;&lt;/h4&gt;
      &lt;p&gt;&lt;data:blogCommentMessage/&gt;&lt;/p&gt;
      &lt;data:blogTeamBlogMessage/&gt;
      &lt;a expr:href='data:post.commentFormIframeSrc' id='comment-editor-src'/&gt;
      &lt;iframe allowtransparency='true' class='blogger-iframe-colorize blogger-comment-from-post' expr:height='data:cmtIframeInitialHeight' frameborder='0' id='comment-editor' name='comment-editor' src='' width='100%'/&gt;
    &lt;/b:if&gt;
    &lt;data:post.cmtfpIframe/&gt;
    &lt;script type='text/javascript'&gt;
      BLOG_CMT_createIframe(&amp;#39;&lt;data:post.appRpcRelayPath/&gt;&amp;#39;);
    &lt;/script&gt;
  &lt;/div&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='commentDeleteIcon' var='comment'&gt;
  &lt;span expr:class='&amp;quot;item-control &amp;quot; + data:comment.adminClass'&gt;
    &lt;b:if cond='data:showCmtPopup'&gt;
      &lt;div class='goog-toggle-button'&gt;
        &lt;div class='goog-inline-block comment-action-icon'/&gt;
      &lt;/div&gt;
    &lt;b:else/&gt;
      &lt;a class='comment-delete' expr:href='data:comment.deleteUrl' expr:title='data:top.deleteCommentMsg'&gt;
        &lt;img src='https://resources.blogblog.com/img/icon_delete13.gif'/&gt;
      &lt;/a&gt;
    &lt;/b:if&gt;
  &lt;/span&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='comment_count_picker' var='post'&gt;
  &lt;b:if cond='data:post.commentSource == 1'&gt;
    &lt;span class='cmt_count_iframe_holder' expr:data-count='data:post.numComments' expr:data-onclick='data:post.addCommentOnclick' expr:data-post-url='data:post.url' expr:data-url='data:post.url.canonical.http'&gt;
    &lt;/span&gt;
  &lt;b:else/&gt;
    &lt;a class='comment-link' expr:href='data:post.addCommentUrl' expr:onclick='data:post.addCommentOnclick'&gt;
      &lt;data:post.commentLabelFull/&gt;:
    &lt;/a&gt;
  &lt;/b:if&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='comment_picker' var='post'&gt;
  &lt;b:if cond='data:post.commentSource == 1'&gt;
    &lt;b:include data='post' name='iframe_comments'/&gt;
  &lt;b:elseif cond='data:post.showThreadedComments'/&gt;
    &lt;b:include data='post' name='threaded_comments'/&gt;
  &lt;b:else/&gt;
    &lt;b:include data='post' name='comments'/&gt;
  &lt;/b:if&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='comments' var='post'&gt;
  &lt;div class='comments' id='comments'&gt;
    &lt;a name='comments'/&gt;
    &lt;b:if cond='data:post.allowComments'&gt;
      &lt;h4&gt;&lt;data:post.commentLabelFull/&gt;:&lt;/h4&gt;

      &lt;b:if cond='data:post.commentPagingRequired'&gt;
        &lt;span class='paging-control-container'&gt;
          &lt;b:if cond='data:post.hasOlderLinks'&gt;
            &lt;a expr:class='data:post.oldLinkClass' expr:href='data:post.oldestLinkUrl'&gt;&lt;data:post.oldestLinkText/&gt;&lt;/a&gt;
              &amp;#160;
            &lt;a expr:class='data:post.oldLinkClass' expr:href='data:post.olderLinkUrl'&gt;&lt;data:post.olderLinkText/&gt;&lt;/a&gt;
              &amp;#160;
          &lt;/b:if&gt;

          &lt;data:post.commentRangeText/&gt;

          &lt;b:if cond='data:post.hasNewerLinks'&gt;
            &amp;#160;
            &lt;a expr:class='data:post.newLinkClass' expr:href='data:post.newerLinkUrl'&gt;&lt;data:post.newerLinkText/&gt;&lt;/a&gt;
            &amp;#160;
            &lt;a expr:class='data:post.newLinkClass' expr:href='data:post.newestLinkUrl'&gt;&lt;data:post.newestLinkText/&gt;&lt;/a&gt;
          &lt;/b:if&gt;
        &lt;/span&gt;
      &lt;/b:if&gt;

      &lt;div expr:id='data:widget.instanceId + &amp;quot;_comments-block-wrapper&amp;quot;'&gt;
        &lt;dl expr:class='data:post.avatarIndentClass' id='comments-block'&gt;
          &lt;b:loop values='data:post.comments' var='comment'&gt;
            &lt;dt expr:class='&amp;quot;comment-author &amp;quot; + data:comment.authorClass' expr:id='data:comment.anchorName'&gt;
              &lt;b:if cond='data:comment.favicon'&gt;
                &lt;img expr:src='data:comment.favicon' height='16px' style='margin-bottom:-2px;' width='16px'/&gt;
              &lt;/b:if&gt;
              &lt;a expr:name='data:comment.anchorName'/&gt;
              &lt;b:if cond='data:blog.enabledCommentProfileImages'&gt;
                &lt;data:comment.authorAvatarImage/&gt;
              &lt;/b:if&gt;
              &lt;b:if cond='data:comment.authorUrl'&gt;
                &lt;a expr:href='data:comment.authorUrl' rel='nofollow'&gt;&lt;data:comment.author/&gt;&lt;/a&gt;
              &lt;b:else/&gt;
                &lt;data:comment.author/&gt;
              &lt;/b:if&gt;
              &lt;data:commentPostedByMsg/&gt;
            &lt;/dt&gt;
            &lt;dd class='comment-body' expr:id='data:widget.instanceId + data:comment.cmtBodyIdPostfix'&gt;
              &lt;b:if cond='data:comment.isDeleted'&gt;
                &lt;span class='deleted-comment'&gt;&lt;data:comment.body/&gt;&lt;/span&gt;
              &lt;b:else/&gt;
                &lt;p&gt;
                  &lt;data:comment.body/&gt;
                &lt;/p&gt;
              &lt;/b:if&gt;
            &lt;/dd&gt;
            &lt;dd class='comment-footer'&gt;
              &lt;span class='comment-timestamp'&gt;
                &lt;a expr:href='data:comment.url' title='comment permalink'&gt;
                  &lt;data:comment.timestamp/&gt;
                &lt;/a&gt;
                &lt;b:include data='comment' name='commentDeleteIcon'/&gt;
              &lt;/span&gt;
            &lt;/dd&gt;
          &lt;/b:loop&gt;
        &lt;/dl&gt;
      &lt;/div&gt;

      &lt;b:if cond='data:post.commentPagingRequired'&gt;
        &lt;span class='paging-control-container'&gt;
          &lt;a expr:class='data:post.oldLinkClass' expr:href='data:post.oldestLinkUrl'&gt;
            &lt;data:post.oldestLinkText/&gt;
          &lt;/a&gt;
          &lt;a expr:class='data:post.oldLinkClass' expr:href='data:post.olderLinkUrl'&gt;
            &lt;data:post.olderLinkText/&gt;
          &lt;/a&gt;
          &amp;#160;
          &lt;data:post.commentRangeText/&gt;
          &amp;#160;
          &lt;a expr:class='data:post.newLinkClass' expr:href='data:post.newerLinkUrl'&gt;
            &lt;data:post.newerLinkText/&gt;
          &lt;/a&gt;
          &lt;a expr:class='data:post.newLinkClass' expr:href='data:post.newestLinkUrl'&gt;
            &lt;data:post.newestLinkText/&gt;
          &lt;/a&gt;
        &lt;/span&gt;
      &lt;/b:if&gt;

      &lt;p class='comment-footer'&gt;
        &lt;b:if cond='data:post.embedCommentForm'&gt;
          &lt;b:if cond='data:post.allowNewComments'&gt;
            &lt;b:include data='post' name='comment-form'/&gt;
          &lt;b:else/&gt;
            &lt;data:post.noNewCommentsText/&gt;
          &lt;/b:if&gt;
        &lt;b:elseif cond='data:post.allowComments'/&gt;
          &lt;a expr:href='data:post.addCommentUrl' expr:onclick='data:post.addCommentOnclick'&gt;&lt;data:postCommentMsg/&gt;&lt;/a&gt;
        &lt;/b:if&gt;
      &lt;/p&gt;
    &lt;/b:if&gt;
    &lt;b:if cond='data:showCmtPopup'&gt;
      &lt;div id='comment-popup'&gt;
        &lt;iframe allowtransparency='true' frameborder='0' id='comment-actions' name='comment-actions' scrolling='no'&gt;
        &lt;/iframe&gt;
      &lt;/div&gt;
    &lt;/b:if&gt;

    &lt;div id='backlinks-container'&gt;
    &lt;div expr:id='data:widget.instanceId + &amp;quot;_backlinks-container&amp;quot;'&gt;
       &lt;b:include cond='data:post.showBacklinks' data='post' name='backlinks'/&gt;
    &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='feedLinks'&gt;
  &lt;b:if cond='data:blog.pageType != &amp;quot;item&amp;quot;'&gt; &lt;!-- Blog feed links --&gt;
    &lt;b:if cond='data:feedLinks'&gt;
      &lt;div class='blog-feeds'&gt;
        &lt;b:include data='feedLinks' name='feedLinksBody'/&gt;
      &lt;/div&gt;
    &lt;/b:if&gt;

  &lt;b:else/&gt; &lt;!--Post feed links --&gt;
    &lt;div class='post-feeds'&gt;
      &lt;b:loop values='data:posts' var='post'&gt;
        &lt;b:include cond='data:post.allowComments and data:post.feedLinks' data='post.feedLinks' name='feedLinksBody'/&gt;
      &lt;/b:loop&gt;
    &lt;/div&gt;
  &lt;/b:if&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='feedLinksBody' var='links'&gt;
  &lt;div class='feed-links'&gt;
  &lt;data:feedLinksMsg/&gt;
  &lt;b:loop values='data:links' var='f'&gt;
     &lt;a class='feed-link' expr:href='data:f.url' expr:type='data:f.mimeType' target='_blank'&gt;&lt;data:f.name/&gt; (&lt;data:f.feedType/&gt;)&lt;/a&gt;
  &lt;/b:loop&gt;
  &lt;/div&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='iframe_comments' var='post'&gt;

  &lt;b:if cond='data:post.allowIframeComments'&gt;
    &lt;script expr:src='data:post.iframeCommentSrc' type='text/javascript'/&gt;
    &lt;div class='cmt_iframe_holder' expr:data-href='data:post.url.canonical' expr:data-viewtype='data:post.viewType'/&gt;

    &lt;b:if cond='data:post.embedCommentForm == &amp;quot;false&amp;quot;'&gt;
      &lt;a expr:href='data:post.addCommentUrl' expr:onclick='data:post.addCommentOnclick'&gt;&lt;data:postCommentMsg/&gt;&lt;/a&gt;
    &lt;/b:if&gt;
  &lt;/b:if&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='mobile-index-post' var='post'&gt;
  &lt;div class='mobile-date-outer date-outer'&gt;
    &lt;b:if cond='data:post.dateHeader'&gt;
      &lt;div class='date-header'&gt;
        &lt;span&gt;&lt;data:post.dateHeader/&gt;&lt;/span&gt;
      &lt;/div&gt;
    &lt;/b:if&gt;

    &lt;div class='mobile-post-outer'&gt;
      &lt;a expr:href='data:post.url'&gt;
        &lt;h3 class='mobile-index-title entry-title' itemprop='name'&gt;
          &lt;data:post.title/&gt;
        &lt;/h3&gt;

        &lt;div class='mobile-index-arrow'&gt;&amp;amp;rsaquo;&lt;/div&gt;

        &lt;div class='mobile-index-contents'&gt;
          &lt;b:if cond='data:post.thumbnailUrl'&gt;
            &lt;div class='mobile-index-thumbnail'&gt;
              &lt;div class='Image'&gt;
                &lt;img expr:src='data:post.thumbnailUrl'/&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/b:if&gt;

          &lt;div class='post-body'&gt;
            &lt;b:if cond='data:post.snippet'&gt;&lt;data:post.snippet/&gt;&lt;/b:if&gt;
          &lt;/div&gt;
        &lt;/div&gt;

        &lt;div style='clear: both;'/&gt;
      &lt;/a&gt;

      &lt;div class='mobile-index-comment'&gt;
        &lt;b:include cond='data:blog.pageType != &amp;quot;static_page&amp;quot;                          and data:post.allowComments                          and data:post.numComments != 0' data='post' name='comment_count_picker'/&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='mobile-main' var='top'&gt;
    &lt;!-- posts --&gt;
    &lt;div class='blog-posts hfeed'&gt;

      &lt;b:include data='top' name='status-message'/&gt;

      &lt;b:if cond='data:blog.pageType == &amp;quot;index&amp;quot;'&gt;
        &lt;b:loop values='data:posts' var='post'&gt;
          &lt;b:include data='post' name='mobile-index-post'/&gt;
        &lt;/b:loop&gt;
      &lt;b:else/&gt;
        &lt;b:loop values='data:posts' var='post'&gt;
          &lt;b:include data='post' name='mobile-post'/&gt;
        &lt;/b:loop&gt;
      &lt;/b:if&gt;
    &lt;/div&gt;

   &lt;b:include name='mobile-nextprev'/&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='mobile-nextprev'&gt;
  &lt;div class='blog-pager' id='blog-pager'&gt;
    &lt;b:if cond='data:newerPageUrl'&gt;
      &lt;div class='mobile-link-button' id='blog-pager-newer-link'&gt;
      &lt;a class='blog-pager-newer-link' expr:href='data:newerPageUrl' expr:id='data:widget.instanceId + &amp;quot;_blog-pager-newer-link&amp;quot;' expr:title='data:newerPageTitle'&gt;&amp;amp;lsaquo;&lt;/a&gt;
      &lt;/div&gt;
    &lt;/b:if&gt;

    &lt;b:if cond='data:olderPageUrl'&gt;
      &lt;div class='mobile-link-button' id='blog-pager-older-link'&gt;
      &lt;a class='blog-pager-older-link' expr:href='data:olderPageUrl' expr:id='data:widget.instanceId + &amp;quot;_blog-pager-older-link&amp;quot;' expr:title='data:olderPageTitle'&gt;&amp;amp;rsaquo;&lt;/a&gt;
      &lt;/div&gt;
    &lt;/b:if&gt;

    &lt;div class='mobile-link-button' id='blog-pager-home-link'&gt;
    &lt;a class='home-link' expr:href='data:blog.homepageUrl'&gt;&lt;data:homeMsg/&gt;&lt;/a&gt;
    &lt;/div&gt;

    &lt;div class='mobile-desktop-link'&gt;
      &lt;a class='home-link' expr:href='data:desktopLinkUrl'&gt;&lt;data:desktopLinkMsg/&gt;&lt;/a&gt;
    &lt;/div&gt;

  &lt;/div&gt;
  &lt;div class='clear'/&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='mobile-post' var='post'&gt;
  &lt;div class='date-outer'&gt;
    &lt;b:if cond='data:post.dateHeader'&gt;
      &lt;h2 class='date-header'&gt;&lt;span&gt;&lt;data:post.dateHeader/&gt;&lt;/span&gt;&lt;/h2&gt;
    &lt;/b:if&gt;
    &lt;div class='date-posts'&gt;
      &lt;div class='post-outer'&gt;

        &lt;div class='post hentry uncustomized-post-template' itemscope='itemscope' itemtype='http://schema.org/BlogPosting'&gt;
          &lt;b:if cond='data:post.thumbnailUrl'&gt;
            &lt;meta expr:content='data:post.thumbnailUrl' itemprop='image_url'/&gt;
          &lt;/b:if&gt;
          &lt;meta expr:content='data:blog.blogId' itemprop='blogId'/&gt;
          &lt;meta expr:content='data:post.id' itemprop='postId'/&gt;

          &lt;a expr:name='data:post.id'/&gt;
          &lt;b:if cond='data:post.title'&gt;
            &lt;h3 class='post-title entry-title' itemprop='name'&gt;
              &lt;b:if cond='data:post.link'&gt;
                &lt;a expr:href='data:post.link'&gt;&lt;data:post.title/&gt;&lt;/a&gt;
              &lt;b:elseif cond='data:post.url and data:blog.url != data:post.url'/&gt;
                &lt;a expr:href='data:post.url'&gt;&lt;data:post.title/&gt;&lt;/a&gt;
              &lt;b:else/&gt;
                &lt;data:post.title/&gt;
              &lt;/b:if&gt;
            &lt;/h3&gt;
          &lt;/b:if&gt;

          &lt;div class='post-header'&gt;
            &lt;div class='post-header-line-1'/&gt;
          &lt;/div&gt;

          &lt;div class='post-body entry-content' expr:id='&amp;quot;post-body-&amp;quot; + data:post.id' itemprop='articleBody'&gt;
            &lt;data:post.body/&gt;
            &lt;div style='clear: both;'/&gt; &lt;!-- clear for photos floats --&gt;
          &lt;/div&gt;

          &lt;div class='post-footer'&gt;
            &lt;div class='post-footer-line post-footer-line-1'&gt;
              &lt;span class='post-author vcard'&gt;
                &lt;b:if cond='data:top.showAuthor'&gt;
                  &lt;b:if cond='data:post.authorProfileUrl'&gt;
                    &lt;span class='fn' itemprop='author' itemscope='itemscope' itemtype='http://schema.org/Person'&gt;
                      &lt;meta expr:content='data:post.authorProfileUrl' itemprop='url'/&gt;
                      &lt;a expr:href='data:post.authorProfileUrl' rel='author' title='author profile'&gt;
                        &lt;span itemprop='name'&gt;&lt;data:post.author/&gt;&lt;/span&gt;
                      &lt;/a&gt;
                    &lt;/span&gt;
                  &lt;b:else/&gt;
                    &lt;span class='fn' itemprop='author' itemscope='itemscope' itemtype='http://schema.org/Person'&gt;
                      &lt;span itemprop='name'&gt;&lt;data:post.author/&gt;&lt;/span&gt;
                    &lt;/span&gt;
                  &lt;/b:if&gt;
                &lt;/b:if&gt;
              &lt;/span&gt;

              &lt;span class='post-timestamp'&gt;
                &lt;b:if cond='data:top.showTimestamp'&gt;
                  &lt;data:top.timestampLabel/&gt;
                  &lt;b:if cond='data:post.url'&gt;
                    &lt;meta expr:content='data:post.url.canonical' itemprop='url'/&gt;
                    &lt;a class='timestamp-link' expr:href='data:post.url' rel='bookmark' title='permanent link'&gt;&lt;abbr class='published' expr:title='data:post.timestampISO8601' itemprop='datePublished'&gt;&lt;data:post.timestamp/&gt;&lt;/abbr&gt;&lt;/a&gt;
                  &lt;/b:if&gt;
                &lt;/b:if&gt;
              &lt;/span&gt;

              &lt;span class='post-comment-link'&gt;
                &lt;b:include cond='data:blog.pageType not in {&amp;quot;item&amp;quot;,&amp;quot;static_page&amp;quot;}                                  and data:post.allowComments' data='post' name='comment_count_picker'/&gt;
              &lt;/span&gt;
            &lt;/div&gt;

            &lt;div class='post-footer-line post-footer-line-2'&gt;
              &lt;b:if cond='data:top.showMobileShare'&gt;
                &lt;div class='mobile-link-button goog-inline-block' id='mobile-share-button'&gt;
                  &lt;a href='javascript:void(0);'&gt;&lt;data:shareMsg/&gt;&lt;/a&gt;
                &lt;/div&gt;
              &lt;/b:if&gt;
              &lt;b:if cond='data:top.showDummy'&gt;
                &lt;div class='goog-inline-block dummy-container'&gt;&lt;data:post.dummyTag/&gt;&lt;/div&gt;
              &lt;/b:if&gt;
            &lt;/div&gt;

          &lt;/div&gt;
        &lt;/div&gt;

        &lt;b:include cond='data:blog.pageType in {&amp;quot;static_page&amp;quot;,&amp;quot;item&amp;quot;}' data='post' name='comment_picker'/&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='nextprev'&gt;
  &lt;div class='blog-pager' id='blog-pager'&gt;
    &lt;b:if cond='data:newerPageUrl'&gt;
      &lt;span id='blog-pager-newer-link'&gt;
      &lt;a class='blog-pager-newer-link' expr:href='data:newerPageUrl' expr:id='data:widget.instanceId + &amp;quot;_blog-pager-newer-link&amp;quot;' expr:title='data:newerPageTitle'&gt;&lt;data:newerPageTitle/&gt;&lt;/a&gt;
      &lt;/span&gt;
    &lt;/b:if&gt;

    &lt;b:if cond='data:olderPageUrl'&gt;
      &lt;span id='blog-pager-older-link'&gt;
      &lt;a class='blog-pager-older-link' expr:href='data:olderPageUrl' expr:id='data:widget.instanceId + &amp;quot;_blog-pager-older-link&amp;quot;' expr:title='data:olderPageTitle'&gt;&lt;data:olderPageTitle/&gt;&lt;/a&gt;
      &lt;/span&gt;
    &lt;/b:if&gt;

    &lt;a class='home-link' expr:href='data:blog.homepageUrl'&gt;&lt;data:homeMsg/&gt;&lt;/a&gt;

    &lt;b:if cond='data:mobileLinkUrl'&gt;
      &lt;div class='blog-mobile-link'&gt;
        &lt;a expr:href='data:mobileLinkUrl'&gt;&lt;data:mobileLinkMsg/&gt;&lt;/a&gt;
      &lt;/div&gt;
    &lt;/b:if&gt;

  &lt;/div&gt;
  &lt;div class='clear'/&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='post' var='post'&gt;
  &lt;div class='post hentry uncustomized-post-template' itemprop='blogPost' itemscope='itemscope' itemtype='http://schema.org/BlogPosting'&gt;
    &lt;b:if cond='data:post.firstImageUrl'&gt;
      &lt;meta expr:content='data:post.firstImageUrl' itemprop='image_url'/&gt;
    &lt;/b:if&gt;
    &lt;meta expr:content='data:blog.blogId' itemprop='blogId'/&gt;
    &lt;meta expr:content='data:post.id' itemprop='postId'/&gt;

    &lt;a expr:name='data:post.id'/&gt;
    &lt;b:if cond='data:post.title'&gt;
      &lt;h3 class='post-title entry-title' itemprop='name'&gt;
      &lt;b:if cond='data:post.link or (data:post.url and data:blog.url != data:post.url)'&gt;
        &lt;a expr:href='data:post.link ? data:post.link : data:post.url'&gt;&lt;data:post.title/&gt;&lt;/a&gt;
      &lt;b:else/&gt;
        &lt;data:post.title/&gt;
      &lt;/b:if&gt;
      &lt;/h3&gt;
    &lt;/b:if&gt;

    &lt;div class='post-header'&gt;
    &lt;div class='post-header-line-1'/&gt;
    &lt;/div&gt;

    &lt;!-- Then use the post body as the schema.org description, for good G+/FB snippeting. --&gt;
    &lt;div class='post-body entry-content' expr:id='&amp;quot;post-body-&amp;quot; + data:post.id' expr:itemprop='(data:blog.metaDescription ? &amp;quot;&amp;quot; : &amp;quot;description &amp;quot;) + &amp;quot;articleBody&amp;quot;'&gt;
      &lt;data:post.body/&gt;
      &lt;div style='clear: both;'/&gt; &lt;!-- clear for photos floats --&gt;
    &lt;/div&gt;

    &lt;b:if cond='data:post.hasJumpLink'&gt;
      &lt;div class='jump-link'&gt;
        &lt;a expr:href='data:post.url + &amp;quot;#more&amp;quot;' expr:title='data:post.title'&gt;&lt;data:post.jumpText/&gt;&lt;/a&gt;
      &lt;/div&gt;
    &lt;/b:if&gt;

    &lt;div class='post-footer'&gt;
    &lt;div class='post-footer-line post-footer-line-1'&gt;
      &lt;span class='post-author vcard'&gt;
        &lt;b:if cond='data:top.showAuthor'&gt;
          &lt;data:top.authorLabel/&gt;
            &lt;b:if cond='data:post.authorProfileUrl'&gt;
              &lt;span class='fn' itemprop='author' itemscope='itemscope' itemtype='http://schema.org/Person'&gt;
                &lt;meta expr:content='data:post.authorProfileUrl' itemprop='url'/&gt;
                &lt;a class='g-profile' expr:href='data:post.authorProfileUrl' rel='author' title='author profile'&gt;
                  &lt;span itemprop='name'&gt;&lt;data:post.author/&gt;&lt;/span&gt;
                &lt;/a&gt;
              &lt;/span&gt;
            &lt;b:else/&gt;
              &lt;span class='fn' itemprop='author' itemscope='itemscope' itemtype='http://schema.org/Person'&gt;
                &lt;span itemprop='name'&gt;&lt;data:post.author/&gt;&lt;/span&gt;
              &lt;/span&gt;
            &lt;/b:if&gt;
        &lt;/b:if&gt;
      &lt;/span&gt;

      &lt;span class='post-timestamp'&gt;
        &lt;b:if cond='data:top.showTimestamp'&gt;
          &lt;data:top.timestampLabel/&gt;
          &lt;b:if cond='data:post.url'&gt;
            &lt;meta expr:content='data:post.url.canonical' itemprop='url'/&gt;
            &lt;a class='timestamp-link' expr:href='data:post.url' rel='bookmark' title='permanent link'&gt;&lt;abbr class='published' expr:title='data:post.timestampISO8601' itemprop='datePublished'&gt;&lt;data:post.timestamp/&gt;&lt;/abbr&gt;&lt;/a&gt;
          &lt;/b:if&gt;
        &lt;/b:if&gt;
      &lt;/span&gt;

      &lt;span class='reaction-buttons'&gt;
        &lt;b:if cond='data:top.showReactions'&gt;
          &lt;table border='0' cellpadding='0' cellspacing='0' width='100%'&gt;&lt;tr&gt;
            &lt;td class='reactions-label-cell' nowrap='nowrap' valign='top' width='1%'&gt;
              &lt;span class='reactions-label'&gt;
              &lt;data:top.reactionsLabel/&gt;&lt;/span&gt;&amp;#160;&lt;/td&gt;
            &lt;td&gt;&lt;iframe allowtransparency='true' class='reactions-iframe' expr:src='data:post.reactionsUrl' frameborder='0' name='reactions' scrolling='no'/&gt;&lt;/td&gt;
           &lt;/tr&gt;&lt;/table&gt;
        &lt;/b:if&gt;
      &lt;/span&gt;

      &lt;span class='post-comment-link'&gt;
        &lt;b:include cond='data:blog.pageType not in {&amp;quot;item&amp;quot;,&amp;quot;static_page&amp;quot;}                          and data:post.allowComments' data='post' name='comment_count_picker'/&gt;
      &lt;/span&gt;

       &lt;!-- backlinks --&gt;
       &lt;span class='post-backlinks post-comment-link'&gt;
         &lt;b:if cond='data:blog.pageType not in {&amp;quot;item&amp;quot;,&amp;quot;static_page&amp;quot;}                      and data:post.showBacklinks'&gt;
           &lt;a class='comment-link' expr:href='data:post.url + &amp;quot;#links&amp;quot;'&gt;&lt;data:top.backlinkLabel/&gt;&lt;/a&gt;
         &lt;/b:if&gt;
       &lt;/span&gt;

      &lt;span class='post-icons'&gt;
        &lt;!-- email post links --&gt;
        &lt;b:if cond='data:post.emailPostUrl'&gt;
          &lt;span class='item-action'&gt;
          &lt;a expr:href='data:post.emailPostUrl' expr:title='data:top.emailPostMsg'&gt;
            &lt;img alt='' class='icon-action' height='13' src='https://resources.blogblog.com/img/icon18_email.gif' width='18'/&gt;
          &lt;/a&gt;
          &lt;/span&gt;
        &lt;/b:if&gt;

        &lt;!-- quickedit pencil --&gt;
        &lt;b:include data='post' name='postQuickEdit'/&gt;
      &lt;/span&gt;

      &lt;!-- share buttons --&gt;
      &lt;div class='post-share-buttons goog-inline-block'&gt;
        &lt;b:include cond='data:post.sharePostUrl' data='post' name='shareButtons'/&gt;
      &lt;/div&gt;

      &lt;/div&gt;

      &lt;div class='post-footer-line post-footer-line-2'&gt;
      &lt;span class='post-labels'&gt;
        &lt;b:if cond='data:top.showPostLabels and data:post.labels'&gt;
          &lt;data:postLabelsLabel/&gt;
          &lt;b:loop values='data:post.labels' var='label'&gt;
            &lt;a expr:href='data:label.url' rel='tag'&gt;&lt;data:label.name/&gt;&lt;/a&gt;&lt;b:if cond='not data:label.isLast'&gt;,&lt;/b:if&gt;
          &lt;/b:loop&gt;
        &lt;/b:if&gt;
      &lt;/span&gt;
      &lt;/div&gt;

      &lt;div class='post-footer-line post-footer-line-3'&gt;
      &lt;span class='post-location'&gt;
        &lt;b:if cond='data:top.showLocation and data:post.location'&gt;
          &lt;data:postLocationLabel/&gt;
          &lt;a expr:href='data:post.location.mapsUrl' target='_blank'&gt;&lt;data:post.location.name/&gt;&lt;/a&gt;
        &lt;/b:if&gt;
      &lt;/span&gt;
      &lt;/div&gt;
      &lt;b:if cond='data:post.authorAboutMe'&gt;
        &lt;div class='author-profile' itemprop='author' itemscope='itemscope' itemtype='http://schema.org/Person'&gt;
          &lt;b:if cond='data:post.authorPhoto.url'&gt;
            &lt;img expr:src='data:post.authorPhoto.url' itemprop='image' width='50px'/&gt;
          &lt;/b:if&gt;
          &lt;div&gt;
            &lt;a class='g-profile' expr:href='data:post.authorProfileUrl' itemprop='url' rel='author' title='author profile'&gt;
              &lt;span itemprop='name'&gt;&lt;data:post.author/&gt;&lt;/span&gt;
            &lt;/a&gt;
          &lt;/div&gt;
          &lt;span itemprop='description'&gt;&lt;data:post.authorAboutMe/&gt;&lt;/span&gt;
        &lt;/div&gt;
      &lt;/b:if&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='postQuickEdit' var='post'&gt;
  &lt;b:if cond='data:post.editUrl'&gt;
    &lt;span expr:class='&amp;quot;item-control &amp;quot; + data:post.adminClass'&gt;
      &lt;a expr:href='data:post.editUrl' expr:title='data:top.editPostMsg'&gt;
        &lt;img alt='' class='icon-action' height='18' src='https://resources.blogblog.com/img/icon18_edit_allbkg.gif' width='18'/&gt;
      &lt;/a&gt;
    &lt;/span&gt;
  &lt;/b:if&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='shareButtons' var='post'&gt;
  &lt;b:if cond='data:top.showEmailButton'&gt;&lt;a class='goog-inline-block share-button sb-email' expr:href='data:post.sharePostUrl + &amp;quot;&amp;amp;target=email&amp;quot;' expr:title='data:top.emailThisMsg' target='_blank'&gt;&lt;span class='share-button-link-text'&gt;&lt;data:top.emailThisMsg/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/b:if&gt;&lt;b:if cond='data:top.showBlogThisButton'&gt;&lt;a class='goog-inline-block share-button sb-blog' expr:href='data:post.sharePostUrl + &amp;quot;&amp;amp;target=blog&amp;quot;' expr:onclick='&amp;quot;window.open(this.href, \&amp;quot;_blank\&amp;quot;, \&amp;quot;height=270,width=475\&amp;quot;); return false;&amp;quot;' expr:title='data:top.blogThisMsg' target='_blank'&gt;&lt;span class='share-button-link-text'&gt;&lt;data:top.blogThisMsg/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/b:if&gt;&lt;b:if cond='data:top.showTwitterButton'&gt;&lt;a class='goog-inline-block share-button sb-twitter' expr:href='data:post.sharePostUrl + &amp;quot;&amp;amp;target=twitter&amp;quot;' expr:title='data:top.shareToTwitterMsg' target='_blank'&gt;&lt;span class='share-button-link-text'&gt;&lt;data:top.shareToTwitterMsg/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/b:if&gt;&lt;b:if cond='data:top.showFacebookButton'&gt;&lt;a class='goog-inline-block share-button sb-facebook' expr:href='data:post.sharePostUrl + &amp;quot;&amp;amp;target=facebook&amp;quot;' expr:onclick='&amp;quot;window.open(this.href, \&amp;quot;_blank\&amp;quot;, \&amp;quot;height=430,width=640\&amp;quot;); return false;&amp;quot;' expr:title='data:top.shareToFacebookMsg' target='_blank'&gt;&lt;span class='share-button-link-text'&gt;&lt;data:top.shareToFacebookMsg/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/b:if&gt;&lt;b:if cond='data:top.showPinterestButton'&gt;&lt;a class='goog-inline-block share-button sb-pinterest' expr:href='data:post.sharePostUrl + &amp;quot;&amp;amp;target=pinterest&amp;quot;' expr:title='data:top.shareToPinterestMsg' target='_blank'&gt;&lt;span class='share-button-link-text'&gt;&lt;data:top.shareToPinterestMsg/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/b:if&gt;&lt;b:if cond='data:top.showPlusOne'&gt;&lt;div class='goog-inline-block google-plus-share-container'&gt;&lt;data:post.googlePlusShareTag/&gt;&lt;/div&gt;&lt;/b:if&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='status-message'&gt;
  &lt;b:if cond='data:navMessage'&gt;
  &lt;div class='status-msg-wrap'&gt;
    &lt;div class='status-msg-body'&gt;
      &lt;data:navMessage/&gt;
    &lt;/div&gt;
    &lt;div class='status-msg-border'&gt;
      &lt;div class='status-msg-bg'&gt;
        &lt;div class='status-msg-hidden'&gt;&lt;data:navMessage/&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div style='clear: both;'/&gt;
  &lt;/b:if&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='threaded-comment-form' var='post'&gt;
  &lt;div class='comment-form'&gt;
    &lt;a name='comment-form'/&gt;
    &lt;b:if cond='data:mobile'&gt;
      &lt;p&gt;&lt;data:blogCommentMessage/&gt;&lt;/p&gt;
      &lt;data:blogTeamBlogMessage/&gt;
      &lt;a expr:href='data:post.commentFormIframeSrc' id='comment-editor-src'/&gt;
      &lt;iframe allowtransparency='true' class='blogger-iframe-colorize blogger-comment-from-post' expr:height='data:cmtIframeInitialHeight' frameborder='0' id='comment-editor' name='comment-editor' src='' style='display: none' width='100%'/&gt;
    &lt;b:else/&gt;
      &lt;p&gt;&lt;data:blogCommentMessage/&gt;&lt;/p&gt;
      &lt;data:blogTeamBlogMessage/&gt;
      &lt;a expr:href='data:post.commentFormIframeSrc' id='comment-editor-src'/&gt;
      &lt;iframe allowtransparency='true' class='blogger-iframe-colorize blogger-comment-from-post' expr:height='data:cmtIframeInitialHeight' frameborder='0' id='comment-editor' name='comment-editor' src='' width='100%'/&gt;
    &lt;/b:if&gt;
    &lt;data:post.cmtfpIframe/&gt;
    &lt;script type='text/javascript'&gt;
      BLOG_CMT_createIframe(&amp;#39;&lt;data:post.appRpcRelayPath/&gt;&amp;#39;);
    &lt;/script&gt;
  &lt;/div&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='threaded_comment_js' var='post'&gt;
  &lt;script async='async' expr:src='data:post.commentSrc' type='text/javascript'/&gt;

  &lt;script type='text/javascript'&gt;
    (function() {
      var items = &lt;data:post.commentJso/&gt;;
      var msgs = &lt;data:post.commentMsgs/&gt;;
      var config = &lt;data:post.commentConfig/&gt;;

// &lt;![CDATA[
      var cursor = null;
      if (items &amp;&amp; items.length &gt; 0) {
        cursor = parseInt(items[items.length - 1].timestamp) + 1;
      }

      var bodyFromEntry = function(entry) {
        var text = (entry &amp;&amp;
                    ((entry.content &amp;&amp; entry.content.$t) ||
                     (entry.summary &amp;&amp; entry.summary.$t))) ||
            '';
        if (entry &amp;&amp; entry.gd$extendedProperty) {
          for (var k in entry.gd$extendedProperty) {
            if (entry.gd$extendedProperty[k].name == 'blogger.contentRemoved') {
              return '&lt;span class="deleted-comment"&gt;' + text + '&lt;/span&gt;';
            }
          }
        }
        return text;
      }

      var parse = function(data) {
        cursor = null;
        var comments = [];
        if (data &amp;&amp; data.feed &amp;&amp; data.feed.entry) {
          for (var i = 0, entry; entry = data.feed.entry[i]; i++) {
            var comment = {};
            // comment ID, parsed out of the original id format
            var id = /blog-(\d+).post-(\d+)/.exec(entry.id.$t);
            comment.id = id ? id[2] : null;
            comment.body = bodyFromEntry(entry);
            comment.timestamp = Date.parse(entry.published.$t) + '';
            if (entry.author &amp;&amp; entry.author.constructor === Array) {
              var auth = entry.author[0];
              if (auth) {
                comment.author = {
                  name: (auth.name ? auth.name.$t : undefined),
                  profileUrl: (auth.uri ? auth.uri.$t : undefined),
                  avatarUrl: (auth.gd$image ? auth.gd$image.src : undefined)
                };
              }
            }
            if (entry.link) {
              if (entry.link[2]) {
                comment.link = comment.permalink = entry.link[2].href;
              }
              if (entry.link[3]) {
                var pid = /.*comments\/default\/(\d+)\?.*/.exec(entry.link[3].href);
                if (pid &amp;&amp; pid[1]) {
                  comment.parentId = pid[1];
                }
              }
            }
            comment.deleteclass = 'item-control blog-admin';
            if (entry.gd$extendedProperty) {
              for (var k in entry.gd$extendedProperty) {
                if (entry.gd$extendedProperty[k].name == 'blogger.itemClass') {
                  comment.deleteclass += ' ' + entry.gd$extendedProperty[k].value;
                } else if (entry.gd$extendedProperty[k].name == 'blogger.displayTime') {
                  comment.displayTime = entry.gd$extendedProperty[k].value;
                }
              }
            }
            comments.push(comment);
          }
        }
        return comments;
      };

      var paginator = function(callback) {
        if (hasMore()) {
          var url = config.feed + '?alt=json&amp;v=2&amp;orderby=published&amp;reverse=false&amp;max-results=50';
          if (cursor) {
            url += '&amp;published-min=' + new Date(cursor).toISOString();
          }
          window.bloggercomments = function(data) {
            var parsed = parse(data);
            cursor = parsed.length &lt; 50 ? null
                : parseInt(parsed[parsed.length - 1].timestamp) + 1
            callback(parsed);
            window.bloggercomments = null;
          }
          url += '&amp;callback=bloggercomments';
          var script = document.createElement('script');
          script.type = 'text/javascript';
          script.src = url;
          document.getElementsByTagName('head')[0].appendChild(script);
        }
      };
      var hasMore = function() {
        return !!cursor;
      };
      var getMeta = function(key, comment) {
        if ('iswriter' == key) {
          var matches = !!comment.author
              &amp;&amp; comment.author.name == config.authorName
              &amp;&amp; comment.author.profileUrl == config.authorUrl;
          return matches ? 'true' : '';
        } else if ('deletelink' == key) {
          return config.baseUri + '/delete-comment.g?blogID='
               + config.blogId + '&amp;postID=' + comment.id;
        } else if ('deleteclass' == key) {
          return comment.deleteclass;
        }
        return '';
      };

      var replybox = null;
      var replyUrlParts = null;
      var replyParent = undefined;

      var onReply = function(commentId, domId) {
        if (replybox == null) {
          // lazily cache replybox, and adjust to suit this style:
          replybox = document.getElementById('comment-editor');
          if (replybox != null) {
            replybox.height = '250px';
            replybox.style.display = 'block';
            replyUrlParts = replybox.src.split('#');
          }
        }
        if (replybox &amp;&amp; (commentId !== replyParent)) {
          replybox.src = '';
          document.getElementById(domId).insertBefore(replybox, null);
          replybox.src = replyUrlParts[0]
              + (commentId ? '&amp;parentID=' + commentId : '')
              + '#' + replyUrlParts[1];
          replyParent = commentId;
        }
      };

      var hash = (window.location.hash || '#').substring(1);
      var startThread, targetComment;
      if (/^comment-form_/.test(hash)) {
        startThread = hash.substring('comment-form_'.length);
      } else if (/^c[0-9]+$/.test(hash)) {
        targetComment = hash.substring(1);
      }

      // Configure commenting API:
      var configJso = {
        'maxDepth': config.maxThreadDepth
      };
      var provider = {
        'id': config.postId,
        'data': items,
        'loadNext': paginator,
        'hasMore': hasMore,
        'getMeta': getMeta,
        'onReply': onReply,
        'rendered': true,
        'initComment': targetComment,
        'initReplyThread': startThread,
        'config': configJso,
        'messages': msgs
      };

      var render = function() {
        if (window.goog &amp;&amp; window.goog.comments) {
          var holder = document.getElementById('comment-holder');
          window.goog.comments.render(holder, provider);
        }
      };

      // render now, or queue to render when library loads:
      if (window.goog &amp;&amp; window.goog.comments) {
        render();
      } else {
        window.goog = window.goog || {};
        window.goog.comments = window.goog.comments || {};
        window.goog.comments.loadQueue = window.goog.comments.loadQueue || [];
        window.goog.comments.loadQueue.push(render);
      }
    })();
// ]]&gt;
  &lt;/script&gt;
&lt;/b:includable&gt;
              &lt;b:includable id='threaded_comments' var='post'&gt;
  &lt;div class='comments' id='comments'&gt;
    &lt;a name='comments'/&gt;
    &lt;h4&gt;&lt;data:post.commentLabelFull/&gt;:&lt;/h4&gt;

    &lt;div class='comments-content'&gt;
      &lt;b:include cond='data:post.embedCommentForm' data='post' name='threaded_comment_js'/&gt;
      &lt;div id='comment-holder'&gt;
         &lt;data:post.commentHtml/&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;p class='comment-footer'&gt;
      &lt;b:if cond='data:post.allowNewComments'&gt;
        &lt;b:include data='post' name='threaded-comment-form'/&gt;
      &lt;b:else/&gt;
        &lt;data:post.noNewCommentsText/&gt;
      &lt;/b:if&gt;
    &lt;/p&gt;

    &lt;b:if cond='data:showCmtPopup'&gt;
      &lt;div id='comment-popup'&gt;
        &lt;iframe allowtransparency='true' frameborder='0' id='comment-actions' name='comment-actions' scrolling='no'&gt;
        &lt;/iframe&gt;
      &lt;/div&gt;
    &lt;/b:if&gt;

    &lt;div id='backlinks-container'&gt;
    &lt;div expr:id='data:widget.instanceId + &amp;quot;_backlinks-container&amp;quot;'&gt;
      &lt;b:include cond='data:post.showBacklinks' data='post' name='backlinks'/&gt;
    &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/b:includable&gt;
            &lt;/b:widget&gt;
          &lt;/b:section&gt;
        &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class='column-left-outer'&gt;
        &lt;div class='column-left-inner'&gt;
          &lt;aside&gt;
          &lt;macro:include id='main-column-left-sections' name='sections'&gt;
            &lt;macro:param default='0' name='num' value='0'/&gt;
            &lt;macro:param default='sidebar-left' name='idPrefix'/&gt;
            &lt;macro:param default='sidebar' name='class'/&gt;
            &lt;macro:param default='true' name='includeBottom'/&gt;
          &lt;/macro:include&gt;
          &lt;/aside&gt;
        &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class='column-right-outer'&gt;
        &lt;div class='column-right-inner'&gt;
          &lt;aside&gt;
          &lt;macro:include id='main-column-right-sections' name='sections'&gt;
            &lt;macro:param default='2' name='num' value='1'/&gt;
            &lt;macro:param default='sidebar-right' name='idPrefix'/&gt;
            &lt;macro:param default='sidebar' name='class'/&gt;
            &lt;macro:param default='true' name='includeBottom'/&gt;
          &lt;/macro:include&gt;
          &lt;/aside&gt;
        &lt;/div&gt;
        &lt;/div&gt;

        &lt;/div&gt;

        &lt;div style='clear: both'/&gt;
      &lt;!-- columns --&gt;
      &lt;/div&gt;

    &lt;!-- main --&gt;
    &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class='main-cap-bottom cap-bottom'&gt;
      &lt;div class='cap-left'/&gt;
      &lt;div class='cap-right'/&gt;
    &lt;/div&gt;
    &lt;/div&gt;

    &lt;footer&gt;
    &lt;div class='footer-outer'&gt;
    &lt;div class='footer-cap-top cap-top'&gt;
      &lt;div class='cap-left'/&gt;
      &lt;div class='cap-right'/&gt;
    &lt;/div&gt;
    &lt;div class='fauxborder-left footer-fauxborder-left'&gt;
    &lt;div class='fauxborder-right footer-fauxborder-right'/&gt;
    &lt;div class='region-inner footer-inner'&gt;
      &lt;macro:include id='footer-sections' name='sections'&gt;
        &lt;macro:param default='2' name='num'/&gt;
        &lt;macro:param default='footer' name='idPrefix'/&gt;
        &lt;macro:param default='foot' name='class'/&gt;
        &lt;macro:param default='false' name='includeBottom'/&gt;
      &lt;/macro:include&gt;
      &lt;!-- outside of the include in order to lock Attribution widget --&gt;
      &lt;b:section class='foot' id='footer-3' name='Footer' showaddelement='no'&gt;
        &lt;b:widget id='Attribution1' locked='true' title='' type='Attribution'&gt;
          &lt;b:widget-settings&gt;
            &lt;b:widget-setting name='copyright'/&gt;
          &lt;/b:widget-settings&gt;
          &lt;b:includable id='main'&gt;
    &lt;div class='widget-content' style='text-align: center;'&gt;
      &lt;b:if cond='data:attribution != &amp;quot;&amp;quot;'&gt;
       &lt;data:attribution/&gt;
      &lt;/b:if&gt;
    &lt;/div&gt;

    &lt;b:include name='quickedit'/&gt;
  &lt;/b:includable&gt;
        &lt;/b:widget&gt;
      &lt;/b:section&gt;
    &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class='footer-cap-bottom cap-bottom'&gt;
      &lt;div class='cap-left'/&gt;
      &lt;div class='cap-right'/&gt;
    &lt;/div&gt;
    &lt;/div&gt;
    &lt;/footer&gt;

  &lt;!-- content --&gt;
  &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class='content-cap-bottom cap-bottom'&gt;
    &lt;div class='cap-left'/&gt;
    &lt;div class='cap-right'/&gt;
  &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;

  &lt;script type='text/javascript'&gt;
    window.setTimeout(function() {
        document.body.className = document.body.className.replace(&amp;#39;loading&amp;#39;, &amp;#39;&amp;#39;);
      }, 10);
  &lt;/script&gt;
&lt;/body&gt;

&lt;macro:includable id='sections' var='col'&gt;
  &lt;macro:if cond='data:col.num == 0'&gt;
  &lt;macro:else/&gt;
    &lt;b:section mexpr:class='data:col.class' mexpr:id='data:col.idPrefix + &amp;quot;-1&amp;quot;' preferred='yes' showaddelement='yes'/&gt;

    &lt;macro:if cond='data:col.num &amp;gt;= 2'&gt;
      &lt;table border='0' cellpadding='0' cellspacing='0' mexpr:class='&amp;quot;section-columns columns-&amp;quot; + data:col.num'&gt;
      &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td class='first columns-cell'&gt;
          &lt;b:section mexpr:class='data:col.class' mexpr:id='data:col.idPrefix + &amp;quot;-2-1&amp;quot;'/&gt;
        &lt;/td&gt;

        &lt;td class='columns-cell'&gt;
          &lt;b:section mexpr:class='data:col.class' mexpr:id='data:col.idPrefix + &amp;quot;-2-2&amp;quot;'/&gt;
        &lt;/td&gt;

        &lt;macro:if cond='data:col.num &amp;gt;= 3'&gt;
          &lt;td class='columns-cell'&gt;
            &lt;b:section mexpr:class='data:col.class' mexpr:id='data:col.idPrefix + &amp;quot;-2-3&amp;quot;'/&gt;
          &lt;/td&gt;
        &lt;/macro:if&gt;

        &lt;macro:if cond='data:col.num &amp;gt;= 4'&gt;
          &lt;td class='columns-cell'&gt;
            &lt;b:section mexpr:class='data:col.class' mexpr:id='data:col.idPrefix + &amp;quot;-2-4&amp;quot;'/&gt;
          &lt;/td&gt;
        &lt;/macro:if&gt;
      &lt;/tr&gt;
      &lt;/tbody&gt;
      &lt;/table&gt;

      &lt;macro:if cond='data:col.includeBottom'&gt;
        &lt;b:section mexpr:class='data:col.class' mexpr:id='data:col.idPrefix + &amp;quot;-3&amp;quot;' showaddelement='no'/&gt;
      &lt;/macro:if&gt;
    &lt;/macro:if&gt;
  &lt;/macro:if&gt;
&lt;/macro:includable&gt;

&lt;b:section-contents id='sidebar-right-1'&gt;
  &lt;b:widget id='BlogSearch1' locked='false' title='Search This Blog' type='BlogSearch'&gt;
    &lt;b:includable id='main'&gt;
    &lt;!-- only display title if it's non-empty --&gt;
    &lt;b:if cond='data:title != &amp;quot;&amp;quot;'&gt;
      &lt;h2 class='title'&gt;&lt;data:title/&gt;&lt;/h2&gt;
    &lt;/b:if&gt;

    &lt;div class='widget-content'&gt;
      &lt;div expr:id='data:widget.instanceId + &amp;quot;_form&amp;quot;'&gt;
        &lt;form class='gsc-search-box' expr:action='data:blog.searchUrl'&gt;
          &lt;b:attr cond='not data:view.isPreview' name='target' value='_top'/&gt;
          &lt;table cellpadding='0' cellspacing='0' class='gsc-search-box'&gt;
            &lt;tbody&gt;
              &lt;tr&gt;
                &lt;td class='gsc-input'&gt;
                  &lt;input autocomplete='off' class='gsc-input' expr:value='data:view.isSearch ? data:view.search.query.escaped : &amp;quot;&amp;quot;' name='q' size='10' title='search' type='text'/&gt;
                &lt;/td&gt;
                &lt;td class='gsc-search-button'&gt;
                  &lt;input class='gsc-search-button' expr:value='data:messages.search' title='search' type='submit'/&gt;
                &lt;/td&gt;
              &lt;/tr&gt;
            &lt;/tbody&gt;
          &lt;/table&gt;
        &lt;/form&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;b:include name='quickedit'/&gt;
  &lt;/b:includable&gt;
  &lt;/b:widget&gt;
  &lt;b:widget id='Profile1' locked='false' title='About Me' type='Profile'&gt;
    &lt;b:widget-settings&gt;
      &lt;b:widget-setting name='showaboutme'&gt;true&lt;/b:widget-setting&gt;
      &lt;b:widget-setting name='showlocation'&gt;false&lt;/b:widget-setting&gt;
    &lt;/b:widget-settings&gt;
    &lt;b:includable id='main'&gt;
    &lt;b:if cond='data:title != &amp;quot;&amp;quot;'&gt;
      &lt;h2&gt;&lt;data:title/&gt;&lt;/h2&gt;
    &lt;/b:if&gt;
    &lt;div class='widget-content'&gt;
    &lt;b:if cond='data:team'&gt; &lt;!-- team blog profile --&gt;
      &lt;ul&gt;
        &lt;b:loop values='data:authors' var='i'&gt;
          &lt;li&gt;&lt;a class='profile-name-link g-profile' expr:href='data:i.userUrl' expr:style='&amp;quot;background-image: url(&amp;quot; + data:i.profileLogo + &amp;quot;);&amp;quot;'&gt;&lt;data:i.display-name/&gt;&lt;/a&gt;&lt;/li&gt;
        &lt;/b:loop&gt;
      &lt;/ul&gt;

    &lt;b:else/&gt; &lt;!-- normal blog profile --&gt;

      &lt;b:if cond='data:photo.url != &amp;quot;&amp;quot;'&gt;
        &lt;a expr:href='data:userUrl'&gt;&lt;img class='profile-img' expr:alt='data:messages.myPhoto' expr:height='data:photo.height' expr:src='data:photo.url' expr:width='data:photo.width'/&gt;&lt;/a&gt;
      &lt;/b:if&gt;

      &lt;dl class='profile-datablock'&gt;
        &lt;dt class='profile-data'&gt;
          &lt;a class='profile-name-link g-profile' expr:href='data:userUrl' expr:style='&amp;quot;background-image: url(&amp;quot; + data:profileLogo + &amp;quot;);&amp;quot;' rel='author'&gt;
            &lt;data:displayname/&gt;
          &lt;/a&gt;
          &lt;b:if cond='data:hasgoogleprofile'&gt;
            &lt;br/&gt;
            &lt;div class='g-follow' data-annotation='bubble' data-height='20' expr:data-href='data:userUrl'/&gt;
          &lt;/b:if&gt;
        &lt;/dt&gt;

        &lt;b:if cond='data:showlocation'&gt;
          &lt;dd class='profile-data'&gt;&lt;data:location/&gt;&lt;/dd&gt;
        &lt;/b:if&gt;

        &lt;b:if cond='data:aboutme != &amp;quot;&amp;quot;'&gt;&lt;dd class='profile-textblock'&gt;&lt;data:aboutme/&gt;&lt;/dd&gt;&lt;/b:if&gt;
      &lt;/dl&gt;
      &lt;a class='profile-link' expr:href='data:userUrl' rel='author'&gt;&lt;data:viewProfileMsg/&gt;&lt;/a&gt;
    &lt;/b:if&gt;

     &lt;b:include name='quickedit'/&gt;
    &lt;/div&gt;
  &lt;/b:includable&gt;
  &lt;/b:widget&gt;
  &lt;b:widget id='HTML2' locked='false' title='All Posts' type='HTML'&gt;
    &lt;b:widget-settings&gt;
      &lt;b:widget-setting name='content'&gt;&amp;lt;div&amp;gt;&amp;lt;ul id=&amp;quot;postList12&amp;quot;&amp;gt;&amp;lt;/ul&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;

var startIndex = 1;
var maxResults = 100;

function sendQuery12()
{
   var scpt = document.createElement(&amp;quot;script&amp;quot;);
   scpt.src = &amp;quot;/feeds/posts/summary?alt=json&amp;amp;callback=processPostList12&amp;amp;start-index=&amp;quot; + startIndex + &amp;quot;&amp;amp;max-results=&amp;quot; + maxResults;

   document.body.appendChild(scpt);
}

function processPostList12(root)
{
   var elmt = document.getElementById(&amp;quot;postList12&amp;quot;);
   if (!elmt)
      return;

   var feed = root.feed;

   if (feed.entry.length &amp;gt; 0)
   {
      for (var i = 0; i &amp;lt; feed.entry.length; i++)
      {
         var entry = feed.entry[i];

         var title = entry.title.$t;

         for (var j = 0; j &amp;lt; entry.link.length; j++)
         {
            if (entry.link[j].rel == &amp;quot;alternate&amp;quot;)
            {
               var url = entry.link[j].href;

               if (url &amp;amp;&amp;amp; url.length &amp;gt; 0 &amp;amp;&amp;amp; title &amp;amp;&amp;amp; title.length &amp;gt; 0)
               {
                  var liE = document.createElement(&amp;quot;li&amp;quot;);

                  var a1E = document.createElement(&amp;quot;a&amp;quot;);
                  a1E.href = url;
                  a1E.textContent = title;

                  liE.appendChild(a1E);

                  elmt.appendChild(liE);
               }

               break;
            }
         }
      }

      if (feed.entry.length &amp;gt;= maxResults)
      {
         startIndex += maxResults;
         sendQuery12();
      }
   }
}

sendQuery12();&amp;lt;/script&amp;gt;&lt;/b:widget-setting&gt;
    &lt;/b:widget-settings&gt;
    &lt;b:includable id='main'&gt;
  &lt;!-- only display title if it's non-empty --&gt;
  &lt;b:if cond='data:title != &amp;quot;&amp;quot;'&gt;
    &lt;h2 class='title'&gt;&lt;data:title/&gt;&lt;/h2&gt;
  &lt;/b:if&gt;
  &lt;div class='widget-content'&gt;
    &lt;data:content/&gt;
  &lt;/div&gt;

  &lt;b:include name='quickedit'/&gt;
&lt;/b:includable&gt;
  &lt;/b:widget&gt;
  &lt;b:widget id='HTML1' locked='false' title='' type='HTML'&gt;
    &lt;b:widget-settings&gt;
      &lt;b:widget-setting name='content'&gt;&lt;![CDATA[&lt;script type="text/javascript" src="http://latex.codecogs.com/latexit.php?p&amp;li&amp;div"&gt;&lt;/script&gt;]]&gt;&lt;/b:widget-setting&gt;
    &lt;/b:widget-settings&gt;
    &lt;b:includable id='main'&gt;
  &lt;!-- only display title if it's non-empty --&gt;
  &lt;b:if cond='data:title != &amp;quot;&amp;quot;'&gt;
    &lt;h2 class='title'&gt;&lt;data:title/&gt;&lt;/h2&gt;
  &lt;/b:if&gt;
  &lt;div class='widget-content'&gt;
    &lt;data:content/&gt;
  &lt;/div&gt;

  &lt;b:include name='quickedit'/&gt;
&lt;/b:includable&gt;
  &lt;/b:widget&gt;
&lt;/b:section-contents&gt;&lt;b:section-contents id='footer-1'/&gt;&lt;b:section-contents id='footer-2-1'/&gt;&lt;b:section-contents id='footer-2-2'/&gt;&lt;/html&gt;</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/template/default'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/template/default'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_PUBLISHING_MODE</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The type of publishing done for this blog.</title><content type='text'>PUBLISH_MODE_BLOGSPOT</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_PUBLISHING_MODE'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_PUBLISHING_MODE'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_ADMIN_PERMISSION</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The list of administrators' emails for the blog.</title><content type='text'>sujay.skumar141295@gmail.com</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_ADMIN_PERMISSION'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_ADMIN_PERMISSION'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_ADULT_CONTENT</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether this blog contains adult content</title><content type='text'>false</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_ADULT_CONTENT'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_ADULT_CONTENT'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_ALTERNATE_JSRENDER_ALLOWED</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether alternate JS renderings are allowed</title><content type='text'>true</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_ALTERNATE_JSRENDER_ALLOWED'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_ALTERNATE_JSRENDER_ALLOWED'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_ANALYTICS_ACCOUNT_NUMBER</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Blog's Google Analytics account number</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_ANALYTICS_ACCOUNT_NUMBER'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_ANALYTICS_ACCOUNT_NUMBER'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_ARCHIVE_DATE_FORMAT</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The number of the archive index date format</title><content type='text'>9</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_ARCHIVE_DATE_FORMAT'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_ARCHIVE_DATE_FORMAT'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_ARCHIVE_FREQUENCY</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>How frequently this blog should be archived</title><content type='text'>MONTHLY</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_ARCHIVE_FREQUENCY'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_ARCHIVE_FREQUENCY'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_AUTHOR_PERMISSION</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The list of authors' emails who have permission to publish.</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_AUTHOR_PERMISSION'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_AUTHOR_PERMISSION'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_BACKLINKS_ALLOWED</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether to show comment backlinks on the blog</title><content type='text'>false</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_BACKLINKS_ALLOWED'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_BACKLINKS_ALLOWED'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_BY_POST_ARCHIVING</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether to provide an archive page for each post</title><content type='text'>true</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_BY_POST_ARCHIVING'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_BY_POST_ARCHIVING'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_COMMENT_ACCESS</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Who can comment</title><content type='text'>BLOGGERS</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_ACCESS'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_ACCESS'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_COMMENT_CAPTCHA</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether to require commenters to complete a Captcha</title><content type='text'>true</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_CAPTCHA'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_CAPTCHA'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_COMMENT_EMAIL_V2</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>List of e-mail addresses to send notifications of new comments to</title><content type='text'>sujay.skumar141295@gmail.com</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_EMAIL_V2'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_EMAIL_V2'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_COMMENT_FEED</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The type of feed to provide for blog comments</title><content type='text'>FULL</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_FEED'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_FEED'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_COMMENT_FORM_LOCATION</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Blog comment form location</title><content type='text'>EMBEDDED_IFRAME</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_FORM_LOCATION'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_FORM_LOCATION'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_COMMENT_MESSAGE</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Blog comment message</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_MESSAGE'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_MESSAGE'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_COMMENT_MODERATION</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether to enable comment moderation</title><content type='text'>DISABLED</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_MODERATION'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_MODERATION'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_COMMENT_MODERATION_DELAY</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Number of days after which new comments are subject to moderation</title><content type='text'>14</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_MODERATION_DELAY'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_MODERATION_DELAY'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_COMMENT_MODERATION_EMAIL_V2</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Email address to send notifications of new comments needing moderation to</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_MODERATION_EMAIL_V2'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_MODERATION_EMAIL_V2'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_COMMENT_PROFILE_IMAGES</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether to show profile images in comments</title><content type='text'>true</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_PROFILE_IMAGES'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENT_PROFILE_IMAGES'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_COMMENTS_ALLOWED</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether to show comments</title><content type='text'>true</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENTS_ALLOWED'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENTS_ALLOWED'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_COMMENTS_TIME_STAMP_FORMAT</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Comment time stamp format number</title><content type='text'>29</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENTS_TIME_STAMP_FORMAT'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_COMMENTS_TIME_STAMP_FORMAT'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_CONVERT_LINE_BREAKS</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether to convert line breaks into &lt;br /&gt; tags in post editor</title><content type='text'>true</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_CONVERT_LINE_BREAKS'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_CONVERT_LINE_BREAKS'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_CUSTOM_ADS_TXT</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The custom ads.txt content of the blog served to ads search engines.</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_CUSTOM_ADS_TXT'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_CUSTOM_ADS_TXT'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_CUSTOM_ADS_TXT_ENABLED</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether this blog serves custom ads.txt content to ads search engines.</title><content type='text'>false</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_CUSTOM_ADS_TXT_ENABLED'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_CUSTOM_ADS_TXT_ENABLED'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_CUSTOM_PAGE_NOT_FOUND</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The content served when the requested post or page is not found.</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_CUSTOM_PAGE_NOT_FOUND'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_CUSTOM_PAGE_NOT_FOUND'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_CUSTOM_ROBOTS_TXT</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The custom robots.txt content of the blog served to search engines.</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_CUSTOM_ROBOTS_TXT'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_CUSTOM_ROBOTS_TXT'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_CUSTOM_ROBOTS_TXT_ENABLED</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether this blog serves custom robots.txt content to search engines.</title><content type='text'>false</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_CUSTOM_ROBOTS_TXT_ENABLED'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_CUSTOM_ROBOTS_TXT_ENABLED'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_DATE_FORMAT</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The number of the date header format</title><content type='text'>26</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_DATE_FORMAT'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_DATE_FORMAT'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_DEFAULT_BACKLINKS_MODE</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Default backlinks mode for posts</title><content type='text'>DEFAULT_HAVE_BACKLINKS</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_DEFAULT_BACKLINKS_MODE'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_DEFAULT_BACKLINKS_MODE'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_DEFAULT_COMMENTS_MODE</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Default comment mode for posts</title><content type='text'>DEFAULT_HAVE_COMMENTS</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_DEFAULT_COMMENTS_MODE'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_DEFAULT_COMMENTS_MODE'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_DESCRIPTION</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>A description of the blog</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_DESCRIPTION'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_DESCRIPTION'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_EMAIL_POST_LINKS</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether to show a link for users to e-mail posts</title><content type='text'>false</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_EMAIL_POST_LINKS'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_EMAIL_POST_LINKS'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_FEED_REDIRECT_URL</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>URL to redirect post feed requests to</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_FEED_REDIRECT_URL'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_FEED_REDIRECT_URL'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_FLOAT_ALIGNMENT</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether float alignment is enabled for the blog</title><content type='text'>true</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_FLOAT_ALIGNMENT'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_FLOAT_ALIGNMENT'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_LOCALE</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Language for this blog</title><content type='text'>en</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_LOCALE'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_LOCALE'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_M2B_WHITELIST_EMAIL</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>List of email addresses that can post to the blog via email.</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_M2B_WHITELIST_EMAIL'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_M2B_WHITELIST_EMAIL'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_MAX_NUM</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Maximum number of things to show on the main page"</title><content type='text'>7</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_MAX_NUM'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_MAX_NUM'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_MAX_UNIT</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Unit of things to show on the main page</title><content type='text'>POSTS</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_MAX_UNIT'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_MAX_UNIT'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_META_DESCRIPTION</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The meta description of the blog served to search engines.</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_META_DESCRIPTION'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_META_DESCRIPTION'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_META_DESCRIPTION_ENABLED</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether this blog is served with meta descriptions.</title><content type='text'>false</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_META_DESCRIPTION_ENABLED'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_META_DESCRIPTION_ENABLED'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_NAME</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The name of the blog</title><content type='text'>Machine Learning and Data Science</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_NAME'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_NAME'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_PER_POST_FEED</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The type of feed to provide for per-post comments</title><content type='text'>FULL</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_PER_POST_FEED'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_PER_POST_FEED'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_POST_FEED</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The type of feed to provide for blog posts</title><content type='text'>FULL</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_POST_FEED'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_POST_FEED'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_POST_FEED_FOOTER</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Footer to append to the end of each entry in the post feed</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_POST_FEED_FOOTER'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_POST_FEED_FOOTER'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_POST_TEMPLATE</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The template for blog posts</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_POST_TEMPLATE'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_POST_TEMPLATE'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_PROMOTED</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether this blog can be promoted on Blogger</title><content type='text'>true</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_PROMOTED'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_PROMOTED'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_QUICK_EDITING</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether Quick Editing is enabled</title><content type='text'>true</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_QUICK_EDITING'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_QUICK_EDITING'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_READ_ACCESS_MODE</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The access type for the readers of the blog.</title><content type='text'>PUBLIC</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_READ_ACCESS_MODE'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_READ_ACCESS_MODE'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_READER_PERMISSION</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The list of emails for users who have permission to read the blog.</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_READER_PERMISSION'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_READER_PERMISSION'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_SEARCHABLE</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether this blog should be indexed by search engines</title><content type='text'>true</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_SEARCHABLE'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_SEARCHABLE'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_SEND_EMAIL_V2</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Comma separated list of emails to send new blog posts to</title><content type='text'></content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_SEND_EMAIL_V2'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_SEND_EMAIL_V2'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_SHOW_TITLE</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether to show the title field</title><content type='text'>true</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_SHOW_TITLE'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_SHOW_TITLE'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_SHOW_URL</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether to show a related link box in the post composer</title><content type='text'>false</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_SHOW_URL'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_SHOW_URL'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_SUBDOMAIN</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The BlogSpot subdomain under which to publish your blog</title><content type='text'>sujayskumar</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_SUBDOMAIN'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_SUBDOMAIN'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_TIME_STAMP_FORMAT</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The number of the time stamp format</title><content type='text'>27</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_TIME_STAMP_FORMAT'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_TIME_STAMP_FORMAT'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_TIME_ZONE</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>The time zone for this blog</title><content type='text'>America/Los_Angeles</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_TIME_ZONE'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_TIME_ZONE'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.settings.BLOG_USE_LIGHTBOX</id><published>2017-02-16T23:19:31.438-08:00</published><updated>2018-06-30T00:52:21.694-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#settings'/><title type='text'>Whether to show images in the Lightbox when clicked</title><content type='text'>true</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_USE_LIGHTBOX'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/settings/BLOG_USE_LIGHTBOX'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-5574642840918483102</id><published>2018-06-30T00:52:00.000-07:00</published><updated>2018-06-30T00:52:21.691-07:00</updated><app:control xmlns:app='http://purl.org/atom/app#'><app:draft>yes</app:draft></app:control><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Transfer Learning in NLP using Keras and ELMo</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;br /&gt;&lt;/div&gt;</content><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2018/06/transfer-learning-in-nlp-using-keras.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/5574642840918483102'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/5574642840918483102'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-1476940022075810002</id><published>2018-06-29T21:16:00.000-07:00</published><updated>2018-06-29T21:16:07.738-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>I Have Words! Give Me Sentences! - Sentence Embeddings</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Word embeddings are the staple of any Natural Language Processing (NLP) task. In fact, representation of words in the form of vectors is probably the first step in building any NLP application. These vector representations of words fall in a wide spectrum in semantic encoding space, with a one-hot representation on one end of the spectrum, encoding absolutely nothing in terms of semantics between words and the other end of the spectrum still being an active area of research with ELMo embeddings achieving state of the art results. Most widely used embeddings such as Word2Vec and GloVe fall somewhere in between on this spectrum.&lt;br /&gt;&lt;br /&gt;Although these word embeddings encode semantic relationships between words and can be efficiently used as vector representations of words, these embeddings cannot directly be applied to NLP tasks. Majority of NLP tasks deal in sentences and paragraphs (a set of words, to be more formal) and not individual words themselves. Therefore, there is a need for efficient semantic embeddings for groups of words, henceforth referred to as sentence embeddings.&lt;br /&gt;&lt;br /&gt;Averaging of individual Word2Vec embeddings is one of the most widely used sentence embedding techniques. Although it might sound naive, hey, it works. There definitely exists some information loss when we average out word2vec vectors which get cancelled out when another learning algorithm is stacked after the averaging operation.&lt;br /&gt;&lt;br /&gt;Another approach to sentence embedding is to treat the words in a sentence as sequence inputs at respective time steps. Hence, it can be modeled using a recurrent neural network architecture where the each word is treated as input at current time step. The encoded representation or the last hidden state activation at the final time step is taken as the sentence embedding. &lt;br /&gt;&lt;br /&gt;One of the most recent research in sentence encoding comes from Google, which has open sourced their implementation in the form of &lt;a href="https://arxiv.org/pdf/1803.11175.pdf" target="_blank"&gt;Universal Sentence Encoder&lt;/a&gt;. Universal Sentence Encoder is an implementation of two sentence encoding architectures, &lt;a href="https://www.cs.umd.edu/~miyyer/pubs/2015_acl_dan.pdf" target="_blank"&gt;Deep Averaged Networks&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank"&gt;Transformer&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Deep Averaged Network is a simple feed forward neural network that takes the average of word embeddings as the input layer, stacks two hidden layers and culminates with a softmax over the target classification. The last hidden layer activation is taken as the sentence embedding.&lt;br /&gt;&lt;br /&gt;The Transformer architecture is a variant of recurrent neural network, where a convolution is implemented over the input sentence. Each word is embedded using an existing word embedding technique with an additional positional embedding. These word embeddings are passed through a convolutional layer with attention mechanism. The decoder stage generates the context/future words given a sequence of words. The hidden state activation is taken as the sentence embedding.&lt;br /&gt;&lt;br /&gt;While these approaches are promising, employing complex neural architectures fail to perform significantly better than simple old-fashioned averaging of word vectors. In most of the NLP tasks, instead of employing such complicated architectures in your model, you will be better off employing simple average based sentence encodings and optimizing your classification model.&lt;br /&gt;&lt;br /&gt;Since we have decided to go down the averaging route, we can explore different kinds of averaging in order to better embed sentences. One of the approaches is to employ tf-idf weighted average of word vectors instead of a simple average, which in practice turns out to be an embarrassingly good sentence embedding. Any averaging technique is dependent on the quality of the underlying word embeddings. Therefore, any improvement in word embeddings has a direct effect on sentence embeddings. This is where ELMo embeddings come into the picture.&lt;br /&gt;&lt;br /&gt;ELMo  (Em-beddings from Language Models) is a word representation algorithm that is providing state of the art results in downstream NLP tasks. They are presented in the following paper: &lt;a href="https://arxiv.org/pdf/1802.05365.pdf" target="_blank"&gt;Deep Contextualized Word Representations&lt;/a&gt;. The architecture consists of 1 word embedding layer and 2 hidden bi-LSTM layers, for both forward and backward representations. ELMo is modeled on image classification neural network ResNet and hence, the defining characteristic of ELMo is that it exposes the hidden layer activations for each word. A weighted average of these activations yield the word embedding. These weights are learnable parameters and can be fine tuned for the NLP task at hand. Since the entire ELMo model is pre trained on big corpus and only these weights are learned for the task at hand, it falls into transfer learning territory and is best suited for any NLP task with less amount of data.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-ubuE38txbNM/Wzb9BhVvRKI/AAAAAAAAOZY/0xp9N8TTLaMxzLY2FsyySHKThgJ1c2lpwCLcBGAs/s1600/ELMO.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="250" data-original-width="545" height="182" src="https://3.bp.blogspot.com/-ubuE38txbNM/Wzb9BhVvRKI/AAAAAAAAOZY/0xp9N8TTLaMxzLY2FsyySHKThgJ1c2lpwCLcBGAs/s400/ELMO.png" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;One important point about the above architecture is that, ELMo takes words as input character wise. A 2048 character n gram convolutional filter is applied on the characters of the words, followed by a projection on the 512 dimension vector space for each word. This gives ELMo the ability to handle unseen words and even commonly miss-spelt words. &lt;br /&gt;&lt;br /&gt;Assume that &lt;i&gt;t&lt;sub&gt;k&lt;/sub&gt; &lt;/i&gt;is the current word (token) that needs to be embedded, the following probabilities is modeled by the forward and backward LSTM layers:&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=p(t_{1},t_{2},...,t_{N})&amp;amp;space;=&amp;amp;space;\prod_{k=1}^{N}p(t_{k}|t_{1},t_{2},...,t_{k-1})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?p(t_{1},t_{2},...,t_{N})&amp;amp;space;=&amp;amp;space;\prod_{k=1}^{N}p(t_{k}|t_{1},t_{2},...,t_{k-1})" title="p(t_{1},t_{2},...,t_{N}) = \prod_{k=1}^{N}p(t_{k}|t_{1},t_{2},...,t_{k-1})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=p(t_{1},t_{2},...,t_{N})&amp;amp;space;=&amp;amp;space;\prod_{k=1}^{N}p(t_{k}|t_{k+1},t_{k+2},...,t_{N})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?p(t_{1},t_{2},...,t_{N})&amp;amp;space;=&amp;amp;space;\prod_{k=1}^{N}p(t_{k}|t_{k+1},t_{k+2},...,t_{N})" title="p(t_{1},t_{2},...,t_{N}) = \prod_{k=1}^{N}p(t_{k}|t_{k+1},t_{k+2},...,t_{N})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Given the token &lt;i&gt;t&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt; (word), the convolutional filter is applied on the characters and projected into the word embedding space. This projection is denoted by &lt;i&gt;x&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt;.&lt;br /&gt;&lt;br /&gt;If the architecture consists of &lt;i&gt;L&lt;/i&gt; hidden layers, for the token &lt;i&gt;t&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt;, we get &lt;i&gt;2L&lt;/i&gt; hidden representations (forward and backward) and 1 word embedding representation &lt;i&gt;x&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt;, which can be represented as:&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=R_{k}&amp;amp;space;=&amp;amp;space;\{x_{k},&amp;amp;space;h_{k,j}^{forward},&amp;amp;space;h_{k,j}^{backward}&amp;amp;space;|&amp;amp;space;j=1,2,...,N\}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?R_{k}&amp;amp;space;=&amp;amp;space;\{x_{k},&amp;amp;space;h_{k,j}^{forward},&amp;amp;space;h_{k,j}^{backward}&amp;amp;space;|&amp;amp;space;j=1,2,...,N\}" title="R_{k} = \{x_{k}, h_{k,j}^{forward}, h_{k,j}^{backward} | j=1,2,...,N\}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Concatenating the forward and backward representations, each token &lt;i&gt;t&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt; has &lt;i&gt;2L+1&lt;/i&gt; representations, which can expressed as follows:&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=R_{k}&amp;amp;space;=&amp;amp;space;\{h_{k,j}&amp;amp;space;|&amp;amp;space;j=0,1,2,...,N\},&amp;amp;space;where&amp;amp;space;\quad&amp;amp;space;h_{0,j}=x_{k}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?R_{k}&amp;amp;space;=&amp;amp;space;\{h_{k,j}&amp;amp;space;|&amp;amp;space;j=0,1,2,...,N\},&amp;amp;space;where&amp;amp;space;\quad&amp;amp;space;h_{0,j}=x_{k}" title="R_{k} = \{h_{k,j} | j=0,1,2,...,N\}, where \quad h_{0,j}=x_{k}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Now, the ELMo representation of this word (which is task dependent) is expressed as follows:&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=ELMo_{k}^{task}&amp;amp;space;=&amp;amp;space;\gamma^{task}\sum_{j=0}^{L}s_{j}^{task}h_{k,j}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?ELMo_{k}^{task}&amp;amp;space;=&amp;amp;space;\gamma^{task}\sum_{j=0}^{L}s_{j}^{task}h_{k,j}" title="ELMo_{k}^{task} = \gamma^{task}\sum_{j=0}^{L}s_{j}^{task}h_{k,j}" /&gt;&lt;/a&gt;&lt;br /&gt;where &lt;a href="https://www.codecogs.com/eqnedit.php?latex=\gamma^{task}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\gamma^{task}" title="\gamma^{task}" /&gt;&lt;/a&gt; is a scaling parameter.&lt;br /&gt;&lt;br /&gt;Both &lt;a href="https://www.codecogs.com/eqnedit.php?latex=\gamma^{task}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\gamma^{task}" title="\gamma^{task}" /&gt;&lt;/a&gt; and &lt;a href="https://www.codecogs.com/eqnedit.php?latex=s_{j}^{task}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?s_{j}^{task}" title="s_{j}^{task}" /&gt;&lt;/a&gt; are learnable parameters that are trained specific to the NLP task at hand. &lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/1476940022075810002/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2018/06/i-have-words-give-me-sentences-sentence.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/1476940022075810002'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/1476940022075810002'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2018/06/i-have-words-give-me-sentences-sentence.html' title='I Have Words! Give Me Sentences! - Sentence Embeddings'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><media:thumbnail xmlns:media='http://search.yahoo.com/mrss/' url='https://3.bp.blogspot.com/-ubuE38txbNM/Wzb9BhVvRKI/AAAAAAAAOZY/0xp9N8TTLaMxzLY2FsyySHKThgJ1c2lpwCLcBGAs/s72-c/ELMO.png' height='72' width='72'/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-9095579379828525248</id><published>2018-05-16T07:44:00.000-07:00</published><updated>2018-05-16T07:44:12.687-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Conditional Random Fields</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Conditional Random Field (CRF) is the go-to algorithm for sequence labeling problems. Initial attempts at sequence labeling such as POS tagging and Named Entity Recognition were accomplished using the Hidden Markov Models. Although HMMs gave promising results for the same, they suffered from the same drawbacks as using a Naive Bayes models i.e conditional independence.&lt;br /&gt;&lt;br /&gt;Both Naive Bayes (and HMM in extension) try to fit a model that maximizes the joint probability distribution &lt;i&gt;P(X , Y)&lt;/i&gt;. This is flawed on two levels. One, since &lt;i&gt;X&lt;/i&gt; is already given, trying to fit a joint distribution over both &lt;i&gt;X&lt;/i&gt; and &lt;i&gt;Y&lt;/i&gt; is computationally expensive, wasteful and in the end, we do not require the type of distribution the input variable follow. We just need to know what distribution the target variable follows given an input variable. Second, since we are assuming that the input variables are conditionally independent, if there exists some correlation between the variables, the model assigns high probability when these two variables occur together instead of generalizing over the input distribution. Hence, we can see that any perturbance in the input distribution has a significant effect over the output. Ideally, since we only care about the distribution of the target variable &lt;i&gt;Y&lt;/i&gt;, this should not be under consideration. We should evaluate &lt;i&gt;P(Y | X)&lt;/i&gt; instead of &lt;i&gt;P(X , Y)&lt;/i&gt;.&lt;br /&gt;&lt;br /&gt;In hindsight, this might seem trivial and as the obvious choice for any classification problem. In fact, majority of the classifiers in use today optimize over this metric. Nevertheless, it was an important breakthrough when it was considered decades ago. &lt;br /&gt;&lt;br /&gt;A Conditional Random Field (CRF) does exactly this. It evaluates &lt;i&gt;P(Y | X)&lt;/i&gt;. The purpose of this post is to delve deeper into the mathematics of a CRF and why CRF is considered to be the starting point for most of the current classification algorithms.&lt;br /&gt;&lt;br /&gt;Consider a function &lt;i&gt;Q(.)&lt;/i&gt; as a real valued function. According to Markovian distribution theorem,&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/gif.latex?P(X,Y)&amp;amp;space;\propto&amp;amp;space;exp(\sum&amp;amp;space;_{c\in&amp;amp;space;C}Q(c,&amp;amp;space;X,Y))" title="P(X,Y) \propto exp(\sum _{c\in C}Q(c, X,Y))" /&gt;&lt;br /&gt;&lt;br /&gt;Where &lt;i&gt;C&lt;/i&gt; is a set of feature verticals (or cliques). This equation provides us with the un-normalized joint probability distribution over &lt;i&gt;X&lt;/i&gt; and &lt;i&gt;Y&lt;/i&gt;. Since we are interested in calculating the conditional probability,&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/gif.latex?P(Y|X)=&amp;amp;space;\frac{exp(\sum&amp;amp;space;_{c\in&amp;amp;space;C}Q(c,&amp;amp;space;X,Y))}{\sum&amp;amp;space;_{X}exp(\sum&amp;amp;space;_{c\in&amp;amp;space;C}Q(c,&amp;amp;space;X,Y))}" title="P(Y|X)= \frac{exp(\sum _{c\in C}Q(c, X,Y))}{\sum _{X}exp(\sum _{c\in C}Q(c, X,Y))}" /&gt;&lt;br /&gt;&lt;br /&gt;This is similar to Gibbs Distribution (or Softmax depending on the &lt;i&gt;Q(.)&lt;/i&gt; function)&lt;br /&gt;The above equation can be re written as&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/gif.latex?P(Y|X)=&amp;amp;space;\frac{\prod&amp;amp;space;_{C}\phi&amp;amp;space;_{C}(X,&amp;amp;space;Y)}{Z}" title="P(Y|X)= \frac{\prod _{C}\phi _{C}(X, Y)}{Z}" /&gt;&lt;br /&gt;&lt;br /&gt;Where &lt;img src="https://latex.codecogs.com/gif.latex?\phi&amp;amp;space;_{C}(X,&amp;amp;space;Y)&amp;amp;space;=&amp;amp;space;exp(Q(C,X,Y))" title="\phi _{C}(X, Y) = exp(Q(C,X,Y))" /&gt; and &lt;i&gt;Z&lt;/i&gt; is called as the Partition Function.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/gif.latex?Z&amp;amp;space;=&amp;amp;space;\sum&amp;amp;space;_{X}exp(\sum&amp;amp;space;_{c\in&amp;amp;space;C}Q(c,&amp;amp;space;X,Y))" title="Z = \sum _{X}exp(\sum _{c\in C}Q(c, X,Y))" /&gt;&lt;br /&gt;&lt;br /&gt;For a CRF which is used for sequence labelling such as PoS or NER, the graph forms a linear chain and the probability equation can be written as&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/gif.latex?P(Y_{1},Y_{2},...,Y_{M}|X)&amp;amp;space;=&amp;amp;space;\frac{1}{Z}\prod&amp;amp;space;_{i}\phi&amp;amp;space;(Y_{i},X)\phi^{1}(Y_{i-1},Y_{i},X)" title="P(Y_{1},Y_{2},...,Y_{M}|X) = \frac{1}{Z}\prod _{i}\phi (Y_{i},X)\phi^{1}(Y_{i-1},Y_{i},X)" /&gt;&lt;br /&gt;&lt;br /&gt;Where,&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\phi&amp;amp;space;()&amp;amp;space;=&amp;amp;space;exp(\sum&amp;amp;space;_{k}\theta&amp;amp;space;_{k}s_{k}(y_{i},x_{i},i))" title="\phi () = exp(\sum _{k}\theta _{k}s_{k}(y_{i},x_{i},i))" /&gt;&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\phi^{1}&amp;amp;space;()&amp;amp;space;=&amp;amp;space;exp(\sum&amp;amp;space;_{j}\lambda_{j}t_{j}(y_{i-1},y_{i},x_{i},i))" title="\phi^{1} () = exp(\sum _{j}\lambda_{j}t_{j}(y_{i-1},y_{i},x_{i},i))" /&gt;&lt;br /&gt;where &lt;i&gt;s&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt; is the state feature function and &lt;i&gt;t&lt;sub&gt;j&lt;/sub&gt;&lt;/i&gt; is the transition feature function (Similar to HMMs).&lt;br /&gt;&lt;br /&gt;CRF is a generalized method of calculating &lt;i&gt;P(Y | X)&lt;/i&gt; and is not restricted to just evaluating sequence label probabilities. The flexibility of CRFs stems from the ability to choose any function as &lt;i&gt;Q(X , Y)&lt;/i&gt;. In the following section, we can see how the logistic function can also be derived from CRF.&lt;br /&gt;&lt;br /&gt;Consider the feature function,&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\phi&amp;amp;space;(X_{i},Y)&amp;amp;space;=&amp;amp;space;exp(w_{i}1(X_{i},Y))" title="\phi (X_{i},Y) = exp(w_{i}1(X_{i},Y))" /&gt;&lt;br /&gt;&lt;br /&gt;where &lt;i&gt;1&lt;/i&gt; is an indicator function. It can also be denoted as&amp;nbsp; &lt;img src="https://latex.codecogs.com/gif.latex?\phi&amp;amp;space;(X_{i},Y)&amp;amp;space;=&amp;amp;space;exp(w_{i}*&amp;amp;space;AND(X_{i},Y))" title="\phi (X_{i},Y) = exp(w_{i}* AND(X_{i},Y))" /&gt;&lt;br /&gt;&lt;br /&gt;Calculating the probabilities,&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\phi&amp;amp;space;(X_{i},Y=1)&amp;amp;space;=&amp;amp;space;exp(w_{i}X_{i})" title="\phi (X_{i},Y=1) = exp(w_{i}X_{i})" /&gt;&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\phi&amp;amp;space;(X_{i},Y=0)&amp;amp;space;=&amp;amp;space;exp(0)=1" title="\phi (X_{i},Y=0) = exp(0)=1" /&gt;&lt;br /&gt;&lt;br /&gt;Therefore, substituting the above results in the CRF equation, we get,&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/gif.latex?P(Y|X)&amp;amp;space;=&amp;amp;space;\frac{\phi&amp;amp;space;(X_{i},Y=0)&amp;amp;space;*&amp;amp;space;\phi&amp;amp;space;(X_{i},Y=1)}{\phi&amp;amp;space;(X_{i},Y=0)&amp;amp;space;+&amp;amp;space;\phi&amp;amp;space;(X_{i},Y=1)}&amp;amp;space;=&amp;amp;space;\frac{exp(\sum&amp;amp;space;_{i}w_{i}X_{i})}{1+exp(\sum&amp;amp;space;_{i}w_{i}X_{i})}" title="P(Y|X) = \frac{\phi (X_{i},Y=0) * \phi (X_{i},Y=1)}{\phi (X_{i},Y=0) + \phi (X_{i},Y=1)} = \frac{exp(\sum _{i}w_{i}X_{i})}{1+exp(\sum _{i}w_{i}X_{i})}" /&gt;&lt;br /&gt;&lt;br /&gt;The above equation is nothing but the logistic equation. Hence, we can see that CRF is a generalized form of any machine learning classification problem.&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/9095579379828525248/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2018/05/conditional-random-fields.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/9095579379828525248'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/9095579379828525248'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2018/05/conditional-random-fields.html' title='Conditional Random Fields'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-2447877304108304122</id><published>2018-01-26T20:02:00.001-08:00</published><updated>2018-02-11T08:35:12.308-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Word Mover's Distance: Mathematical Background</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;We are fully aware of the marked influence of the introduction of Word2Vec method of word embedding on the Natural Language Processing domain. It was a huge leap forward from the hitherto constricting method of word embeddings namely, Term Frequency (TF) and Inverse Document Frequency (IDF). Neither of these methods were anywhere close to preserving the semantics of the words in their representations. With the introduction of Word2Vec and the possibility of semantic embedding in the vectors, various avenues were thrown open where this representation could be exploited for various NLP applications.&lt;br /&gt;&lt;br /&gt;One of the logical extensions to Word2Vec was document similarity. Now that you could find out similarity between words, what was the best way of classifying or clustering documents semantically? There are two metrics by which we can quantify the similarity between two words, cosine similarity and Euclidean distance.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Word Mover's Distance (WMD)&lt;/b&gt; was introduced in 2015 which leveraged Euclidean distance in order to quantify similarity between documents. WMD accomplishes this by quantifying the amount of distance that the embedded vectors in a document needs to travel in order to match the embedded vectors in another document, thereby offering us a proxy which quantifies dissimilarity (or similarity) between two documents. You can find a link to the original paper &lt;a href="http://proceedings.mlr.press/v37/kusnerb15.pdf" target="_blank"&gt;here&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;For example, let us consider three documents,&lt;br /&gt;&lt;br /&gt;D1: "&lt;i&gt;&lt;u&gt;Obama&lt;/u&gt; &lt;u&gt;speaks &lt;/u&gt;to the &lt;u&gt;media&lt;/u&gt; in &lt;u&gt;Illinois&lt;/u&gt;&lt;/i&gt;"&lt;br /&gt;D2: "&lt;i&gt;The &lt;u&gt;President&lt;/u&gt; &lt;u&gt;greets &lt;/u&gt;the &lt;u&gt;press&lt;/u&gt; in &lt;u&gt;Chicago&lt;/u&gt;&lt;/i&gt;"&lt;br /&gt;D3: "&lt;i&gt;&lt;u&gt;Obama&lt;/u&gt; &lt;u&gt;speaks&lt;/u&gt; in &lt;u&gt;Illinois&lt;/u&gt;&lt;/i&gt;" &lt;br /&gt;&lt;br /&gt;WMD algorithm can be described in the following steps.&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;Each word in a sentence can be represented as a point in the &lt;i&gt;(n-1)&lt;/i&gt; dimensional simplex of word distribution. The magnitude of the vector is represented by it's nBOW (n Bag Of Words) representation. Mathematically, if the word &lt;i&gt;i &lt;/i&gt;appears &lt;i&gt;c&lt;sub&gt;i&lt;/sub&gt; &lt;/i&gt;times it can represented as,&amp;nbsp; &lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=d_{i}&amp;amp;space;=&amp;amp;space;\frac{c_{i}}{\sum_{j=1}^{n}c_{j}}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?d_{i}&amp;amp;space;=&amp;amp;space;\frac{c_{i}}{\sum_{j=1}^{n}c_{j}}" title="d_{i} = \frac{c_{i}}{\sum_{j=1}^{n}c_{j}}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;where &lt;i&gt;di&amp;nbsp; &lt;/i&gt;is a vector in &lt;i&gt;n &lt;/i&gt;dimensional space specified by vocabulary size. It is perfectly clear from the above description that each word pair, if they are dissimilar, lie in a completely different plane irrespective of their semantic distance.&lt;/li&gt;&lt;li&gt;In the example considered above, after stop words removal, the nBOW representations of documents D1 and D2 have zero common non zero elements and hence lie in the max distance possible from each other even though semantically these sentences are close.&lt;/li&gt;&lt;li&gt;The distance metric used between any word pair is given by the Euclidean distance between the Word2Vec vectors. We will denote this distance between the word &lt;i&gt;i&lt;/i&gt; and word &lt;i&gt;j&lt;/i&gt; as  &lt;br /&gt;&lt;br /&gt;&lt;i&gt;c(i , j) = || x&lt;sub&gt;i&lt;/sub&gt; - x&lt;sub&gt;j&lt;/sub&gt; ||&lt;/i&gt;,  &lt;br /&gt;&lt;br /&gt;where &lt;i&gt;c(i , j)&lt;/i&gt; is the traveling cost from word &lt;i&gt;i&lt;/i&gt; to word &lt;i&gt;j&lt;/i&gt;.&lt;/li&gt;&lt;li&gt;The objective of the WMD algorithm is to calculate the flow matrix &lt;i&gt;T&lt;/i&gt;. Flow matrix &lt;i&gt;T&lt;/i&gt; can be defined as a sparse matrix of dimension &lt;i&gt;n X n.&lt;/i&gt;  &lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=T&amp;amp;space;\in&amp;amp;space;R^{n&amp;amp;space;X&amp;amp;space;n}&amp;amp;space;\hspace{0.2cm}where&amp;amp;space;\hspace{0.2cm}&amp;amp;space;T_{i,j}\geq&amp;amp;space;0" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?T&amp;amp;space;\in&amp;amp;space;R^{n&amp;amp;space;X&amp;amp;space;n}&amp;amp;space;\hspace{0.2cm}where&amp;amp;space;\hspace{0.2cm}&amp;amp;space;T_{i,j}\geq&amp;amp;space;0" title="T \in R^{n X n} \hspace{0.2cm}where \hspace{0.2cm} T_{i,j}\geq 0" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;In the flow matrix &lt;i&gt;T&lt;/i&gt;, &lt;i&gt;T&lt;sub&gt;i,j&lt;/sub&gt;&lt;/i&gt; denotes how much of word &lt;i&gt;i&lt;/i&gt; in &lt;i&gt;d&lt;/i&gt; flows into word &lt;i&gt;j&lt;/i&gt; in &lt;i&gt;d'&lt;/i&gt;. Naturally, the sum of the outgoing flow from word &lt;i&gt;i&lt;/i&gt; should be equal to &lt;i&gt;d&lt;sub&gt;i&lt;/sub&gt;&lt;/i&gt; and the sum of the incoming flow to word &lt;i&gt;j&lt;/i&gt; should be equal to &lt;i&gt;d'&lt;sub&gt;j&lt;/sub&gt;&lt;/i&gt;. Mathematically,  &lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\sum_{j}&amp;amp;space;T_{i,j}&amp;amp;space;=&amp;amp;space;d_{i}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\sum_{j}&amp;amp;space;T_{i,j}&amp;amp;space;=&amp;amp;space;d_{i}" title="\sum_{j} T_{i,j} = d_{i}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\sum_{i}&amp;amp;space;T_{i,j}&amp;amp;space;=&amp;amp;space;d%27_{j}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\sum_{i}&amp;amp;space;T_{i,j}&amp;amp;space;=&amp;amp;space;d'_{j}" title="\sum_{i} T_{i,j} = d'_{j}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Finally, we can calculate the distance between the two documents &lt;i&gt;d&lt;/i&gt; and &lt;i&gt;d'&lt;/i&gt; by calculating the minimum cumulative cost required to move all words in &lt;i&gt;d&lt;/i&gt; to &lt;i&gt;d'&lt;/i&gt;.  &lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\sum_{i,j}&amp;amp;space;T_{i,j}c(i,j)" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\sum_{i,j}&amp;amp;space;T_{i,j}c(i,j)" title="\sum_{i,j} T_{i,j}c(i,j)" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;The minimum cumulative cost can be formalized with constraints as follows,&amp;nbsp;  &lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\underset{T\geq&amp;amp;space;0}{min}\sum_{i,j}&amp;amp;space;T_{i,j}c(i,j)" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\underset{T\geq&amp;amp;space;0}{min}\sum_{i,j}&amp;amp;space;T_{i,j}c(i,j)" title="\underset{T\geq 0}{min}\sum_{i,j} T_{i,j}c(i,j)" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;subject to  &lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\sum_{j}&amp;amp;space;T_{i,j}&amp;amp;space;=&amp;amp;space;d_{i}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\sum_{j}&amp;amp;space;T_{i,j}&amp;amp;space;=&amp;amp;space;d_{i}" title="\sum_{j} T_{i,j} = d_{i}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\sum_{i}&amp;amp;space;T_{i,j}&amp;amp;space;=&amp;amp;space;d%27_{j}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\sum_{i}&amp;amp;space;T_{i,j}&amp;amp;space;=&amp;amp;space;d'_{j}" title="\sum_{i} T_{i,j} = d'_{j}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;The solution to the above problem is a variation of the Transportation Problem called Earth Mover's Distance which can be found &lt;a href="https://en.wikipedia.org/wiki/Earth_mover%27s_distance" target="_blank"&gt;here&lt;/a&gt;.&lt;/li&gt;&lt;/ul&gt;Although the algorithm seems simple enough when the number of words in the 2 documents are equal, complications arise when the number of words are different, as in the case between D2 and D3. In that case, the computational complexity increases to &lt;i&gt;O(P&lt;sup&gt;4&lt;/sup&gt;)&lt;/i&gt;. Hence, this algorithm is computationally very expensive.&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;/ul&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/2447877304108304122/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2018/01/word-movers-distance-mathematical.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/2447877304108304122'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/2447877304108304122'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2018/01/word-movers-distance-mathematical.html' title='Word Mover&apos;s Distance: Mathematical Background'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-1886062490513676810</id><published>2017-12-05T21:37:00.000-08:00</published><updated>2017-12-05T21:37:41.820-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Hidden Markov Models (HMM): Theoretical Background</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div&gt;Hidden Markov Models (HMM) were the mainstay of generative models a couple of years ago. Even though more sophisticated Deep Learning generative models have emerged, we cannot rule out the effectiveness of the humble HMM. After all, one of the most widely known principle (Occam's Razor) states that if you have a number of competing hypothesis, the simplest one is the best one. The purpose of this blog post is to explore the mathematical basis on which HMMs are built. &lt;/div&gt;&lt;/div&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div&gt;&lt;br /&gt;Hidden Markov Models are characterized by two types of states, Hidden States and Observable States. Any HMM can be represented by three parameters:&lt;br /&gt;&lt;ol style="text-align: left;"&gt;&lt;li&gt;Transition Probability: The probability of the model to transition from one hidden state to the other given the current state.&lt;/li&gt;&lt;li&gt;Emission Probability: The probability of the model to emit an observable state given the current hidden state.&lt;/li&gt;&lt;li&gt;Initial Probability: The probability of the model being in a specific hidden state when it starts off.&lt;/li&gt;&lt;/ol&gt;Graphically, HMM are represented using a Trellis Diagram:&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-X0NomdJBYBw/WiazLkBPx5I/AAAAAAAAKkc/_0NvEd5zbusO6j0JdQsYxHCdDrakQYlZACLcBGAs/s1600/TrellisDiagram.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="221" data-original-width="461" height="153" src="https://4.bp.blogspot.com/-X0NomdJBYBw/WiazLkBPx5I/AAAAAAAAKkc/_0NvEd5zbusO6j0JdQsYxHCdDrakQYlZACLcBGAs/s320/TrellisDiagram.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;There are four algorithms fundamental to HMM: Forward algorithm, Backward algorithm, Forward-Backward algorithm and Viterbi Algorithm.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Forward Algorithm:&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;Goal - To calculate &lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=P(Z_{k},X_{1:k})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?P(Z_{k},X_{1:k})" title="P(Z_{k},X_{1:k})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Using marginalization, &lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\sum_{Z_{k-1}}^{n}P(Z_{k},Z_{k-1},X_{1:k})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\sum_{Z_{k-1}}^{n}P(Z_{k},Z_{k-1},X_{1:k})" title="\sum_{Z_{k-1}}^{n}P(Z_{k},Z_{k-1},X_{1:k})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\sum_{Z_{k-1}}^{n}P(X_{k},X_{1:k-1},Z_{k},Z_{k-1})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\sum_{Z_{k-1}}^{n}P(X_{k},X_{1:k-1},Z_{k},Z_{k-1})" title="\sum_{Z_{k-1}}^{n}P(X_{k},X_{1:k-1},Z_{k},Z_{k-1})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\sum_{Z_{k-1}}^{n}P(X_{k}|X_{1:k-1},Z_{k},Z_{k-1})P(Z_{k}|Z_{k-1},X_{1:k-1})P(Z_{k-1},X_{1:k-1})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\sum_{Z_{k-1}}^{n}P(X_{k}|X_{1:k-1},Z_{k},Z_{k-1})P(Z_{k}|Z_{k-1},X_{1:k-1})P(Z_{k-1},X_{1:k-1})" title="\sum_{Z_{k-1}}^{n}P(X_{k}|X_{1:k-1},Z_{k},Z_{k-1})P(Z_{k}|Z_{k-1},X_{1:k-1})P(Z_{k-1},X_{1:k-1})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Since &lt;a href="https://www.codecogs.com/eqnedit.php?latex=X_{k}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?X_{k}" title="X_{k}" /&gt;&lt;/a&gt;, &lt;a href="https://www.codecogs.com/eqnedit.php?latex=X_{1:k-1}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?X_{1:k-1}" title="X_{1:k-1}" /&gt;&lt;/a&gt; and &lt;a href="https://www.codecogs.com/eqnedit.php?latex=Z_{k-1}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?Z_{k-1}" title="Z_{k-1}" /&gt;&lt;/a&gt; are independent, &lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\sum_{Z_{k-1}}^{n}P(X_{k}|Z_{k})P(Z_{k}|Z_{k-1})P(Z_{k-1},X_{1:k-1})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\sum_{Z_{k-1}}^{n}P(X_{k}|Z_{k})P(Z_{k}|Z_{k-1})P(Z_{k-1},X_{1:k-1})" title="\sum_{Z_{k-1}}^{n}P(X_{k}|Z_{k})P(Z_{k}|Z_{k-1})P(Z_{k-1},X_{1:k-1})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\alpha_{k}&amp;amp;space;=&amp;amp;space;\sum_{Z_{k-1}=1}^{n}(Emission&amp;amp;space;Probability)(Transition&amp;amp;space;Probability)\alpha_{k-1}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\alpha_{k}&amp;amp;space;=&amp;amp;space;\sum_{Z_{k-1}=1}^{n}(Emission&amp;amp;space;Probability)(Transition&amp;amp;space;Probability)\alpha_{k-1}" title="\alpha_{k} = \sum_{Z_{k-1}=1}^{n}(Emission Probability)(Transition Probability)\alpha_{k-1}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Backward Algorithm:&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;Goal - To calculate&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=P(X_{k+1:n}|Z_{k})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?P(X_{k+1:n}|Z_{k})" title="P(X_{k+1:n}|Z_{k})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Using marginalization, &lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\sum_{Z_{k+1}=1}^{n}P(X_{k+1},&amp;amp;space;X_{k+2:n},&amp;amp;space;Z_{k+1}|&amp;amp;space;Z_{k})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\sum_{Z_{k+1}=1}^{n}P(X_{k+1},&amp;amp;space;X_{k+2:n},&amp;amp;space;Z_{k+1}|&amp;amp;space;Z_{k})" title="\sum_{Z_{k+1}=1}^{n}P(X_{k+1}, X_{k+2:n}, Z_{k+1}| Z_{k})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\sum_{Z_{k+1}=1}^{n}P(X_{k+1}|&amp;amp;space;X_{k+2:n},&amp;amp;space;Z_{k+1},&amp;amp;space;Z_{k})P(X_{k+2:n}|&amp;amp;space;Z_{k+1},&amp;amp;space;Z_{k})P(Z_{k+1}|&amp;amp;space;Z_{k})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\sum_{Z_{k+1}=1}^{n}P(X_{k+1}|&amp;amp;space;X_{k+2:n},&amp;amp;space;Z_{k+1},&amp;amp;space;Z_{k})P(X_{k+2:n}|&amp;amp;space;Z_{k+1},&amp;amp;space;Z_{k})P(Z_{k+1}|&amp;amp;space;Z_{k})" title="\sum_{Z_{k+1}=1}^{n}P(X_{k+1}| X_{k+2:n}, Z_{k+1}, Z_{k})P(X_{k+2:n}| Z_{k+1}, Z_{k})P(Z_{k+1}| Z_{k})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\sum_{Z_{k+1}=1}^{n}P(X_{k+1}|&amp;amp;space;Z_{k+1})P(X_{k+2:n}|&amp;amp;space;Z_{k+1})P(Z_{k+1}|&amp;amp;space;Z_{k})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\sum_{Z_{k+1}=1}^{n}P(X_{k+1}|&amp;amp;space;Z_{k+1})P(X_{k+2:n}|&amp;amp;space;Z_{k+1})P(Z_{k+1}|&amp;amp;space;Z_{k})" title="\sum_{Z_{k+1}=1}^{n}P(X_{k+1}| Z_{k+1})P(X_{k+2:n}| Z_{k+1})P(Z_{k+1}| Z_{k})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\beta&amp;amp;space;_{k}&amp;amp;space;=&amp;amp;space;\sum_{Z_{k+1}=1}^{n}(Emission&amp;amp;space;Probability)\beta_{k+1}(Transition&amp;amp;space;Probability)" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\beta&amp;amp;space;_{k}&amp;amp;space;=&amp;amp;space;\sum_{Z_{k+1}=1}^{n}(Emission&amp;amp;space;Probability)\beta_{k+1}(Transition&amp;amp;space;Probability)" title="\beta _{k} = \sum_{Z_{k+1}=1}^{n}(Emission Probability)\beta_{k+1}(Transition Probability)" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Forward-Backward (Baum Welch) Algorithm:&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;Goal - To compute&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=P(Z_{k}|X)" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?P(Z_{k}|X)" title="P(Z_{k}|X)" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;where&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=X&amp;amp;space;=&amp;amp;space;(X_{1},&amp;amp;space;X_{2},..&amp;amp;space;X_{n})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?X&amp;amp;space;=&amp;amp;space;(X_{1},&amp;amp;space;X_{2},..&amp;amp;space;X_{n})" title="X = (X_{1}, X_{2},.. X_{n})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=P(Z_{k}|X)\propto&amp;amp;space;P(Z_{k},X)&amp;amp;space;=&amp;amp;space;P(X_{k+1:n}|Z_{k},X_{1:k})P(Z_{k},X_{1:k})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?P(Z_{k}|X)\propto&amp;amp;space;P(Z_{k},X)&amp;amp;space;=&amp;amp;space;P(X_{k+1:n}|Z_{k},X_{1:k})P(Z_{k},X_{1:k})" title="P(Z_{k}|X)\propto P(Z_{k},X) = P(X_{k+1:n}|Z_{k},X_{1:k})P(Z_{k},X_{1:k})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Here, &lt;a href="https://www.codecogs.com/eqnedit.php?latex=X_{k+1:n}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?X_{k+1:n}" title="X_{k+1:n}" /&gt;&lt;/a&gt; is independent of &lt;a href="https://www.codecogs.com/eqnedit.php?latex=X_{1:k}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?X_{1:k}" title="X_{1:k}" /&gt;&lt;/a&gt; given &lt;a href="https://www.codecogs.com/eqnedit.php?latex=Z_{k}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?Z_{k}" title="Z_{k}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=P(Z_{k},X)&amp;amp;space;=&amp;amp;space;P(X_{k+1:n}|Z_{k})P(Z_{k},X_{1:k})" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?P(Z_{k},X)&amp;amp;space;=&amp;amp;space;P(X_{k+1:n}|Z_{k})P(Z_{k},X_{1:k})" title="P(Z_{k},X) = P(X_{k+1:n}|Z_{k})P(Z_{k},X_{1:k})" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=P(Z_{k},X)&amp;amp;space;=&amp;amp;space;(Backward&amp;amp;space;Algorithm)(Forward&amp;amp;space;Algorithm)" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?P(Z_{k},X)&amp;amp;space;=&amp;amp;space;(Backward&amp;amp;space;Algorithm)(Forward&amp;amp;space;Algorithm)" title="P(Z_{k},X) = (Backward Algorithm)(Forward Algorithm)" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/1886062490513676810/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/12/hidden-markov-models-hmm-theoretical.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/1886062490513676810'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/1886062490513676810'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/12/hidden-markov-models-hmm-theoretical.html' title='Hidden Markov Models (HMM): Theoretical Background'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><media:thumbnail xmlns:media='http://search.yahoo.com/mrss/' url='https://4.bp.blogspot.com/-X0NomdJBYBw/WiazLkBPx5I/AAAAAAAAKkc/_0NvEd5zbusO6j0JdQsYxHCdDrakQYlZACLcBGAs/s72-c/TrellisDiagram.png' height='72' width='72'/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-5997800817393012575</id><published>2017-07-20T21:46:00.000-07:00</published><updated>2017-07-20T23:25:58.537-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Deep Learning - Not As Powerful As It Seems?</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;I recently came across a &lt;a href="https://blog.keras.io/the-limitations-of-deep-learning.html" target="_blank"&gt;blog&lt;/a&gt; post by Francois Chollet, the creator of Keras, where he explores the limitations of deep learning methods. It is an extremely informative blog piece, which I would recommend readers to go through before continuing further.&lt;br /&gt;&lt;br /&gt;I, personally, am guilty of over estimating the capabilities of deep learning for machine learning tasks. Theoretically, a recurrent neural network can be considered as a Turing Complete machine. To put it in a simpler phrase, every Turing Machine can be modeled by a recurrent neural network. In other words, any algorithm can be modeled using a recurrent neural network. Does this mean we don't need to learn algorithmic programming anymore and just throw enough sample training data to the neural net and let the net learn the algorithm? This is where the catch is. Neural networks are universal approximators. They can never leverage precision decision boundaries like an actual algorithm. They approximate the underlying function in order to produce outputs of varying precision. The phrase "varying precision" is of utmost importance since it can also represent a machine that is infinitely bad.&lt;br /&gt;&lt;br /&gt;In order to comprehend why deep learning is over hyped and may not perform up to our expectations, we need to dive deeper into how a neural net does what it does. Like Francios rightly pointed out, we tend to think of a neural net as a replica of a human brain, both in terms of form and functionality. This can be attributed to the similar nomenclature used in these two contexts. For example, both the brains and the neural nets consists of neurons that are central to the decision making process, where different neurons get fired in response to different data points (stimuli, for brain). But this is where the similarity ends. Human neurons are much complex and have the ability to handle a diverse set of stimuli. Neural nets neurons on the other hand are simple differentiable functions which just applies a non linearity to the input data. Although the neural nets are modeled on human brains and are ideally expected to mimic its functionality, the status quo suggests that we are way too primitive to achieve such performance.&lt;br /&gt;&lt;br /&gt;Deep learning methods are constrained in the geometric space. It is all about mapping one set of data in one vector space to another set of data in another vector space, one point at a time. There are two requisites for any deep learning model to perform well. One, availability of large (and by large, I mean very large) densely sampled, accurate data and the other is the existence of a learnable function. The requirement of a large set of training data is understood well by the public (thanks to the widespread media coverage). The other requirement of having a learnable function is more obscure and sometimes eludes the most seasoned deep learning engineer. This fact can be demonstrated by the below par performance of a neural net in as simple a task as sorting a list of numbers. Even after throwing millions of data points at it, it would still not perform well. Contrast this with the ability of a human brain to map the sorting function given a few examples.&lt;br /&gt;&lt;br /&gt;This weakness of the neural nets has been brought to the forefront in recent times with importance being given to the adversarial examples, where the neural nets can be fooled completely by addition of a different overlay over the input image. Although the images looks identical to any human being, the neural net is unable to comprehend each of them. This highlights the fact that humans and neural nets comprehend an image in a completely contrasting manner. This should drive home the fact that we should never expect the neural net to perform like a human brain (at least not in the near future).&lt;br /&gt;&lt;br /&gt;Francois also talks about Local and Extreme Generalizations. Deep learning methods are pretty good at local generalizations. They excel at mapping a narrow set of data points from one vector space to another vector space. When faced with a new data point far from the already encountered data points, the neural nets perform unpredictably. Human cognition, on the other hand, is adept at extreme generalizations, capable of applying cognition from one area into another seamlessly.&lt;br /&gt;&lt;br /&gt;The status quo is such that, we are trying to model a bike cruiser using lego blocks with a motor attached. Although the intentions and the end goal is to have a cruiser, we cannot expect a lego model to replace it. Hence, we should be cautious while estimating the performance of any deep learning method.&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/5997800817393012575/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/07/deep-learning-not-as-powerful-as-it.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/5997800817393012575'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/5997800817393012575'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/07/deep-learning-not-as-powerful-as-it.html' title='Deep Learning - Not As Powerful As It Seems?'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-8929267834066959687</id><published>2017-06-25T07:38:00.000-07:00</published><updated>2017-06-25T07:38:52.401-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Neural Embedding: Technique For Nonlinear Dimensionality Reduction</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;One of the major drawbacks of neural networks (or any machine learning model, in general) is the inability to handle data with huge dimensions, effectively. In this blog post, I will be exploring the technique of neural embedding, which is a variation on using auto-encoders for dimensionality reduction.&lt;br /&gt;&lt;br /&gt;Data with high dimensions pose a very unique problem to any statistical analyses as the volume of the vector space under consideration increases exponentially with increase in dimensionality. As the vector space increases exponentially, the number of data points has to grow exponentially in order to retain the statistical significance of the data. Else, the sparsity of the data increases which hinders the statistical analysis employed by a majority of machine learning algorithms. This problem is usually referred to as the&amp;nbsp;&lt;a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" target="_blank"&gt;Curse Of Dimensionality&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;There are numerous approaches for dimensionality reduction, with Principal Component Analysis (PCA) and Auto-Encoders being the most widely used methods for linear and non linear reduction respectively.&lt;br /&gt;&lt;br /&gt;Auto-Encoders are feed forward neural networks that are used to reduce the dimensions of the input vector and convert them from a sparse representation into a dense representation. The simplest of these encoders have a single hidden layer, consisting of neurons equal to the desired output dimensionality. The differentiating factor of auto-encoders from a normal feed forward neural network is that the target vector is the same as the input vector. The input-hidden weights are forced to learn the dense representations of sparse input vectors. The hidden-output weights are tuned in such a way that the dense representation can be used to reasonably recreate the input vector. Hence, the neural network is forced to reduce dimensions without losing information (much information, anyway). Thus, instead of using the high dimensioned input vector, feed it as input to the trained auto-encoder and use the hidden activation as the replacement for your machine learning applications. Auto-encoders can be as deep as you wish it to be. Sometimes, a single hidden layer is not enough to encode the input vector. In that case, we can have as many hidden layers as needed and the appropriate hidden layer activation can be considered as the dense representation of input vector.&lt;br /&gt;&lt;br /&gt;A variation of this technique is employed in Word2Vec, a widely used word embedding technique (&lt;a href="http://sujayskumar.blogspot.in/2017/03/exploring-word2vec_3.html" target="_blank"&gt;Exploring Word2Vec&lt;/a&gt;). Since the target vector in auto-encoders are same as the input vector, each data point is considered independent of each other i.e it is assumed that there is no semantic relation between the data points. On the contrary, as we know, words are semantically linked to each other, more so with the neighbouring words. Hence, in the case of Word2Vec, if the input vector is a vector representation of the current word, the target vector is the vector representation of the neighbouring word. This ensures that along with the dimensionality reduction of the vector representation, the neural net also preserves the semantic relation between neighbouring words. A classic case of two birds, one stone.&lt;br /&gt;&lt;br /&gt;We can further tweak the auto-encoders along the lines of Word2Vec in order to make the representation work for us, depending on the use case. We can replace the target vector with any suitable target variable (input vector itself in case of auto-encoders and the neighbouring word in case of Word2Vec). This serves the dual purpose of dimensionality reduction as well as establishing some semantics between data points. On a high level, we can view this as a clustering activity where the dense vectors with similar target values are clustered together in the reduced vector space. Since these vectors already embed some amount of semantic information within them, it becomes easier for other machine learning models to leverage this information and make better predictions.&lt;br /&gt;&lt;br /&gt;More information regarding non linear dimensionality reduction can be found at the following wiki page, which I think is very detailed: &lt;a href="https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction" target="_blank"&gt;Nonlinear Dimensionality Reduction.&lt;/a&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/8929267834066959687/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/06/neural-embedding-technique-for.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/8929267834066959687'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/8929267834066959687'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/06/neural-embedding-technique-for.html' title='Neural Embedding: Technique For Nonlinear Dimensionality Reduction'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-2090072747343859971</id><published>2017-06-12T01:29:00.000-07:00</published><updated>2017-06-12T01:29:19.821-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Generative Adversarial Networks (GAN)</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;In machine learning, there are two primary categories of models, generative models and discriminatory models. Discriminatory models strive to discriminate the given input into one or the other output classes depending on the type of input data. Whereas a generative model does not have a set of output classes that it has to categorize the data into. A generative model, as it's name suggests, tries to generate data that fits into the distribution exhibited by the input data. Mathematically, we can make the following conclusion. A discriminatory model calculates P(X|A) whereas a generative model calculates P(X,A).&lt;br /&gt;&lt;br /&gt;It is generally known that neural networks behave poorly in optimizing P(X,A) and are most widely used as a discriminatory model. The model of choice for any generative models have been Hidden Markov Models (HMMs) or Guassian Mixture Models (GMMs). This can be seen from the dominance of these in models in generative applications such as speech synthesis and audio generators. But with the recent developments in neural networks as generative models (especially Google's WaveNet), GANs have taken prominence in the ML domain.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;What are GANs?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;GANs are a combination of generative and discriminatory models working together to out-smart each other. Let us look into each of these components in turn.&lt;br /&gt;&lt;br /&gt;Problem Statement: Building a neural network that can generate an image as close as possible to a real world image.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Generator:&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;The goal of the generator is to predict 784 numbers (28X28 images of MNIST) that looks almost like the real image of numbers.&lt;br /&gt;&lt;br /&gt;The real images might follow some distribution (say Y distribution) in the real numbers space. The generator takes a random point from the Guassian distribution and tries to transform it in such a way as to fit it into the distribution followed by the real images. Now, let us break it down into bits. Guassian distribution is nothing but the distribution of random numbers. Hence, picking a point from a guassian distribution is analogous to picking a vector with random values. Hence, let us assume that the input vector space is of the dimension 100. Hence, the input to the generative model is a vector of size 100 having random values. The goal of the generator model is to take this vector and turn it into a real world image.&lt;br /&gt;&lt;br /&gt;Here, the problem becomes apparent that there is no set image to compare this generated image to. We need a model that can generate an image that is as close to a real world image as possible. This is where the discriminator model comes into picture.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Discriminator:&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;The goal of the discriminator is to be able to differentiate between the fake images generated by the generator and the real images. The input to the discriminator model is the 28X28 image and the output is a neuron indicating whether the image is a fake or a real image.&lt;br /&gt;&lt;br /&gt;The discriminator is trained by using a binary cross entropy as the cost function (as is the norm in a neural net for classification) and the most important part is that this error is back propagated to the generative model as well.&lt;br /&gt;&lt;br /&gt;This process of backpropagating the error to the generative model, forces the generator to produce images with more authenticity. Since the discriminator is trained to differentiate between the real and fake images and this error is propagted to the generator, the generator is forced to generate images matching the distributions of the real images.&lt;br /&gt;&lt;br /&gt;Now that the concept behind the GANs are clear, let us delve deeper into the technical aspects.&lt;br /&gt;&lt;br /&gt;Let the generative model be represented by G and the discriminatory model be represented by D. Since both of them are neural models, both G and D are differentiable functions that can be applied on the input. Let x be the input vector of dimension 100.&lt;br /&gt;&lt;br /&gt;z = G(x)&lt;br /&gt;y = D(z)&lt;br /&gt;&lt;br /&gt;where, y is the 1 or 0 indicating if the input image is real or not.&lt;br /&gt;&lt;br /&gt;Let &lt;sub&gt;G&lt;/sub&gt; and &lt;sub&gt;D&lt;/sub&gt; be the model parameters for G and D respectively. The cost function J&lt;sub&gt;G&lt;/sub&gt; of the generator and J&lt;sub&gt;D&lt;/sub&gt; of the discriminator depend both on &lt;sub&gt;G&lt;/sub&gt; and &lt;sub&gt;D&lt;/sub&gt;. But G does not have access to &lt;sub&gt;D&lt;/sub&gt; and D does not have access to &lt;sub&gt;G&lt;/sub&gt;. Therefore, we need to minimize J&lt;sub&gt;G&lt;/sub&gt; with respect to &lt;sub&gt;G&lt;/sub&gt; and J&lt;sub&gt;D&lt;/sub&gt; with respect to &lt;sub&gt;D&lt;/sub&gt; and both J&lt;sub&gt;G&lt;/sub&gt; and J&lt;sub&gt;D&lt;/sub&gt; must attain an equilibrium.&lt;br /&gt;&lt;br /&gt;As we know,&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/png.latex?\inline&amp;amp;space;J_{D}=-\frac{1}{2}\left&amp;amp;space;(&amp;amp;space;y_{i}log(p_{i})&amp;amp;space;+&amp;amp;space;(1-y_{i})log(1-p_{i})&amp;amp;space;\right&amp;amp;space;)" title="J_{D}=-\frac{1}{2}\left ( y_{i}log(p_{i}) + (1-y_{i})log(1-p_{i}) \right )" /&gt;&lt;br /&gt;&lt;br /&gt;&lt;img src="https://latex.codecogs.com/png.latex?\inline&amp;amp;space;J_{G}=-J_{D}" title="J_{G}=-J_{D}" /&gt;&lt;br /&gt;&lt;br /&gt;NOTE: The generator and the discriminator are trained in alternate cycles.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Generator Model:&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;Input Layer: Vector of dimension 100 &lt;br /&gt;Layer 1:&amp;nbsp; Dense Neurons (1024)&lt;br /&gt;Layer 2: Dense Neurons (128 * 7 * 7)&lt;br /&gt;Layer 3: Reshape Neurons (128 * 7 * 7) -&amp;gt; (128, 7, 7)&lt;br /&gt;Layer 4: Upsampling2D Neurons (2, 2) [ (128, 7, 7) -&amp;gt; (128, 14, 14) ]&lt;br /&gt;Layer 5: Convolution2D Neurons (64, 5, 5) with border=same&lt;br /&gt;Layer 6: Upsampling2D Neurons (2, 2) [ (128, 14, 14) -&amp;gt; (128, 28, 28) ]&lt;br /&gt;Layer 7: Convolution2D Neurons (1, 5, 5) with border=same&lt;br /&gt;&lt;br /&gt;At the end, as we can see, the output will be a (1, 28, 28) vector which is the same dimension as an MNIST image. Also, since all activations are relU, these pixel values would be either 0 or 1 i.e black or white.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Discriminator model:&amp;nbsp;&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;Input Layer: Vector of dimension (1, 28, 28)&lt;br /&gt;Layer 1: Convolution2D Neurons (64, 5, 5) with border=same&lt;br /&gt;Layer 2: MaxPooling2D Neurons with pool_size=(2, 2)&lt;br /&gt;Layer 3: Convolution2D Neurons (128, 5, 5) with border=same&lt;br /&gt;Layer 4: MaxPooling2D Neurons with pool_size=(2, 2)&lt;br /&gt;Layer 5: Flatten&lt;br /&gt;Layer 6:&amp;nbsp; Dense Neurons (1024)&lt;br /&gt;Layer 7: Dense Neurons (1)&lt;br /&gt;Activation: Sigmoid/tanh &lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/2090072747343859971/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/06/generative-adversarial-networks-gan.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/2090072747343859971'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/2090072747343859971'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/06/generative-adversarial-networks-gan.html' title='Generative Adversarial Networks (GAN)'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-1208365884481265384</id><published>2017-04-23T00:00:00.002-07:00</published><updated>2017-04-23T00:03:47.629-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Machine Learning: From The Realm of Academia To Industry</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;One of the most striking observation I made in the past couple of years in the Machine Learning domain is the gradual shift in the demographics of ML Engineers from academia to that of the industry.&lt;br /&gt;&lt;br /&gt;A couple of years ago, ML and AI applications were built by a group consisting predominantly of academicians and researchers in the ML domain. This could be seen from the mass hiring of entire ML departments, students and teachers included, of colleges like MIT by companies like Google, Apple etc. &lt;br /&gt;&lt;br /&gt;The main reason for this could be attributed to the niche factor of the applications of ML during the formative years of ML in the software industry. Most of the ML models that these researchers were hired to build were highly niche, project specific and turnkey products that were not extendible. This had a ripple effect on the ML industry where there was no incentive for building any frameworks with extendible functionality for building ML models. Thus, in order to build any ML model, every component had to be built from ground up using first principles. This discouraged adoption from the engineers in the industry who are always looking for easy solutions for fast prototyping and not spend months building a certain model. Thus, ML was relegated to the experimental section of the projects in  the mainstream software industry, where not much importance was given  to the necessity of such applications. &lt;br /&gt;&lt;br /&gt;This was the situation for a long time before Google made the decision to build TensorFlow and make it open source. As ML applications gradually took a turn from being niche products to being ubiquitous, there was more and more demand for a reusable, extendible framework where focus was on rapid prototyping rather than on building the components from scratch.&lt;br /&gt;&lt;br /&gt;If the realm of ML applications is observed from a birds' eye, most of the components are inherently reusable. Be it the neurons in a Neural Network, or the Decision Nodes in a Decision Tree, every component implements a predefined function that remains constant irrespective of the use case for which the model is being built. This led to the explosive adaptation of ML frameworks such as TensorFlow, Theano or Caffe. Now, the focus shifted from "how to build the module" to "what module to add to the model". Building a ML model was reduced to playing with pre-built modules, similar to playing around with Lego blocks.&lt;br /&gt;&lt;br /&gt;With the advent of even higher level of abstraction over these frameworks like Keras, building an ML model became even simpler. There is increased penetration of these technologies in the software industry with engineers with no formal degree in ML or statistics trying their hands on ML applications.&lt;br /&gt;&lt;br /&gt;With the release of TensorFlow v1.0 and the in built support for Keras, I believe that there would be a noticeable shift in the demographic of people building ML applications. It will no longer be dominated by researchers/academicians. Rather, it will be widely accepted by the industry as well as the developers, along the lines of web/mobile development. Thus leading to the shift from "Machine Learning Scientist" to "Machine Learning Developer".&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/1208365884481265384/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/04/machine-learning-from-realm-of-academia.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/1208365884481265384'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/1208365884481265384'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/04/machine-learning-from-realm-of-academia.html' title='Machine Learning: From The Realm of Academia To Industry'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-2750000337812608207</id><published>2017-03-03T08:25:00.000-08:00</published><updated>2017-03-03T08:25:01.960-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Exploring Word2Vec</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;In my previous blog post, I explored some of the early ways of word embeddings and their shortcomings. The purpose of this post is to explore one of the most widely used word representations in the natural language processing industry today.&lt;br /&gt;&lt;br /&gt;Word2Vec was created by a team of researchers led by Tomas Mikolov at Google. According to Wikipedia,&lt;br /&gt;&lt;blockquote class="tr_bq"&gt;&lt;i&gt;&lt;b&gt;Word2vec&lt;/b&gt; is a group of related models that are used to produce &lt;a href="https://www.blogger.com/null" title="Word embedding"&gt;word embeddings&lt;/a&gt;. These models are shallow, two-layer &lt;a class="mw-redirect" href="https://www.blogger.com/null" title="Neural network"&gt;neural networks&lt;/a&gt; that are trained to reconstruct linguistic contexts of words. Word2vec  takes as its input a large corpus of text and produces a &lt;a href="https://www.blogger.com/null" title="Vector space"&gt;vector space&lt;/a&gt;, typically of several hundred &lt;a class="mw-redirect" href="https://www.blogger.com/null" title="Dimensions"&gt;dimensions&lt;/a&gt;, with each unique word in the &lt;a href="https://www.blogger.com/null" title="Corpus linguistics"&gt;corpus&lt;/a&gt; being assigned a corresponding vector in the space. &lt;a class="mw-redirect" href="https://www.blogger.com/null" title="Word vectors"&gt;Word vectors&lt;/a&gt; are positioned in the vector space such that words that share common  contexts in the corpus are located in close proximity to one another in  the space.&lt;/i&gt;&lt;/blockquote&gt;There are many resources on the internet providing a detailed mathematical explanation and derivations of Word2Vec and the reason why they perform so well. I have included links to some of them at the end of this post. The purpose of this post is to explore Word2Vec in a graphical manner in order to get an intuitive feel of how Word2Vec works, what the vectors mean and why they perform so well.&lt;br /&gt;&lt;br /&gt;Let us look at the equation proposed by Mikolov,&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-4bCMkA62ZmU/WLcAPOxR8cI/AAAAAAAAIwI/6AakzRa7HoIdTHgV1pmm_D-idqZ5hxwbwCLcB/s1600/equation.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="152" src="https://2.bp.blogspot.com/-4bCMkA62ZmU/WLcAPOxR8cI/AAAAAAAAIwI/6AakzRa7HoIdTHgV1pmm_D-idqZ5hxwbwCLcB/s640/equation.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;As we can see from the equation, it is nothing but a softmax equation.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Intuitively, we can visualize the model as follows. The main operation being performed here is that of dimensionality reduction. We have seen the usage of neural networks for dimensionality reduction in &lt;i&gt;auto-encoders&lt;/i&gt;. In auto-encoders, we trick the neural network to learn compressed representations of vectors by providing the same vector as both input and target. In this way, the neural network learns to reproduce a vector from a compressed representation. Hence, we can replace the high dimension input vectors by their lower dimension hidden activations (Or weight matrices).&lt;br /&gt;&lt;br /&gt;Similarly, in Word2Vec we trick the "neural net" to learn smaller dimensions representations of the huge dimensioned one hot vector.&lt;br /&gt;&lt;br /&gt;But unlike in auto-encoders, we do not provide the same vector as both target and input vector. Although this can be used to reduce dimensions, we need to capture the syntactic and semantic meaning of every word. In order to accomplish that, we need to consider a window of words around the current word (context). How do we add this context to the representation of the current word? We make the neural net predict the current word given its context (CBOW) or to predict the context given the current word (Skip Gram).&lt;br /&gt;&lt;br /&gt;Once the neural net is trained to predict a word given it's context, we are going to strip off the hidden-output connections (just like auto-encoders) and use the trained weight matrix between input and hidden as vector representations (just like auto-encoders)&lt;br /&gt;&lt;br /&gt;Graphically, the model can be visualized as follows:&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-yjUf2gPE_4E/WLcAYtoeluI/AAAAAAAAIwM/ylH_M991FIwYdxjq9CpQ2kD9OeTUT2ItgCLcB/s1600/word2vec_arch.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="506" src="https://1.bp.blogspot.com/-yjUf2gPE_4E/WLcAYtoeluI/AAAAAAAAIwM/ylH_M991FIwYdxjq9CpQ2kD9OeTUT2ItgCLcB/s640/word2vec_arch.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;V - Vocabulary Size&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;H - Size of Word2Vec vector&amp;nbsp;&lt;/span&gt; &lt;br /&gt;&lt;br /&gt;There is a distinct difference between the above model and a normal feed forward neural network. The hidden layer in Word2Vec are linear neurons i.e there is no activation function applied on the hidden activations.&lt;br /&gt;&lt;br /&gt;Also, we can see that the dimensions of input layer and the output layer is equal to the vocabulary size. The hidden layer dimension is the size of the vector which represents a word (which is a tunable hyper-parameter).&lt;br /&gt;&lt;br /&gt;Now, let us take an example in order to understand this better and we'll go through each layer separately. &lt;br /&gt;&lt;blockquote class="tr_bq"&gt;&lt;h4 style="text-align: left;"&gt;&lt;i&gt;&lt;span class="inline_editor_value"&gt;&lt;span class="rendered_qtext"&gt;"The night is darkest just before the dawn rises"&lt;/span&gt;&lt;/span&gt;&lt;/i&gt;&lt;/h4&gt;&lt;/blockquote&gt;From the above corpus we can see that the vocabulary size is 8.&lt;br /&gt;For simplicity, let us make the following assumptions:&lt;br /&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;Window size = 1&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;Word2Vec dimension = 3&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;The initial one-hot representations will be&lt;br /&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;The&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; - [1,0,0,0,0,0,0,0]&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;night&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; - [0,1,0,0,0,0,0,0]&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;is&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; - [0,0,1,0,0,0,0,0]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;darkest&amp;nbsp;&amp;nbsp;&amp;nbsp; - [0,0,0,1,0,0,0,0]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;just&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; - [0,0,0,0,1,0,0,0]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;before&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; - [0,0,0,0,0,1,0,0]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;dawn&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; - [0,0,0,0,0,0,1,0]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;rises&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; - [0,0,0,0,0,0,0,1]&lt;/span&gt;&amp;nbsp;&lt;/span&gt;&amp;nbsp;&lt;/span&gt;&amp;nbsp;&lt;/span&gt;&amp;nbsp;&lt;/span&gt;&amp;nbsp;&lt;/span&gt;&amp;nbsp;&lt;/span&gt;&amp;nbsp;&lt;/span&gt; &lt;br /&gt;&lt;br /&gt;Let us consider the following scenario, where the current word is &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;darkest&lt;/span&gt; and the context word is &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;just&lt;/span&gt;. Let us assume that this is a Continuous Bag Of Words (CBOW) model where we predict the current word given the context words.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Input Layer:&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;Word: &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;just&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;Vector: &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;[0,0,0,0,1,0,0,0]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Hidden Layer:&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;Dimension = 3&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;W&lt;sub&gt;input-hidden&lt;/sub&gt;&lt;/span&gt; is of dimension &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;8X3&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;W&lt;sub&gt;hidden-output&lt;sub&gt;&lt;/sub&gt;&lt;/sub&gt;&lt;/span&gt; is of dimension &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;3X8&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;Since the input is a one-hot vector, the hidden activation is just a lookup operation. That is, hidden activation just looks up the row corresponding to the word ID in &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;W&lt;sub&gt;input-hidden&lt;/sub&gt;&lt;/span&gt; and passes it on to the output layer. As an illustration,&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-PEbbeRo97F4/WLcAlo7zFlI/AAAAAAAAIwQ/LtxSJwJb-nA4K6WAMG3rekML_VXKtAWKgCLcB/s1600/matrix.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="150" src="https://1.bp.blogspot.com/-PEbbeRo97F4/WLcAlo7zFlI/AAAAAAAAIwQ/LtxSJwJb-nA4K6WAMG3rekML_VXKtAWKgCLcB/s640/matrix.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;b&gt;Output Layer:&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;Target word - &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;dar&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;kest&lt;/span&gt;&lt;/span&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;[0,0,0,1,0,0,0,0]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;Since the output layer is a &lt;i&gt;softmax&lt;/i&gt; layer, it produces a probability distribution across the words. Thus, the categorical logloss is calculated (and since this is a softmax, the error is just the difference between the target vector and the output vector). This error is then back propagated to the hidden layer.&lt;br /&gt;&lt;br /&gt;As you might have noticed, this procedure gives us two trained parameters. The &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;W&lt;sub&gt;input-hidden&lt;/sub&gt;&lt;/span&gt; and &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;W&lt;sub&gt;hidden-output&lt;/sub&gt;&lt;/span&gt;. Usually, &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;W&lt;sub&gt;hidden-output&lt;/sub&gt;&lt;/span&gt; is discarded.&lt;br /&gt;&lt;br /&gt;In the Mikolov's equation we saw above, &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;V&lt;sub&gt;w&lt;/sub&gt;&lt;/span&gt; is the &lt;b&gt;&lt;i&gt;inner representation&lt;/i&gt;&lt;/b&gt; of the word i.e from &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;W&lt;sub&gt;input-hidden&lt;/sub&gt;&lt;/span&gt; and &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;V&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif;"&gt;&lt;sup&gt;I&lt;/sup&gt;&lt;/span&gt;&lt;sub&gt;w&lt;/sub&gt;&lt;/span&gt; is the &lt;b&gt;&lt;i&gt;outer representation&lt;/i&gt;&lt;/b&gt; of the word i.e from &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;W&lt;sub&gt;hidden-output&lt;/sub&gt;&lt;/span&gt;.&lt;br /&gt;&lt;br /&gt;&lt;i&gt;Inner representation&lt;/i&gt; is nothing but the representation of the word when it is the current word and &lt;i&gt;outer representation&lt;/i&gt; is when the word occurs in the window of another word.&lt;br /&gt;&lt;br /&gt;After the training process, the &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;W&lt;sub&gt;input-hidden&lt;/sub&gt;&lt;/span&gt; is just a lookup table, given the index, it returns the 3 bit &lt;i&gt;inner representation&lt;/i&gt; of the word. Similarly, &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;W&lt;sub&gt;hidden-output&lt;/sub&gt;&lt;/span&gt; is a lookup table for the &lt;i&gt;outer representation&lt;/i&gt; of the word.&lt;br /&gt;&lt;br /&gt;&lt;a href="https://4.bp.blogspot.com/-c8hMWWJlLYE/WLcFZ3dTqpI/AAAAAAAAIwk/vbvq5k-x_VUhGq5C823je2Iqj634KCnTgCLcB/s1600/lookup%25282%2529.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="416" src="https://4.bp.blogspot.com/-c8hMWWJlLYE/WLcFZ3dTqpI/AAAAAAAAIwk/vbvq5k-x_VUhGq5C823je2Iqj634KCnTgCLcB/s640/lookup%25282%2529.png" width="640" /&gt;&lt;/a&gt; &lt;br /&gt;&amp;nbsp; &lt;br /&gt;&lt;b&gt;Why does this work?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;This method accomplishes dual task of reducing the dimensionality and adding semantic meaning to the word.&lt;i&gt; How?&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;Let us take 2 pairs of words. &lt;i&gt;('Computers', 'ML')&lt;/i&gt; and &lt;i&gt;('NFL', 'Kobe')&lt;/i&gt;. If we look at the above pairs, we can see that &lt;i&gt;'Computers'&lt;/i&gt; and &lt;i&gt;'ML'&lt;/i&gt; occur in the same context in the corpus. Hence, the representations of the words &lt;i&gt;'Computers'&lt;/i&gt; and &lt;i&gt;'ML'&lt;/i&gt; will be very close to each other (cosine similarity). Whereas, there is no way &lt;i&gt;'NFL'&lt;/i&gt; would be a part of a discussion about &lt;i&gt;'ML'&lt;/i&gt; (Although there is a Kobe challenge on Kaggle, which we are assuming is absent from the corpus) and hence the similarity between them will be very low. Since the context will be similar to &lt;i&gt;'Computer'&lt;/i&gt; and &lt;i&gt;'ML'&lt;/i&gt; and &lt;i&gt;'NFL'&lt;/i&gt; and &lt;i&gt;'Kobe'&lt;/i&gt;, the neural net is forced to learn similar representations for each of these pairs.&lt;br /&gt;&lt;br /&gt;This also handles stemming on a certain level, as &lt;i&gt;'Computers'&lt;/i&gt; and &lt;i&gt;'Computer'&lt;/i&gt; occur in the same context and can be interchanged. This also has the ability to handle acronyms. Since &lt;i&gt;'ML'&lt;/i&gt; and &lt;i&gt;'Machine'&lt;/i&gt; and &lt;i&gt;'Learning'&lt;/i&gt; occur in the same contexts, all 3 words will have similar representations.&lt;br /&gt;&lt;br /&gt;One important thing to note is that Word2Vec does &lt;i&gt;not&lt;/i&gt; consider the positional variable of the context words i.e whether the word &lt;i&gt;'Learning'&lt;/i&gt; comes before &lt;i&gt;'Machine'&lt;/i&gt; or after is immaterial to the model. It does not learn a different vector for &lt;i&gt;'Learning'&lt;/i&gt; when it occurs before &lt;i&gt;'Machine'&lt;/i&gt; or after.&lt;br /&gt;&lt;br /&gt;Here are some of the resources where you can find the detailed mathematical derivation for Word2Vec:&lt;br /&gt;&lt;br /&gt;&lt;a href="http://www.1-4-5.net/~dmm/ml/how_does_word2vec_work.pdf"&gt;http://www.1-4-5.net/~dmm/ml/how_does_word2vec_work.pdf&lt;/a&gt;&lt;br /&gt;&lt;a href="http://www-personal.umich.edu/~ronxin/pdf/w2vexp.pdf"&gt;http://www-personal.umich.edu/~ronxin/pdf/w2vexp.pdf&lt;/a&gt;&lt;br /&gt;&lt;a href="https://cs224d.stanford.edu/lectures/CS224d-Lecture2.pdf"&gt;https://cs224d.stanford.edu/lectures/CS224d-Lecture2.pdf&lt;/a&gt; &lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/2750000337812608207/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/03/exploring-word2vec_3.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/2750000337812608207'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/2750000337812608207'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/03/exploring-word2vec_3.html' title='Exploring Word2Vec'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><media:thumbnail xmlns:media='http://search.yahoo.com/mrss/' url='https://2.bp.blogspot.com/-4bCMkA62ZmU/WLcAPOxR8cI/AAAAAAAAIwI/6AakzRa7HoIdTHgV1pmm_D-idqZ5hxwbwCLcB/s72-c/equation.png' height='72' width='72'/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-5039229006551454409</id><published>2017-02-28T21:41:00.001-08:00</published><updated>2017-02-28T21:41:52.074-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Word Embedding: Techniques</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;One of the most important aspects of any Natural Language Processing is the representation of the words. This throws up a unique problem of how to represent words in vector form. Words are ambiguous and can have multiple, complex relationships with other words. Additionally, the number of words in the vocabulary of any given language is in hundreds of thousands of magnitude.&lt;br /&gt;&lt;br /&gt;One of the earliest attempts at word representation was made by WordNet, where each word was represented discretely and the relationships were established between words through hypernyms, synonyms etc. One of the main disadvantages of this setup was the amount of human intervention required to keep this corpus up-to-date. For a community that thrives on automation, this was just unacceptable. Additionally, this building of corpus was specific to a language. Building the corpus for any other language would require as much, if not more, effort and human intervention. Hence, this was not scalable.&lt;br /&gt;&lt;br /&gt;Another discrete representation is one-hot representation (i.e creation of dummy variables). This is just a vector of size equal to the vocabulary size and each word is assigned an index. The one-hot vector of a word will be a vector filled with 0s with it's index bit set to 1. This representation also suffers from the same drawbacks as mentioned above. The vocabulary size of Google's corpus is about 13M. Hence each word would be required to be represented by a sparse vector of dimension 13M.&lt;br /&gt;&lt;br /&gt;Another disadvantage of a one-hot representation is the underlying assumption that each word in the vocabulary is independent of each other, which is not the case. Since each word is represented by an arbitrary index, we cannot establish any implicit relationships between words.&lt;br /&gt;&lt;br /&gt;In order to capture the semantics of any word and it's relationship to any other word, we need to look at the context in which the word appears. According to Richard Socher,&lt;br /&gt;&lt;blockquote class="tr_bq"&gt;&lt;i&gt;"You shall know a word by the company it keeps"&lt;/i&gt;&lt;/blockquote&gt;This gives us the idea that the representation of any word should be some function of the words surrounding the current word. One of the most intuitive ways of doing this is to use a co-occurrence matrix. This matrix just counts the number of times the current word is surrounded by another word.&lt;br /&gt;&lt;br /&gt;There are two ways of taking the neighbours into account. One is to consider the document level frequency, where word frequencies are captured across documents. Second is to localize the context into neighbouring words (called windows). It is proven that the window based approach is better as it is capable of capturing both syntactic (Part-of-Speech) and semantic information.&lt;br /&gt;&lt;br /&gt;The following is an example from Socher's slides, which better illustrates the co-occurrence matrix (for a window of size 1):&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-dDZaar5q1mM/WLZYCt9Nt7I/AAAAAAAAIu4/q3QM3PnmEz8Ti0CUh5pfI-nQh9GvBNQPQCLcB/s1600/co-occurence.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="441" src="https://4.bp.blogspot.com/-dDZaar5q1mM/WLZYCt9Nt7I/AAAAAAAAIu4/q3QM3PnmEz8Ti0CUh5pfI-nQh9GvBNQPQCLcB/s640/co-occurence.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;One of the drawbacks of using co-occurrence matrix is that some words  like '&lt;i&gt;is&lt;/i&gt;', '&lt;i&gt;the&lt;/i&gt;', '&lt;i&gt;at&lt;/i&gt;'&amp;nbsp; etc, which have a high frequency of occurrence in a  corpus can skew the importance of features towards themselves. Easiest  way of overcoming this is to remove the stop-words and cap the maximum  frequency of occurrence of any word.&lt;br /&gt;&lt;br /&gt;Another improvement to the window method is to use a ramped window method where more importance is given to the words immediately next to the current word, than words which are much further away.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-yJ_TRtEAXow/WLZeJ6TtdsI/AAAAAAAAIvo/_CYBzrGyWgEglq7PsfJPiVS3lXiKTRgxwCLcB/s1600/ramped%25281%2529.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="202" src="https://1.bp.blogspot.com/-yJ_TRtEAXow/WLZeJ6TtdsI/AAAAAAAAIvo/_CYBzrGyWgEglq7PsfJPiVS3lXiKTRgxwCLcB/s640/ramped%25281%2529.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;Using this method, we can capture the semantics of the word up to some extent. But this method does not solve the problem of huge dimensionality of the word vector. It still remains the size of the vocabulary.&lt;br /&gt;&lt;br /&gt;In order to reduce the dimension of the vector, we can leverage the age old linear algebraic method of Singular Value Decomposition (SVD).&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-77VSnIqRig4/WLZcDJfLFnI/AAAAAAAAIvU/xCLB7E6BT1YPpp0O6EKnSk_JZfZ_jD86ACLcB/s1600/SVD.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="240" src="https://3.bp.blogspot.com/-77VSnIqRig4/WLZcDJfLFnI/AAAAAAAAIvU/xCLB7E6BT1YPpp0O6EKnSk_JZfZ_jD86ACLcB/s640/SVD.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;From Socher's slides,&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-iFMJVlOnL90/WLZcWC95oYI/AAAAAAAAIvY/q4h6gaJmN4wf2BY-Nd2ktgYWRTR9FwfAgCLcB/s1600/svd.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="348" src="https://2.bp.blogspot.com/-iFMJVlOnL90/WLZcWC95oYI/AAAAAAAAIvY/q4h6gaJmN4wf2BY-Nd2ktgYWRTR9FwfAgCLcB/s640/svd.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;Here, S1, S2...Sn are arranged according to the importance of the dimensions.&lt;br /&gt;&lt;br /&gt;Although SVD is a simple way of reducing the dimensionality of the vector, it is computationally very expensive and it is difficult to add new words to the vocabulary (Since the matrix has to be decomposed every time the input matrix changes).&lt;br /&gt;&lt;br /&gt;Hence, we use Word2Vec, a pseudo-neural approach of solving dimension reduction while preserving the semantic information of a co-occurrence matrix. There will be a separate post exploring Word2Vec in detail.&lt;br /&gt;&lt;br /&gt;For more reference, refer Socher's slides at: &lt;a href="https://cs224d.stanford.edu/lectures/CS224d-Lecture2.pdf" target="_blank"&gt;Stanford: Word Vectors&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/5039229006551454409/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/word-embedding-techniques.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/5039229006551454409'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/5039229006551454409'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/word-embedding-techniques.html' title='Word Embedding: Techniques'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><media:thumbnail xmlns:media='http://search.yahoo.com/mrss/' url='https://4.bp.blogspot.com/-dDZaar5q1mM/WLZYCt9Nt7I/AAAAAAAAIu4/q3QM3PnmEz8Ti0CUh5pfI-nQh9GvBNQPQCLcB/s72-c/co-occurence.png' height='72' width='72'/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-3782427282211978842</id><published>2017-02-27T09:52:00.000-08:00</published><updated>2017-02-27T09:52:26.659-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>R-squared To Evaluate A Regression Model</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div&gt;Evaluating a classification model is fairly straightforward and simple. You just count how many of the classifications the model got right and how many it didn't.&lt;br /&gt;&lt;br /&gt;Evaluating a regression model is not that straightforward, at least from my perspective. One of the useful metric that is used by a majority of the implementations is R-squared.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;What is R-squared?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;R-squared is a goodness-of-fit test in order to evaluate how good your model fits the data. It is also known as the coefficient of determination, or the coefficient of multiple determination for multiple regression.&lt;br /&gt;&lt;br /&gt;I know the terms might be a bit overwhelming, like the majority of statistical terms, but the explanation is quite simple. It is the percentage of variation from the mean that the model can explain. In simpler words, R-squared shows how much of the variance from the mean is explained by the model.&lt;br /&gt;&lt;br /&gt;Consider a set of points in the target set, given by&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\bg_white&amp;amp;space;y_{1},y_{2},y_{3}...y_{n}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\bg_white&amp;amp;space;y_{1},y_{2},y_{3}...y_{n}" title="y_{1},y_{2},y_{3}...y_{n}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Now, consider the set of predicted points&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\bg_white&amp;amp;space;f_{1},f_{2},f_{3}...f_{n}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\bg_white&amp;amp;space;f_{1},f_{2},f_{3}...f_{n}" title="f_{1},f_{2},f_{3}...f_{n}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Let &lt;a href="https://www.codecogs.com/eqnedit.php?latex=\inline&amp;amp;space;\bg_white&amp;amp;space;\bar{y}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\inline&amp;amp;space;\bg_white&amp;amp;space;\bar{y}" title="\bar{y}" /&gt;&lt;/a&gt; be the mean of y.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;The mean variance of the data is given by,&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\bg_white&amp;amp;space;SS_{tot}&amp;amp;space;=&amp;amp;space;\sum&amp;amp;space;(y_{i}-\bar{y})^{2}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\bg_white&amp;amp;space;SS_{tot}&amp;amp;space;=&amp;amp;space;\sum&amp;amp;space;(y_{i}-\bar{y})^{2}" title="SS_{tot} = \sum (y_{i}-\bar{y})^{2}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;The explained variance by the model is given by,&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\bg_white&amp;amp;space;SS_{reg}&amp;amp;space;=&amp;amp;space;\sum&amp;amp;space;(f_{i}-\bar{y})^{2}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\bg_white&amp;amp;space;SS_{reg}&amp;amp;space;=&amp;amp;space;\sum&amp;amp;space;(f_{i}-\bar{y})^{2}" title="SS_{reg} = \sum (f_{i}-\bar{y})^{2}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Consequently, the unexplained variance by the model is given by,&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\bg_white&amp;amp;space;SS_{reg}&amp;amp;space;=&amp;amp;space;\sum&amp;amp;space;(y_{i}-f_{i})^{2}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\bg_white&amp;amp;space;SS_{reg}&amp;amp;space;=&amp;amp;space;\sum&amp;amp;space;(y_{i}-f_{i})^{2}" title="SS_{reg} = \sum (y_{i}-f_{i})^{2}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Hence, the definition for R-squared is as follows,&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\bg_white&amp;amp;space;R^{2}\equiv&amp;amp;space;1-\frac{SS_{res}}{SS_{tot}}" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\bg_white&amp;amp;space;R^{2}\equiv&amp;amp;space;1-\frac{SS_{res}}{SS_{tot}}" title="R^{2}\equiv 1-\frac{SS_{res}}{SS_{tot}}" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;From the above equation, we can see that the value of R-squared lies between 0 and 1. 1 indicating that the model fits the data perfectly and 0 indicating that the model is unable to explain any variation from the mean. Thus we can safely assume that higher the value of R-squared, better the model is.&lt;br /&gt;&lt;br /&gt;&lt;i&gt;BUT, THIS IS NOT ENTIRELY TRUE.&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;Some of the scenarios where this metric cannot be used are: &lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;R-squared cannot be used as an evaluation metric for any non linear regression models. Although it might throw some light on the performance of the model, it is mathematically not a suitable metric for non linear regression. Most of the non linear regression libraries still provide R-squared as an evaluation metric for reasons unknown.&lt;/li&gt;&lt;li&gt;The value of R-squared can be negative, as the model can be infinitely bad.&lt;/li&gt;&lt;li&gt;As we add new variables to the linear regression model, the least squares error decreases. This leads to an increase in the R-squared value. As we can see, R-squared is an increasing function of number of variables. Hence, we cannot truly compare two models with different number of variables on this metric.&lt;/li&gt;&lt;li&gt;As a corollary to the previous point, adding new variables (irrespective of their applicability to the problem) always increases. This does not necessarily mean that the model is better. In such cases, adjusted R-squared is a better metric.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/3782427282211978842/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/r-squared-to-evaluate-regression-model.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/3782427282211978842'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/3782427282211978842'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/r-squared-to-evaluate-regression-model.html' title='R-squared To Evaluate A Regression Model'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-8006134997865210221</id><published>2017-02-26T07:26:00.001-08:00</published><updated>2017-02-26T07:26:37.358-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Out of Bag and k-Fold Validation </title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Two of the main validation techniques for CART models are Out-Of-Bag (OOB) validation and k-Fold validation.&lt;br /&gt;&lt;br /&gt;OOB - Used mainly for Random Forests.&lt;br /&gt;k-Fold - Used mainly for XGB models&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Out-Of-Bag (OOB) Validation:&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;OOB validation is a technique where each tree sample not used in the construction of the current tree becomes the test set for the current tree.&lt;br /&gt;&lt;br /&gt;As we know, in a random forest, a random selection of data and/or variables is chosen as a subset for training for each tree. This means that only a sample of the entire training set is used for training a tree. The remaining points belong to the out-of-bag set and is used for validation.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;k-Fold Cross Validation:&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;Keeping a fixed set of data points for validation might not be conducive for models like XGB. Hence, a k-fold validation is used. In a k-fold method, the entire dataset is divided into k folds. One of the fold is used for validation and the others are used for training. The final performance metric is the average of the metric of each fold.&lt;br /&gt;&lt;br /&gt;Usually, the number of folds is taken to be 10.&lt;br /&gt;&lt;br /&gt;The following illustration better explains a 10-fold cross validation.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-KgZmViuVUkI/WLLzWZgtfsI/AAAAAAAAIug/aFSTZhvaF90nrjQucGmUvi9PiBx_61XUgCLcB/s1600/k-fold.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="225" src="https://1.bp.blogspot.com/-KgZmViuVUkI/WLLzWZgtfsI/AAAAAAAAIug/aFSTZhvaF90nrjQucGmUvi9PiBx_61XUgCLcB/s400/k-fold.png" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/8006134997865210221/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/out-of-bag-and-k-fold-validation.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/8006134997865210221'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/8006134997865210221'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/out-of-bag-and-k-fold-validation.html' title='Out of Bag and k-Fold Validation '/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><media:thumbnail xmlns:media='http://search.yahoo.com/mrss/' url='https://1.bp.blogspot.com/-KgZmViuVUkI/WLLzWZgtfsI/AAAAAAAAIug/aFSTZhvaF90nrjQucGmUvi9PiBx_61XUgCLcB/s72-c/k-fold.png' height='72' width='72'/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-503820693988228126</id><published>2017-02-26T07:11:00.000-08:00</published><updated>2017-02-26T07:27:08.438-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Decision Trees, Random Forests and XGBoost</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;Decision Trees are one of the most intuitive models in the world of perplexing and obscure ML models. This is because of the similarity in the human decision making process and a decision tree.&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; A decision tree can be visualized and we can actually see how a computer arrived at a decision, which is rather difficult in case of other models. Hence, it is also called as a white box model.&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; The purpose of this post is to explore some of the intuition behind building a stand alone decision tree and it's ensemble variants, &lt;i&gt;Random Forests (RF)&lt;/i&gt; and &lt;i&gt;Extreme Gradient Boosting (XGB)&lt;/i&gt;.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Decision Trees:&lt;/b&gt;&lt;br /&gt;&lt;b&gt;What is a Decision Tree?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;A decision tree is a tree in which each node denotes a decision and the corresponding path to take depending on the decision made.&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; Decision trees are versatile and are widely used for both classification and regression models and are called CART (Classification and Regression Trees).&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; One of the main advantages of a decision tree is it's ability to handle missing data gracefully.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;How is a decision tree built?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;There are two metrics on which a decision tree is built, &lt;i&gt;Information Gain&lt;/i&gt; and &lt;i&gt;Standard Deviation&lt;/i&gt;. Information gain is used to build a classification tree and standard deviation is used to build a regression tree.&lt;br /&gt;&lt;br /&gt;In this post, I will be using a regression tree as an example.&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;Decision tree is built in a top down approach.&lt;/li&gt;&lt;li&gt;The goal of a tree is to partition the data into subsets such that each subset contains homogeneous values (with same target classes in case of classification and with minimum standard deviation in case of regression).&lt;/li&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\bg_white&amp;amp;space;S(T)&amp;amp;space;=&amp;amp;space;\sqrt{\frac{\sum&amp;amp;space;(x-\mu&amp;amp;space;)^{2}}{N}}\;&amp;amp;space;\mu\rightarrow&amp;amp;space;mean" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\bg_white&amp;amp;space;S(T)&amp;amp;space;=&amp;amp;space;\sqrt{\frac{\sum&amp;amp;space;(x-\mu&amp;amp;space;)^{2}}{N}}\;&amp;amp;space;\mu\rightarrow&amp;amp;space;mean" title="S(T) = \sqrt{\frac{\sum (x-\mu )^{2}}{N}}\; \mu\rightarrow mean" /&gt;&lt;/a&gt;&lt;a href="https://www.codecogs.com/eqnedit.php?latex=\bg_white&amp;amp;space;Entropy\;&amp;amp;space;H(X)&amp;amp;space;=&amp;amp;space;-\sum&amp;amp;space;p(X)\log&amp;amp;space;p(X)\\&amp;amp;space;Information\&amp;amp;space;Gain\;&amp;amp;space;I(X,Y)=&amp;amp;space;H(X)-H(X|Y)" target="_blank"&gt;&lt;img src="https://latex.codecogs.com/gif.latex?\bg_white&amp;amp;space;Entropy\;&amp;amp;space;H(X)&amp;amp;space;=&amp;amp;space;-\sum&amp;amp;space;p(X)\log&amp;amp;space;p(X)\\&amp;amp;space;Information\&amp;amp;space;Gain\;&amp;amp;space;I(X,Y)=&amp;amp;space;H(X)-H(X|Y)" title="Entropy\; H(X) = -\sum p(X)\log p(X)\\ Information\ Gain\; I(X,Y)= H(X)-H(X|Y)" /&gt;&lt;/a&gt;&lt;li&gt;In case of regression, if the sample is homogeneous i.e equal valued, standard deviation is 0.&lt;/li&gt;&lt;li&gt;In case of regression, the goal is to decrease the standard deviation after the data is split into subsets. Hence, the attribute that can provide the highest decrease in standard deviation is chosen.&lt;/li&gt;&lt;li&gt;In case of classification, the attribute that can provide the highest information gain is chosen.&lt;/li&gt;&lt;li&gt;In simple words, a decision tree can be viewed as a decision table. If the  tree is allowed to grow till the last depth, each leaf node will have  only one sample. If the training data has all possible permutations of  the independent variables, the decision tree becomes a representation of  a truth table. &lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;High level steps in building a regression tree are as follows:&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;Step 1: Calculate the standard deviation of the target (dependant) variable S(T).&lt;/li&gt;&lt;li&gt;Step 2:&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;ul style="text-align: left;"&gt;&lt;ul&gt;&lt;li&gt;Split the data on all the attributes (X).&lt;/li&gt;&lt;li&gt;Calculate the standard deviation of the subsets S(T,X).&lt;/li&gt;&lt;li&gt;Choose the attribute with the highest difference.&lt;/li&gt;&lt;li&gt;SDR(T,X) = S(T) - S(T,X)&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;Step 3: Split the data according to the decision attribute selected in the previous step.&lt;/li&gt;&lt;li&gt;Step 4: Repeat the process recursively.&lt;/li&gt;&lt;li&gt;Step 5: We can repeat the process recursively until each subset of the data has 0 standard deviation. This is not feasible at a large scale and it represents a model with very high variation. Hence, we need a termination criteria. For example, the termination criteria could be that the standard deviation at each leaf node must be lesser than 5%&amp;nbsp; or that each node must contain a minimum number of data points.&lt;/li&gt;&lt;li&gt;Step 6: When the number of data points at a leaf node is more than one, the average of the target variable is taken as the output at that node.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&amp;nbsp; &lt;br /&gt;&lt;b&gt;How does a decision tree handle missing data?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;During the process of building a tree, at each decision node, a decision is made for the missing data. All the data points with the missing data is first clubbed with the left subtree and the drop in standard deviation is calculated. The same is done by combining the missing data points with the right subtree. The branch with the highest drop in standard deviation is assigned to be the path to be followed for missing data points.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;What are ensembles and why do we need them?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;Ensembles are a combination of various learning models which is practically observed to provide a better performance than stand alone la carte models. This practise is also called as bagging.&lt;br /&gt;&lt;br /&gt;One of the main disadvantage of a stand alone model, like a decision tree,which is addressed by an ensemble, is that they are prone to over fitting (high variance). Ensembles are used to average out the noisy data and unbiased (or low biased) models and to create a low variance model.&lt;br /&gt;&lt;br /&gt;Two such ensembles for decision trees are Random Forest and XGBoost.&lt;br /&gt;&lt;br /&gt;The fundamental issue that both RF and XGB try to address is that decision trees are weak learners (prone to over fitting and depends heavily on the training distribution). Hence, by combining a number of weak learners, we can build a strong learner.&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;RF consists of a large number of decorrelated decision trees.&lt;/li&gt;&lt;li&gt;Given a training data set, we create a number of subsets randomly. These subsets can be based on random selection of data or features (variables). These subsets can be overlapping.&lt;/li&gt;&lt;li&gt;Build a decision tree for each of these subsets.&lt;/li&gt;&lt;li&gt;In order to get a classification from a RF, the output from each tree can be polled in order to arrive at the decision.&lt;/li&gt;&lt;li&gt;There can be a number of polling mechanisms, the most common being, the target variable with the highest frequency is chosen i.e the decision arrived to by the majority of the trees. We can also use a weighted average, where certain trees are given more weight-age than others.&lt;/li&gt;&lt;/ul&gt;Another variant of RF is called as XGBoost, which uses gradient boosting in order to build the trees. XGB models are used in cases where the data contains high collinearity. This is called as multicollinearity, where two or more features are highly correlated and one can be predicted with reasonable accuracy given the other.&lt;br /&gt;&lt;br /&gt;Unlike RF, where the trees are built parallelly with no correlation between the trees, XGB model builds the trees sequentially (and hence, computationally expensive). It learns from each tree and builds the subsequent tree so that the model can better learn the distribution of the target variable i.e the errors are propagated from one tree to the other.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;How are these models validated?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;RF models are usually validated using Out-Of-Bag (OOB) validation and the XGB models are validated using k-Fold cross validation, which is explored in another post.&lt;br /&gt;&lt;br /&gt;Given the simplicity and the intuitive nature of these models, they are one of the most widely used models for competitive ML like Kaggle. In fact, XGBoost models have won 65% of the competitions on Kaggle.&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/503820693988228126/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/decision-trees-rf-and-xgboost.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/503820693988228126'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/503820693988228126'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/decision-trees-rf-and-xgboost.html' title='Decision Trees, Random Forests and XGBoost'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-3358458904741594310</id><published>2017-02-26T05:44:00.000-08:00</published><updated>2017-02-26T05:44:08.470-08:00</updated><app:control xmlns:app='http://purl.org/atom/app#'><app:draft>yes</app:draft></app:control><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Handling skewed datasets</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Normalize, center and scale&lt;br /&gt;&lt;br /&gt;Stratified sampling - Making sure that the final training set each dependant variable has equal/near equal distributions&lt;/div&gt;</content><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/handling-skewed-datasets.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/3358458904741594310'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/3358458904741594310'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-801650156900509898</id><published>2017-02-26T04:33:00.001-08:00</published><updated>2017-02-26T04:33:27.566-08:00</updated><app:control xmlns:app='http://purl.org/atom/app#'><app:draft>yes</app:draft></app:control><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Handling a large group of independant categorical variables</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;br /&gt;&lt;/div&gt;</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/801650156900509898'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/801650156900509898'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-4364806939976686861</id><published>2017-02-22T22:59:00.000-08:00</published><updated>2017-02-22T22:59:13.519-08:00</updated><app:control xmlns:app='http://purl.org/atom/app#'><app:draft>yes</app:draft></app:control><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Paradigm shift in thinking as machine learning engineer to problem solver</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;br /&gt;&lt;/div&gt;</content><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/paradigm-shift-in-thinking-as-machine.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/4364806939976686861'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/4364806939976686861'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-5730137798434171470</id><published>2017-02-22T22:55:00.000-08:00</published><updated>2017-02-22T22:56:44.803-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Neural Network To Detect Any Pattern In The US H1B Visas Program</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div&gt;&lt;div&gt;It is officially declared that the process of awarding H1B visas by the government of US is based on a lottery system i.e a random process.&lt;br /&gt;&lt;br /&gt;Therefore, as a random project, I decided to cross verify the claim. Is it truly random or is there a pattern underlying that is not apparent?&lt;br /&gt;&lt;br /&gt;The US government releases the data of all applications for H1B and the status of whether they were certified or not. You can find the data at &lt;a href="https://www.foreignlaborcert.doleta.gov/h-1b.cfm" target="_blank"&gt;United States Department of Labour&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;I built a neural network in order to model this problem, where the features considered were:&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;VISA_CLASS&lt;/li&gt;&lt;li&gt;EMPLOYER_NAME&lt;/li&gt;&lt;li&gt;SOC_NAME&lt;/li&gt;&lt;li&gt;NAIC_CODE&lt;/li&gt;&lt;li&gt;PREVAILING_WAGE&lt;/li&gt;&lt;li&gt;PW_UNIT_OF_PAY&lt;/li&gt;&lt;li&gt;H1-B_DEPENDANT&lt;/li&gt;&lt;li&gt;WILLFUL_VIOLATOR&lt;/li&gt;&lt;li&gt;WORKSITE_STATE&lt;/li&gt;&lt;/ul&gt;There were around 647000 data points for 2016 alone, with the target classes being&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;CERTIFIED&lt;/li&gt;&lt;li&gt;CERTIFIED_WITHDRAWN&lt;/li&gt;&lt;li&gt;WITHDRAWN&lt;/li&gt;&lt;li&gt;DENIED&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;Initially, I was getting around 94% accuracy in the first epoch itself. I realised that I failed to understand the data and to build a baseline model first. You can read about the importance of building a baseline model in my blog post here, &lt;a href="http://sujayskumar.blogspot.in/2017/02/importance-of-baseline-model.html" target="_blank"&gt;Importance of Baseline Models&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;The data suggested that 89% of the 647000 data points were falling under the 'DENIED' category. The baseline model itself was giving me 89%. Hence, it was no wonder that the model was showing such high accuracies.&lt;br /&gt;&lt;br /&gt;In order to handle such a skewed dataset, I decided to create my own dataset with the following distributions:&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;CERTIFIED - 40%&lt;/li&gt;&lt;li&gt;CERTIFIED_WITHDRAWN - 20%&lt;/li&gt;&lt;li&gt;WITHDRAWN - 20%&lt;/li&gt;&lt;li&gt;DENIED - 20%&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;From this distribution, we can clearly see that the baseline accuracy should be 40%. Due to the limitations on my personal computer, I was able to take only 50000 data points for training. The performance of the model was 61%. A bump in 21% accuracy is nothing to be ignored. At the same time, it does not conclusively prove that the process of awarding H1B visas has any underlying pattern.&lt;br /&gt;&lt;br /&gt;I have some more modifications in mind, that I believe would improve the model and can point to some conclusion. I will update this post once I am done with that.&lt;br /&gt;&lt;br /&gt;Also, using at least 80% of the data set for training might throw some new light on the pattern. Also, considering more features might help better the model. This would require significant computing power. This would enable us to build a more complicated and deeper neural network that might be able to capture the underlying pattern, if any.&lt;br /&gt;&lt;br /&gt;But for now,it seems that there is nothing that can be said about the randomness of H1B visas.&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/5730137798434171470/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/neural-network-to-detect-any-pattern-in.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/5730137798434171470'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/5730137798434171470'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/neural-network-to-detect-any-pattern-in.html' title='Neural Network To Detect Any Pattern In The US H1B Visas Program'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-8404032038718427904</id><published>2017-02-22T22:29:00.001-08:00</published><updated>2017-02-22T22:57:50.554-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Importance of a Baseline Model</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;One of the important aspects of building a machine learning model is to understand the data first. Most of us forget this and jump right into modelling. Another corollary to this is that we often times forget to build a baseline model before building something complicated.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;What is a Baseline Model and a Baseline Accuracy?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;A baseline model, in simple words, is the most simple model that you can build over the provided data. The accuracy that is achieved by a baseline model is the lower bound for evaluating the performance of your model.&lt;br /&gt;&lt;br /&gt;A baseline model usually does not include any machine learning approaches, rather a statistical approach. It also include heuristics, randomness or simple statistics in order to come up with a value.&lt;br /&gt;&lt;br /&gt;Sklearn supports baseline models in the form of &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html" target="_blank"&gt;Dummy Classifiers:&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;div style="text-align: left;"&gt;&lt;span class="inline_editor_value"&gt;&lt;span class="rendered_qtext"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;stratified: generates predictions by respecting the training sets class distribution.&lt;/li&gt;&lt;li&gt;most_frequent: always predicts the most frequent label in the training set.&lt;/li&gt;&lt;li&gt;prior: always predicts the class that maximizes the class prior.&lt;/li&gt;&lt;li&gt;uniform: generates predictions uniformly at random.&lt;/li&gt;&lt;li&gt;constant:  always predicts a constant label that is provided by the user. This is  useful for metrics that evaluate a non-majority class.&lt;/li&gt;&lt;/ul&gt;In the case of regression, a baseline model could be any of the following:&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;span class="inline_editor_value"&gt;&lt;span class="rendered_qtext"&gt;Median or average&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span class="inline_editor_value"&gt;&lt;span class="rendered_qtext"&gt;Constant&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;span class="inline_editor_value"&gt;&lt;span class="rendered_qtext"&gt;Ideally, the performance of the machine learning model should be much greater than the statistical performance.&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class="inline_editor_value"&gt;&lt;span class="rendered_qtext"&gt;In case of models that are already implemented, we can use the performance of the existing models as a frame of reference and they become baseline models. &lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;div&gt;&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/8404032038718427904/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/importance-of-baseline-model.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/8404032038718427904'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/8404032038718427904'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/importance-of-baseline-model.html' title='Importance of a Baseline Model'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-6150047071076118799</id><published>2017-02-22T21:06:00.000-08:00</published><updated>2017-02-22T21:10:04.340-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Neural Networks over Random Forest</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;There has been many works published in the academia that prove that a neural network has a higher capability of capturing the underlying pattern much more effectively than statistical models. This fact is embraced by the industry as well where more and more applications leverage the use of Neural Networks.&lt;br /&gt;&lt;br /&gt;I am not going to reiterate on the various reasons why a Neural Network is better than statistical models, as I would not be able to do justice to that. I am going to demonstrate using a simple model how a neural network outperforms statistical model.&lt;br /&gt;&lt;br /&gt;I recently came across a very simple problem on Kaggle, the Kobe's Shot Selection - &lt;a href="https://www.kaggle.com/c/kobe-bryant-shot-selection" target="_blank"&gt;Kobe Bryant Shot Selection.&lt;/a&gt; It is one of the simplest problem for any beginner data scientist to cut his teeth on.&lt;br /&gt;&lt;br /&gt;I went through a lot of solutions for this problem, which were unsurprisingly filled with Random Forests and XGBoost Classifiers. This was as expected, as XGBoost models are a proven winner in a 70% of Kaggle competitions and also, a Decision Tree would be the most intuitive model to model this particular problem.&lt;br /&gt;&lt;br /&gt;I tried many variations of the same and was able to climb upto rank 240 using the XGBoost models. But these models relied heavily on extensive feature engineering. Me, personally, being from a non sports background, it was rather difficult to identify these features which would be relevant to the problem. I had to read blogs and other solutions to understand that certain features like "Is it the last 5 mins of the game?" or "Is it a home or away match?", are very important in order to predict the outcome. This requirement of domain knowledge is a shot in the knee for someone with limited domain knowledge.&lt;br /&gt;&lt;br /&gt;The next model I built, was a simple Feed Forward Neural Network with one hidden layer. The input dimension was 197, the hidden layer dimension was 30 and the output was a single sigmoid neuron, optimizing on binary cross entropy.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-dTTXmkzuxN0/WK5unkhUdJI/AAAAAAAAIuI/QcIIO5rgroIrdT_-AK3it7Op2fpIUBXsACLcB/s1600/Untitled%2BDiagram%25282%2529.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="250" src="https://3.bp.blogspot.com/-dTTXmkzuxN0/WK5unkhUdJI/AAAAAAAAIuI/QcIIO5rgroIrdT_-AK3it7Op2fpIUBXsACLcB/s320/Untitled%2BDiagram%25282%2529.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;br /&gt;Such a simple model with practically no feature engineering at all was able to put me in the 25th position on the public leaderboard, &lt;a href="https://www.kaggle.com/c/kobe-bryant-shot-selection/leaderboard?submissionId=4101391" target="_blank"&gt;Public Leaderboard Ranking. &lt;/a&gt;&lt;br /&gt;&lt;br /&gt;This leads me to one of the main advantages of neural networks over statistical models. You do not need any domain knowledge in order to build a model. Although the winning solution implements an XGBoost model, I am sure it involves a lot of feature engineering, which is a time consuming task.&lt;br /&gt;&lt;br /&gt;Some of the points to keep in mind while building a neural network are:&lt;br /&gt;&lt;br /&gt;&lt;ol style="text-align: left;"&gt;&lt;li&gt;Always normalize the inputs. Neural Networks are optimized for working on numbers between 0 and 1. Any number greater than 1 leads to explosive gradient descent, which involves weight updates by large numbers.&lt;/li&gt;&lt;li&gt;The number of parameters of the model should be significantly less than the number of training examples. If it is greater, it will lead to over fitting.&lt;/li&gt;&lt;li&gt;Use neurons which align to the objective of the problem. For example, in this case, the model was being evaluated on the logloss and hence it makes sense to use sigmoid neurons.&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/6150047071076118799/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/neural-networks-over-random-forest.html#comment-form' title='2 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/6150047071076118799'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/6150047071076118799'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/neural-networks-over-random-forest.html' title='Neural Networks over Random Forest'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><media:thumbnail xmlns:media='http://search.yahoo.com/mrss/' url='https://3.bp.blogspot.com/-dTTXmkzuxN0/WK5unkhUdJI/AAAAAAAAIuI/QcIIO5rgroIrdT_-AK3it7Op2fpIUBXsACLcB/s72-c/Untitled%2BDiagram%25282%2529.png' height='72' width='72'/><thr:total>2</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-8077005362562444871</id><published>2017-02-21T08:56:00.000-08:00</published><updated>2017-02-21T08:56:06.080-08:00</updated><app:control xmlns:app='http://purl.org/atom/app#'><app:draft>yes</app:draft></app:control><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Curse of dimensionality</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;br /&gt;&lt;/div&gt;</content><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/curse-of-dimensionality.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/8077005362562444871'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/8077005362562444871'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-2373839901009698570</id><published>2017-02-18T22:00:00.002-08:00</published><updated>2017-02-26T07:31:51.922-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Points to consider while building a Machine Learning model</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;The objective of this post is to list down some of the pointers to keep in mind while building a Machine Learning model.&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;Always start with the simplest of models. You can increase the complexity if the performance of a simple model is inadequate.&lt;/li&gt;&lt;li&gt;Understand your dataset first.&amp;nbsp;&lt;/li&gt;&lt;li&gt;Build a baseline model before building any prediction model. I will expand on this further in another post.&lt;/li&gt;&lt;li&gt;Complex models tend to over fit and simpler models tend to under fit. It is your job to find a balance between these two.&lt;/li&gt;&lt;li&gt;&lt;b&gt;High bias and low variance&lt;/b&gt; - A property of simpler models. Suggests under fitting.&lt;/li&gt;&lt;li&gt;&lt;b&gt;High variance and low bias&lt;/b&gt; - A property of complex models. Suggests over fitting.&lt;/li&gt;&lt;li&gt;In any Machine Learning model, if the number of parameters is greater than the number of training examples, beware. It leads to over fitting. Try considering a simpler model with lesser number of parameters or reduce the number of hidden layers or anything else to reduce the number of parameters of the model.&lt;/li&gt;&lt;li&gt;Always normalize the inputs. Neural Networks are optimized for working  on numbers between 0 and 1. Any number greater than 1 leads to explosive  gradient descent, which involves weight updates by large numbers. &lt;/li&gt;&lt;li&gt;Regularization is very very important. Therefore, consider using an XGBoost model instead of Random Forest.&lt;/li&gt;&lt;/ul&gt;Some terms to keep in mind:&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;b&gt;Stratified Sampling&lt;/b&gt; - When the training data is overly skewed, the practice of picking the samples such the final training data has the distribution you need.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Bootstrapping&lt;/b&gt; - Evaluating the same model with different random seeds.&amp;nbsp; &lt;/li&gt;&lt;/ul&gt;&lt;ul style="text-align: left;"&gt;&lt;/ul&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/2373839901009698570/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/points-to-consider-while-building.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/2373839901009698570'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/2373839901009698570'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/points-to-consider-while-building.html' title='Points to consider while building a Machine Learning model'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-3583978115664713553</id><published>2017-02-18T09:10:00.000-08:00</published><updated>2017-02-18T09:30:28.004-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Past, Present and Future of Machine Learning</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;"Machine Learning" as a term has gained such traction in the technology world today that it is highly improbable that you would meet a person who hasn't heard this term, either in a positive or a negative connotation.&lt;br /&gt;&lt;br /&gt;We have industry experts, CS professionals, hiring experts and practically every other person directly or indirectly related to the Computer Science domain, harping about how ML/AI is going to be the future of computing.&lt;br /&gt;&lt;br /&gt;I am here to just explore how this came out to be, and also why I think although assuming that ML is going to be &lt;b&gt;THE&lt;/b&gt; future of computing might be over exaggeration, it is going to play an important role in the future nonetheless.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Where did ML start?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;It might be surprising to know for a majority of you that one of the corner stones of ML, the humble Naive Bayes classifier has been around for more than 2 centuries. The Bayes theory was first published in the second half of the 18th century.&lt;br /&gt;&lt;br /&gt;One of the cutting edge of ML research and applications, the Neural Networks has been around since the 1950s! Some of you might even be surprised to learn that this was even before the von Neumann architecture was introduced! For those of you who might not know what von Neumann architecture is, it is the basic architecture on which &lt;b&gt;ALL&lt;/b&gt; the computers till date were ever built.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;How did ML/AI become such a rage in the latter half of this decade?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;So why did it peak in the last 5 years that didn't happen in the past half a century? The answer lies in &lt;b&gt;DATA!&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;The success of any ML model solely depends on the type, amount and quality of data fed to the model for training. The reason why it was abandoned was because of the data. There was never enough data to train even a simple naive Bayes model. With the advent of the World Wide Web in the 2000s, although there was a lot of data being generated, the quality was still too bad to be of any use for any modelling. With the advent of iPhone and personal computers and the penetration of these personal computing devices made sure that there was no dearth in the production of data. Hence, applications of models came to the fore.&lt;br /&gt;&lt;br /&gt;With data being produced at an unprecedented rate which might even surpass the consumption rate, these ML and AI based applications become ever more relevant to our day to day lives.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;How is ML affecting our society and employment?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;Nowadays we are observing a deep uncertainty over the implications of a machine capable of making decisions based on incomplete data available and its potential to disrupt the human society as a whole, with some even suggesting that the Terminator-esque scenario where the human race is hunted by the machines will come to fruition in the near future. I personally believe that such predictions are completely unfounded for various reasons. The popular media has the ability to attach negative connotation to any subject that might be hard to comprehend. If you look at the world today, we can already see a vast majority of our lives being penetrated by ML or AI, without us noticing at all. That Google search you just did to find out how the weather would be today, or your Facebook or Instagram feed, were all powered by ML.&lt;br /&gt;&lt;br /&gt;A couple of decades ago, blue collar factory workers were looked up to as they were considered skilled employees. Youth were drawn towards the glamourous appeal of urban and factory life compared to the agricultural livelihood, as can be seen from the mass migration of rural youth to urban centres which were primarily built around factories. But in the last decade, most of these blue collar jobs were replaced by automated machines, which were both reliable and efficient. Although there were large scale protests against the loss of jobs, the society did not complain when the prices of their day to day products went down and the quality increased. The job market corrected itself after the people who lost their jobs were able to find other means of livelihood made possible by the booming economy brought about by the reduction in production costs.&lt;br /&gt;&lt;br /&gt;Similarly, the society is unsettled with the advent of self driving vehicles, personal assistants etc and its potential to cut human jobs and increase the chances of machines taking over the world. But if we look around us, ML has already taken over our lives and the market has always self corrected itself after a short term decrease in employment.&lt;br /&gt;&lt;br /&gt;In the long term, the ability of a machine to take over mind numbing and routine tasks opens up other avenues for human kind. We can now explore the more creative and intellectually stimulating pursuits that we couldn't afford before. By assigning all the manual and dirty work to the machines, we are actually left free to advance mankind in a more creative venture. This is analogous to getting a maid at home. Whether we will utilize the new found freedom to advance mankind or to other self destructing avenues remain to be seen. But one thing is for certain, if the society does enter an apocalyptic phase, it is only us to be blamed and not the ML/AI.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Where is ML headed?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;In the near future, software development in services is headed towards the same path as the blue collar factory jobs of yesteryears. Since most of the basic architectures and systems are already in place, majority of the software servicing roles have become repetitious. As history as shown us, these repetitious and monotonous jobs are going to be automated with new jobs being created for more intellectually challenging and creative ventures. This is not to say that the entire software development industry is going to be shut down. Some of the software development roles require a lot of human intellect and creativity, which can never be replaced by a machine.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;How will ML/AI change in the future?&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;Right now, we are limited by the processing capabilities of the current computing machines. In the status quo, the processing machines are deterministic i.e given an input, the result can be determined. We are trying to use this machine in order to model a system that is highly probabilistic in nature. I think, in another decade or so, we would come up with an entirely new architecture of computing, that would be probabilistic, instead of the deterministic nature of current processors. This would signal a huge leap in the ML/AI space as a probabilistic machine can better represent a human who has never been a deterministic being.&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/3583978115664713553/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/past-present-and-future-of-machine.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/3583978115664713553'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/3583978115664713553'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/past-present-and-future-of-machine.html' title='Past, Present and Future of Machine Learning'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-8663138205525485319</id><published>2017-02-17T00:19:00.000-08:00</published><updated>2017-02-18T09:31:38.586-08:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#post'/><title type='text'>Why Machine Learning?</title><content type='html'>&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;&lt;b&gt;Why would anyone want to be a Machine Learning engineer?&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-size: x-small;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;I cannot be presumptuous and speak for others, but I can tell you why I wanted to be one. It boils down to one word&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif;"&gt;.&lt;/span&gt; "Magic".&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-size: x-small;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;It all goes back to my childhood when I was utterly bitten by the computer bug in my father's office. I used to hang out with him most of the days, playing games on the computer. I was enthralled by the possibility of such a small machine that makes the tiny human on the screen jump when I press a button. How does that piece of metal know what to do and when? And it was capable of running not one, but multiple games! I could ride a bike, kick another person while riding a bike, I could race cars, I could rescue a princess, I could go through prison walls. Imagine your fantasy world being given to you in a small piece of metal box to do with as you please. It was magic to a 5 year old.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-size: x-small;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;The intense curiosity fuelled by a magic trick and the drive to find out how it was being pulled off is what captured my fascination in computers. &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-size: x-small;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;&lt;b&gt;Result:&lt;/b&gt; I was simple boy. I just wanted to know how it worked.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-size: x-small;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;Fast forward 12 years, I am a CS student at an engineering college, learning how a computer does what it does. After learning a bit about computers and coding in high school, you now understand  how a computer runs your game, how it calculates the equations you throw  at it and how it is capable of a myriad of operations that you didn't know existed. Your curiosity is quenched up to a certain extent. A computer is not that much of a magic box that it once seemed to be. All is good.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;Then you encounter a computer that can recognize your voice and can convert your speech to text! And your entire understanding of how a computer works is turned upside down. If you ask it to add 4 and 5, you know it is capable of giving you the correct answer. But you give it an audio file and ask it to recognize it, you would never expect it to actual deliver. Add the fact that the underlying architecture of a computer has not changed in decades, the ability of a computer to take such soft, ambiguous decisions based on just algorithms is mind blowing.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;It seems like magic when I see a computer recognizing my face in a video, recognizing my friends in the picture, gauging my emotions, hailing a cab when it's time to leave for office and asking if I wanted a coffee on the go since it understands that I love coffee and take it usually in the mornings. It was magic to a 20 year old.&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-size: x-small;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;Being exposed to this all new ability of computers to affect our daily lives and change it drastically for the better (or worse) just fuels my curiosity further. How does it know where to park the car? How does it know if I am going to the office or to my friend's place?&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt; Even after 4 years of studying CS, a computer can still make you drop your jaw, just like it did when you were 5 years old. It still appears to be a magic box that is  capable of doing something you would never expect it to do.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;&lt;b&gt;Result:&lt;/b&gt; I am a simple man. I just want to know how it works. &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-size: x-small;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;span style="font-family: &amp;quot;arial&amp;quot; , &amp;quot;helvetica&amp;quot; , sans-serif; font-size: x-small;"&gt;&lt;span style="font-size: small;"&gt;Plain and simple.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='https://sujayskumar.blogspot.com/feeds/8663138205525485319/comments/default' title='Post Comments'/><link rel='replies' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/why-machine-learning.html#comment-form' title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/8663138205525485319'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/posts/default/8663138205525485319'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/why-machine-learning.html' title='Why Machine Learning?'/><author><name>Sujay S Kumar</name><uri>https://www.blogger.com/profile/07714618653272323377</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//1.bp.blogspot.com/-KChmWUn5U2Y/WmR8gMj-R_I/AAAAAAAAL1o/eCFwOzyajeIsVKdKL3YwmTMbJET9EkoPgCK4BGAYYCw/s32/circular.png'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-1673512050811753724</id><published>2017-08-09T00:22:44.303-07:00</published><updated>2017-08-09T00:22:44.303-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#comment'/><title type='text'>That is very interesting; you are a very skilled b...</title><content type='html'>That is very interesting; you are a very skilled blogger. I have shared your website in my social networks! A very nice guide. I will definitely follow these tips. Thank you for sharing such detailed article. &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.gangboard.com/big-data-training/data-science-training" rel="nofollow"&gt;Data Science Online Training&lt;/a&gt;|&lt;br /&gt;&lt;a href="https://www.gangboard.com/big-data-training/hadoop-training" rel="nofollow"&gt;Hadoop Online Training&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.gangboard.com/business-intelligence-training/r-programming-training" rel="nofollow"&gt;R Programming Online Training&lt;/a&gt;|&lt;br /&gt;</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/6150047071076118799/comments/default/1673512050811753724'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/6150047071076118799/comments/default/1673512050811753724'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/neural-networks-over-random-forest.html?showComment=1502263364303#c1673512050811753724' title=''/><author><name>Sai Bk</name><uri>https://www.blogger.com/profile/15717087772787116127</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='35' height='35' src='//lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35'/></author><thr:in-reply-to href='http://sujayskumar.blogspot.com/2017/02/neural-networks-over-random-forest.html' ref='tag:blogger.com,1999:blog-925060870564624560.post-6150047071076118799' source='https://www.blogger.com/feeds/925060870564624560/posts/default/6150047071076118799' type='text/html'/><gd:extendedProperty name='blogger.itemClass' value='pid-1531454149'/><gd:extendedProperty name='blogger.displayTime' value='August 9, 2017 at 12:22 AM'/></entry><entry><id>tag:blogger.com,1999:blog-925060870564624560.post-6339514376135375499</id><published>2017-09-01T00:28:00.562-07:00</published><updated>2017-09-01T00:28:00.562-07:00</updated><category scheme='http://schemas.google.com/g/2005#kind' term='http://schemas.google.com/blogger/2008/kind#comment'/><title type='text'>This is an awesome post.Really very informative an...</title><content type='html'>This is an awesome post.Really very informative and creative contents. These concept is a good way to enhance the knowledge.I like it and help me to development very well.Thank you for this brief explanation and very nice information.Well, got a good knowledge.&lt;br /&gt;&lt;br /&gt;&lt;a href="http://www.besanttechnologies.com/data-science-training-in-marathahalli" rel="nofollow"&gt;Data science training in Marathahalli&lt;/a&gt;|&lt;br /&gt;&lt;a href="http://www.besanttechnologies.com/data-science-training-in-marathahalli" rel="nofollow"&gt;Data science training in Bangalore&lt;/a&gt;|&lt;br /&gt;&lt;a href="http://www.besanttechnologies.com/hadoop-training-in-marathahalli" rel="nofollow"&gt;Hadoop Training in Marathahalli&lt;/a&gt;|&lt;br /&gt;&lt;a href="http://www.besanttechnologies.com/hadoop-training-in-marathahalli" rel="nofollow"&gt;Hadoop Training in Bangalore&lt;/a&gt;|</content><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/6150047071076118799/comments/default/6339514376135375499'/><link rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/925060870564624560/6150047071076118799/comments/default/6339514376135375499'/><link rel='alternate' type='text/html' href='http://sujayskumar.blogspot.com/2017/02/neural-networks-over-random-forest.html?showComment=1504250880562#c6339514376135375499' title=''/><author><name>rose</name><uri>https://www.blogger.com/profile/14536506270091000134</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='35' height='35' src='//lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35'/></author><thr:in-reply-to href='http://sujayskumar.blogspot.com/2017/02/neural-networks-over-random-forest.html' ref='tag:blogger.com,1999:blog-925060870564624560.post-6150047071076118799' source='https://www.blogger.com/feeds/925060870564624560/posts/default/6150047071076118799' type='text/html'/><gd:extendedProperty name='blogger.itemClass' value='pid-1508762191'/><gd:extendedProperty name='blogger.displayTime' value='September 1, 2017 at 12:28 AM'/></entry></feed>